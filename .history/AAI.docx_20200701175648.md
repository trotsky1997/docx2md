![](media/image1.png)




## ********人工智能讲义
  **Why, What and History**


  February 20, 2020

### ************Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```
[Why：人工智能热潮产生的原因]()[what：什么是人工智能]()
  
```
\*\*3\*\*
```
[History: 人工智能历史的简单回顾]()



工业/工业革命   4.0：产业界的实际应用对技术的渴求
  ![](media/image4.png)2013 年，德国政府提出的研究计划：智能制造主导的第四次工业革命（前三次的代表：蒸汽机/计算机/基因工程）
  ![](media/image5.png)智能工厂 + 智能物流：依赖人工智能技术
  ![](media/image6.png)![](media/image6.png)2015 年，中国，互联网 +，工业革命 4.0，产业升级，黑洞工厂个性化制造：关键在于人工智能技术的发展
  ![](media/image7.png)有人预测，它在 10 年内让淘宝消失；


        ![](media/image8.jpeg)
  ![](media/image6.png)各种“人工大脑”计划：学术界提供了技术发展的基础 欧盟投入 10 亿美元的“人类大脑计划”
  ![](media/image6.png)![](media/image7.png)美国投入 30 亿美元的“大脑基金计划” 中国大脑计划，上海，百度
  ![](media/image7.png)AI：第七次信息革命（语言、文字、纸和印刷术、电报和电话、电 视、计算机和互联网）





  ![](media/image6.png)调查研究显示：科学家们最想参与的研究领域分子生物学
  ![](media/image7.png)人工智能

### ************Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```
[Why：人工智能热潮产生的原因]()[what：什么是人工智能]()
  
```
\*\*3\*\*
```
[History: 人工智能历史的简单回顾]()


                    ![](media/image10.jpeg)2014 年 6 月 8 日，一台计算机成功让人类
                    相信它是一个 13 岁的男孩，成为有史以来首台通过图灵测试的计算机。这被认为是人工智能发展的一个里程碑事件。


像人一样地行为
  ![](media/image7.png)Turing (1950) ”Computing machinery and intelligence”
  ![](media/image7.png)“Can machines think?”*→*“Can machines behave intelligently?”人工智能之父
  ![](media/image7.png)从智能机器的实际效果来判断何为智能：图灵测试，人工智能哲学方面第一个严肃的提案
  ![](media/image7.png)阿兰-图灵：“论数字计算在决断难题中的应用”，图灵给“可计算性”下了一个严格的数学定义，并提出著名的“图灵机”(Turing Machine) 的设想
  ![](media/image7.png)图灵当时预言，到 2000 年将会出现足够好的电脑，能够在不超过 7 成人的长达 5 分钟的提问中全部回答正确
相关技术：自然语言理解、知识表示、自动推理、机器学习、计算机视觉、机器人技术、……




像人一样地思考
  ![](media/image7.png)20 世纪 60 年代，cognitive revolution，information-processing psychology
  ![](media/image4.png)从生物学角度，建立大脑活动的模型和理论
  ![](media/image5.png)将生物学过程人工模拟一遍，可以得到 AI，使之和人脑的输入/输出一样




理性地思考
  ![](media/image7.png)Aristotle: what are correct arguments/thought processes? 三段论，逻辑学
  ![](media/image6.png)![](media/image5.png)19 世纪逻辑学家建立一种描述世界上一切事物及其彼此关系的精确命题符号，AI 中逻辑主义流派，期望编制这样的程序实现智能Problems：（1）所有知识都能方便地转化为逻辑符号表示吗？可靠吗？（2）逻辑推理过程的代价有实际工程意义吗？



|                  |                                                                                                  |
|------------------|--------------------------------------------------------------------------------------------------|
|像人一样思考的系统|新的令人激动的努力， 要使计算机能够思考，从字面上完整的意思就是：有头脑的机器。（Haugeland，1985）|
|                  |[使之自动化] 与人类的思维相关的活动，诸如决策、问题求解、学习等活动。（Bellman，1978）            |
|理性地思考的系统  |通过对计算模型的使用来进行心智能力的研究。（Chaniak 和 McDermott，1985）                          |
|                  |对使得知觉、推理和行动成为可能的计算的研究。（Winston，1992）                                     |
|像人一样行动的系统|一种技艺，创造机器来执行人需要智能才能完成的功能。（Kurzweil,1990）                               |
|                  |研究如何让计算机能够做到那些目前人比计算机做得更好的事情。（Rich 和 Knight，1991）                |
|理性地行动的系统  |计算智能是对设计智能化智能体的研究。（Poole等，1998）                                             |
|                  |AI.关心的是人工制品中的智能行为。（尼尔森，1998）                                                 |



思想和行为
  ![](media/image6.png)思考：思维过程和推理，1 和 2
  ![](media/image7.png)行为：强调行为及其结果，3 和 4
理性和非理性
  ![](media/image7.png)理性：指人在正常思维状态下时，有自信与勇气地遇事不慌且能够全面了解和总结并尽快的分析出多种可行方案（这些方案可以是预备的或是临    时的）并使用其中最好的一种方案去操作或处理，达到事件需要的效果。    理性是基于现有的理论，通过合理的逻辑推导得到确定的结果。 2 和 4
  ![](media/image4.png)非理性：情感支配的思维和行为？1 和 3
我的观点
  ![](media/image6.png)AI：制作一个机器人/智能体/Agent，能对给定的或任何条件/环境， 进行“最正确的/最佳的”应对（思维结果或行为）
  ![](media/image6.png)非理性：额外增加了条件/环境变量（数值量化情感，成为智能体的输入)




Agent/智能体
  ![](media/image7.png)能感知，能行动的机器人（软件或硬件都可）
  ![](media/image6.png)AI：就是设计和制造 Agent
  ![](media/image5.png)
```
\*→\*
```
当我们去掉时间、金钱，软件、硬件等等约束条件，所谓 Agent， 从数学上看，就是一个函数 *f *: *E    A*，其中 *E *是环境或条件的所有可能取值，*A *是所有可能的行动。智能体或函数 *f *就是对任何一个 *x **∈ **E*，映射/对应一个“最佳的”行动 *f*(*x*)。


超人工智能
  ![](media/image7.png)对 任何 的环境或条件都能给出“最正确的/最佳的”应对。
  ![](media/image4.png)Intelligence：超过人类智能水平
弱人工智能
  ![](media/image7.png)对 给定的环境或条件能给出“最正确的/最佳的”应对。
  ![](media/image7.png)Smart：智能手表，智能家电，智能制造，垂直搜索引擎
强人工智能
  ![](media/image7.png)![](media/image7.png)达到人类相近的智能水平我们想要达到的目标


感知智能：智能的软件基础
  ![](media/image6.png)即视觉、听觉、触觉等感知能力，人和动物都具备，能够通过各种  智能感知能力与自然界进行交互
  ![](media/image7.png)识别对象：包括具体对象或抽象概念对象等，即机器学习，数据挖  掘，模式识别

  ![](media/image7.png)运算智能：智能的硬件基础快速计算和记忆存储能力
  ![](media/image7.png)算得比竞争者快，记忆了更多的东西，那就是一种展现出来的智能
认知智能：更高层级的智能
  能理解会思考，人类有语言，才有概念，才有推理，所以概念、意  识、观念等都是人类认知智能的表现。


  ![](media/image7.png)与 AI 有关联的其他领域的研究哲学：思维/意识/推理/……
  ![](media/image6.png)![](media/image6.png)数学：形式化（逻辑）/计算/概率论经济学：博弈论/运筹学
  ![](media/image7.png)神经科学：神经元工作机理/大脑思维过程
  ![](media/image7.png)![](media/image7.png)心理学：认知心理学/认知理论就应该像计算机程序计算机工程：更快的计算能力
  ![](media/image4.png)控制论：控制系统设计
  ![](media/image4.png)![](media/image5.png)语言学：自然语言处理/知识表示系统论：钱学森
  ![](media/image6.png)*. . .*


  
```
\*\*1\*\*
```

```
\*\*2\*\*
```
[Why：人工智能热潮产生的原因]()[what：什么是人工智能]()
  
```
\*\*3\*\*
```
[History: 人工智能历史的简单回顾]()


              ![](media/image14.jpeg)
                计算机科学之父
  ![](media/image7.png)计算机科学之父, 人工智能之父
  ![](media/image7.png)提出了“图灵机”和“图灵测试”(机器学习、遗传算法和增量学习等，in   《计算机器与智能》)
  ![](media/image4.png)1966 年开始，ACM 设立的以其名命名的“图灵奖”是“计算机界的诺贝尔奖”
  ![](media/image4.png)《模仿游戏》并获得 2015 年第 87 届奥斯卡最佳改编剧本奖



最早的人工智能工作
  ![](media/image6.png)两位美国神经科学家
  ![](media/image6.png)1943 年，人工神经元模型，基于：生理学和脑神经元功能 + 命题逻辑的形式化分析 + 图灵的计算理论
  ![](media/image7.png)人工神经元的“开”和“关”状态，激活
  ![](media/image4.png)任何可计算函数都可以用神经元构成的某种网络来实现计算，包括  与、或、非等逻辑运算
  ![](media/image4.png)1949 年，Donald Hebb，提出 Hebb 学习，来更新网络连边的权值， 实现网络学习功能


                    ![](media/image15.jpeg)人工智能之父
                      ![](media/image6.png)人工智能之父
                      ![](media/image7.png)1969 年图灵奖，第一个获奖的 AI
                      研究者
                      ![](media/image6.png)框架理论创建者
                      ![](media/image7.png)1951 年，第一台神经元网络计算机
                      SNARC，合作者 Dean Edmonds
                      ![](media/image4.png)Warren McCulloch 的学生
                      ![](media/image7.png)1958 年 MIT 创建第一个 AI 实验室
                      ![](media/image7.png)1956 年达特茅斯会议发起人，会议确立 artificial intelligence 一词
                      ![](media/image7.png)2016 年 1 月去世


                    ![](media/image16.jpeg)人工智能之父
                      ![](media/image17.png)1956 年达特茅斯会议提出 artificial intelligence 一词（会议四个发起人： 明斯基/IBM 罗杰斯特/香农/麦卡锡， 期望 10 来个人 2 个月的共同努力设计出一台具有真正智能的机器）
                      ![](media/image18.png)1971 年获得图灵奖
                      ![](media/image18.png)发明了 LISP 语言，人工智能界第一个最广泛流行的语言。LISP 是一种函数式的符号处理语言
                      ![](media/image18.png)Alpha-beta 剪枝
                      ![](media/image19.png)1962 年建立了斯坦福人工智能实验室，先协助明斯基在 MIT 建立 AI 实验室
                      ![](media/image17.png)2011 年 10 月 24 日晚上去世


少见的全才
                ![](media/image20.jpeg)![](media/image7.png)政治学博士，符号主义学派创始人
                ![](media/image7.png)1956 年，达特茅斯会议，“逻辑理论家”是当时唯一可以工作的人工智能软件，人工智能之父
                ![](media/image4.png)1978 年，“经济组织内的决策过程进行的开创性的研究”获诺贝尔经济学奖
                ![](media/image7.png)1975 年和学生纽厄尔获得图灵奖，通用问题求解系统
                GPS
                ![](media/image6.png)心理学成就：设计实验证明人类解决问题的过程是一个搜索过程，效率取决于启发式函数
                ![](media/image7.png)自然语言处理：发展和完善了语义网络，成为知识表示的通用方法
                ![](media/image6.png)科学发现只是一种特殊类型的问题求解，因此也可以用计算机程序实现特殊类型的问题求解，可以用计算机程序实现科学发现，搞科学研究
                ![](media/image4.png)1972 年 7 月作为美国计算机科学家代表团成员之一第一
                次到中国访问。之后又 9 次来华访问


              ![](media/image21.jpeg)
              分枝定界的发明者
  ![](media/image7.png)研究了与实际应用有密切联系的一系列数学问题，如路径问题、背包问题、覆盖问题、匹配问题、分区问题、调度问题等，提出了一种称为“分枝限界法”（branch—and—bound method）
  ![](media/image6.png)组合问题中的可归约性
  ![](media/image7.png)1985 年图灵奖


                    知识工程的提出者
                      ![](media/image22.jpeg)![](media/image23.png)1994 年图灵奖
                      ![](media/image19.png)世界上第一个专家系统程序
                      DENDRAL
                      ![](media/image18.png)![](media/image18.png)知识中蕴藏着力量，In the Knowledge lies the power 美国空军的首席科学家
                      ![](media/image18.png)1963 年他主编了《计算机与思想》，这本书被认为是世界上第一本有关人工智能的经典性专著
                      ![](media/image24.png)20 世纪 80 年代，费根鲍姆和 Avron Barr 等人合编了四卷本的《人工智能手册》


              ![](media/image25.jpeg)


  ![](media/image5.png)1994 年图灵奖
大型人工智能系统开发的专家

  ![](media/image5.png)自称是第二代的人工智能研究者
  ![](media/image6.png)导师有” 人工智能之父” 之称的 J.McCarthy
  ![](media/image7.png)1979 年他担任国际 AI 联合会议主席时, 又带头发起成立了美国人工智能协会 AAAI, 并于 1987～1989 年任 AAAI 会长

### ********Judea Pearl
![](media/image26.jpeg)
  不确定性推理算法的创造者
  ![](media/image6.png)《Causality: Models,Reasoning,and  Inference》，创立了概率和因果性推理演算法
  ![](media/image5.png)![](media/image4.png)改变了人工智能最初基于规则和逻辑的方向不确定的条件下的信息处理
  ![](media/image4.png)指出智能系统所面临的不确定性是一个核心问题，并且提出概率论  算法作为知识获取及表现的有效基础

![](media/image1.png)



## ********人工智能讲义
  **智能体、函数与复杂性**


  February 20, 2020

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```
[智能体/Agent ]()[函数]()
  
```
\*\*3\*\*
```
[函数描述的复杂性]()



              ![](media/image28.jpeg)什么是智能体？
              智能体 = 感知器 +“环境-最佳应对”+ 执行器 +......
                  =Observation + Decision + Action + ......
                  =ODA+......
              类比为：眼睛 + 大脑 + 手脚 +......



|            |            |
|------------|------------|
|环境变量 *X*|最佳应对 *A*|
|*x*1        |*a*1        |
|*x*2        |*a*2        |
|*. .** **.* |*. .** **.* |

  Table: *a**i** *= *f*(*x**i*)*,** **i** *= 1*,** *2*,** **.** **.** **.*
我们课程关注“大脑”         O：观测所得环境变量 *X** *的值 *x**i** *A：行动，行动 *a**i*
D：决策/大脑，用函数 *f *来描述， 给出面对环境 *x**i**  *时的最佳行动 *a**∗**i*


生产实践中：（不严谨的说法）
  ![](media/image7.png)一种转换，从输入到输出的转换或映射机制；
  ![](media/image7.png)![](media/image7.png)可以是一个过程，如生产过程，将原材料转换为产品；可以是人的一个思维过程；    可以表示现实中几乎所有的“转换”。

在数学中：（严谨的说法）
  ![](media/image7.png)传统定义：一般的，在一个变化过程中，有两个变量 *x**, **y*，如果给定一个 *x *值，相应的就确定唯一的一个 *y*，那么就称 *y *是 *x *的函数，其中 *x *是自变量，*y *是因变量，*x *的取值范围叫做这个函数的定义域，相应 *y *的取值范围叫做函数的值域。
  ![](media/image6.png)现代定义：设 *A**, **B *是非空的集合，如果按照某种确定的对应关系 *f*，使对于集合*A *中的任意一个元素 *x*，在集合 *B *中都有唯一确定的元素 *y *和它对应，那么就称*f *为从集合 *A *到集合 *B *的一个函数，记作 *y *= *f*(*x*)*, **x **∈ **A *或
  *f*(*A*) = *{**y**|**f*(*x*) = *y**, **y **∈ **B**} *。
  ![](media/image6.png)近似的理解：两个集合 *A**, **B *的元素之间的关系。


函数怎样表示最好呢？考虑：精确性、简洁性和使用方便性
  ![](media/image6.png)解析表示：数学关系等式来描述函数，复杂的函数无法用解析式来表示；    能用解析式简单描述出来的函数，表示两个集合（定义域和值域）元素之    间有很强的关系，这种关系，是一种“知识”或“规律”。
  ![](media/image7.png)列表法：将定义域的元素排在表的左边列，右边列给出对应的值域的值。    能精确描述表示所有的函数；但是面对连续型定义域（或定义域包含无穷    个元素）时，该方法无效；大多数函数的列表表示法面临表中的行（一行    一个定义域的元素）太多的问题。
  ![](media/image5.png)图像法：把一个函数的自变量 *x** *与对应的因变量 *y** *的值分别作为点的横坐标和纵坐标，在直角坐标系内描出它的对应点，所有这些点组成的图形    叫做该函数的图象。这种表示函数关系的方法叫做图象法。这种方法的优    点是通过函数图象可以直观、形象地把函数关系表示出来；缺点是从图象    观察得到的数量关系是近似的。
  ![](media/image7.png)语言叙述法：使用语言文字来描述函数的关系. 这种表示方法在现实中是最常见的。


函数是知识的一种表示方法
  ![](media/image6.png)物理、化学、生物和社会科学等的研究，科学发现，寻找其中的“规律或知识”，并表述成 函数
  ![](media/image7.png)*s** *= *vt**,** **E** *= *m**c*2，“一切微观粒子，包括电子和质子、中子，都有波粒二象性”，......
  ![](media/image7.png)认识世界，总是针对某个“现象”，分析已知条件（集合 *A*）和结果 (集合 *B*) 之间的关系，寻找/理解/描述他们之间的“转换”机制， 即认识某个“函数”。
  ![](media/image6.png)![](media/image5.png)所以，我们若用函数 *f** *来描述世上任一“变换”，那么认识世界，科学发现，就是所谓的“寻找/理解/定义/描述”对应的函数 *f *的过程。计算机人工智能中所谓“机器学习”，即让计算机自动来认识世界，寻找函数 *f*。
  ![](media/image4.png)然而人工智能并非只有“寻找函数 *f*”，还有......




站在计算思维的角度看
  ![](media/image7.png)在计算机科学中，用列表法来表示和定义函数;
  ![](media/image7.png)在计算机科学中，可以用一段程序代码，把函数的输入到输出的映射“打印”出来，这段程序代码被视为“函数”；
  ![](media/image7.png)计算机科学中，通常会把连续的，无穷个元素的集合等用有限集合来近似；（离散化，模拟 *→** *数字）；
  ![](media/image7.png)![](media/image6.png)用列表法来理解函数有助于对问题求解的时空复杂性进行分析。  这一思想将贯穿我们整个人工智能领域。


函数描述/定义：说明给定输入 *x*，输出 *y *是什么
  ![](media/image7.png)
```
\*∈\*\*∈\*
```
完全描述：对任意一个输入 *x*X，都能给出相应的 *y*Y。理论研究中，我们经常追寻对函数的完全描述，来掌握“全部”知识。
  ![](media/image7.png)部分描述：并没有对所有可能输入都说明了其相对应的输出值。实际工程应用中，完全描述      函数，很多时候是没有必要，或者不可行的，故常常给出部分描述即可。
  ![](media/image5.png)符号说明：*|** *· *| *表示集合的大小。


  完全描述
  给定函数 *y *= *f*(*x*)，其中
  
```
\*∈\*\*{}\*\*|\*\* \*\*|\*
```
*x*X = *x*1*, **x*2*, . . . , **x**l** *，*l** *= X ，可用如下表格来完全描述该函数，穷举法
  部分描述
  
```
\*∈\*\*∈\*
```
给定某些输入 *x*X, 输出 *y*Y, 可用如下表格来说明函数的部分对应关系，其中
  *m **&lt; **|*X*|*


      
```
|       |                      |
|-------|----------------------|
|\*x\*    |\*y \*= \*f\*(\*x\*)        |
|\*x\*1   |\*y\*1 = \*f\*(\*x\*1)      |
|\*x\*2   |\*y\*2 = \*f\*(\*x\*2)      |
|\*. . .\*|\*. . .\*               |
|\*x\*\*l\* |\*y\*\*l\*\* \*= \*f\*(\*x\*\*l\*)|


```

```
|       |                    |
|-------|--------------------|
|\*x\*    |\*y \*= \*f\*(\*x\*)      |
|\*x\*1   |\*y\*1 = \*p\*(\*x\*1)    |
|\*x\*2   |\*y\*2 = \*p\*(\*x\*2)    |
|\*. . .\*|\*. . .\*             |
|\*x\*\*m\* |\*y\*\*m \*= \*p\*(\*x\*\*m\*)|


```



假设输入是一个向量，不妨设 *X *= (*X*1*, **X*2*, . . . , **X**n*)，第 *i *个分量的值域大小记为 *|**X**i**|*, 其第 *j *个取值为 *v**ij** *，则如下表格完全表示一个函数：

|              |              |       |                  |                                      |
|--------------|--------------|-------|------------------|--------------------------------------|
|*X*1          |*X*2          |*. . .*|*X**n*            |*f*(*X*1*, **X*2*, . . . , **X**n*)   |
|*v*11         |*v*21         |*. . .*|*v**n*1           |*y*1                                  |
|*v*11         |*v*21         |*. . .*|*v**n*2           |*y*2                                  |
|*. . .*       |*. . .*       |*. . .*|*. .** **.*       |*. .** **.*                           |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|*y**\|**X*1*\|\|**X*2*\|**...**\|**X**n**\|*|

  Table: *n *元函数的表示

  ![](media/image4.png)思考：函数耗费的存储空间是多少？ 随列数指数增加！


为描述/说明/定义一个函数，我们耗费了多少空间？
  ![](media/image6.png)决定因素 1：列数 *n*
  ![](media/image7.png)决定因素 2：每列的值域大小，*m*1*, **m*2*, . . . , **m**n*
  ![](media/image7.png)存储空间需求：*O*(*m*1 *× **m*1 *× **. . . **× **m**n*)
一个类似天气预报的现实问题有多复杂？
  ![](media/image6.png)![](media/image4.png)我们认为天气预报是个包括“建模”，“模型求解”和“模型使用”三步的过程：建模：由人来确定有哪些列（包括列数），通常认为列越多，考虑的因素越多，预报准确性越高；重要的、相关的列越多，预报准确性越高；每个列的值精度越高
  （值域越大），预报准确度越高；（模型被想象成表格）；
  ![](media/image6.png)模型求解：填入已知样本数据到表格中，把剩余的未知的样本数据补上
  ![](media/image6.png)模型应用：依据输入，选择表格的某一行，在此行中找到对应的最佳行动 *y**∗*
  模型求解和模型应用中，如果模型被想象成表格，时间复杂度？空间复杂度？如     果行动是一个序列，其时空复杂度？


计算机求解问题，永恒的主题就是考虑算法的每个步骤和过程的时空复   杂度。
AI 的主要研究问题
  ![](media/image6.png)建模：人手工来做，凭借经验，受制于数据（主要是表格的列）的获取手段（仪器设备，如传感器等）；给定一个数据集，其实此时问题模型已经建好；能让机器自动做吗？复杂性在那儿？
  ![](media/image7.png)模型求解：学习问题，获得最优的完整的表格描述，即函数 *f** *的表示；这就是人工智能中的学习问题；如何简化表格表示及获得对应  的参数？深度学习。时空复杂性？
  ![](media/image4.png)模型应用：搜索问题。找到表格的特定行，及环境的最佳应对行动；  当要找表格的若干行，并连成序列，构成动作序列时，考虑到每个最优动作不一定构成最优动作序列，例如自动驾驶。2006 年以来的蒙特卡罗树搜索。时空复杂性？


奥卡姆剃刀原理：Ockham’sRazor
  ![](media/image4.png)14 世纪逻辑学家、圣方济各会修士奥卡姆的威廉（William of Occam，约 1285 年至 1349
  年）提出；
  ![](media/image7.png)![](media/image7.png)“如无必要，勿增实体”； “简单有效原理”；
  ![](media/image7.png)“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情。”
  ![](media/image6.png)![](media/image6.png)如果对于同一现象有两种不同的假说，我们应该采取比较简单的那一种；    吝啬定律 (Law of parsimony)，或者称为朴素原则；
  ![](media/image7.png)牛顿提出的一个原则：如果某一原因既真又足以解释自然事物的特性，则我们不应当接受比      这更多的原因；
  ![](media/image7.png)莱布尼兹的“不可观测事物的同一性原理”；
  ![](media/image5.png)管理企业制定决策时，应该尽量把复杂的事情简单化，剔除干扰，抓住主要矛盾，解决最根      本的问题，才能让企业保持正确的方向；
  ![](media/image4.png)爱因斯坦的一句著名的格言：万事万物应该都应尽可能简洁，但不能过于简单。


最小描述长度
  ![](media/image4.png)![](media/image29.png)1978 年由 Jorma Rissanen 引入； 卡姆剃刀形式化后的一种结果；
  ![](media/image30.png)在给予假说的集合的情况下，能产生最多资料压缩效果的那个假说  是最好的；
  ![](media/image7.png)任一资料集/数据集都可以由一有限（譬如说，二进制制的）字母集内符号所成的字串来表示。” 最小描述长度原则背后的基本想法是： 在任一给定的资料集内的任何规律性都可用来压缩。亦即在描述资料时，与逐字逐句来描述资料的方式相比，能使用比所需还少的符号”（Grünwald, 1998）；
  ![](media/image7.png)我们希望选取到的假说能抓到资料中最多的规律，于是我们则寻找  压缩效果最佳的假说。


柯尔莫哥洛夫复杂性
  ![](media/image7.png)![](media/image7.png)描述程序的复杂性, Kolmogorov-Chaitin complexity, stochastic complexity, 算法熵; 资料集/数据集可以看成是字符串;
  ![](media/image6.png)![](media/image7.png)程序代码可以看成是字符串; 一段语言可以看成是字符串;
  ![](media/image7.png)资料集的字符串 s 可以找到内在规律后，用一个较短的程序压缩，执行该程序就会输出字符串 s;
  ![](media/image30.png)所有的能输出字符串 s 的程序中，最短程序的长度称为“柯尔莫哥洛夫复杂性”，柯氏复杂性;
  ![](media/image7.png)衡量描述一个对象所需要的信息量的一个尺度;
  ![](media/image7.png)不同程序设计语言，同一功能的程序代码长度会不一样，一般给定程序设计语言     来进行后续讨论。



评价标准
  ![](media/image7.png)![](media/image7.png)完备性：能否对任意输入，给出对应输出？ 描述长度：
      ![](media/image31.png)表格描述具有最大复杂度；
      ![](media/image31.png)解析表示通常具有较小复杂度，解析式的参数个数可以作为解析式  复杂度的度量，如多项式函数的系数向量；
      ![](media/image32.png)柯尔莫哥洛夫复杂性用于计算机科学中，用来比较函数的“程序代码   描述”的复杂性。
  ![](media/image30.png)准确性：函数近似表示或逼近时，需要用到。学习问题就是找函数  的近似表示。


AI：从函数的观点来学习
  ![](media/image6.png)如何获得函数 *f *=*⇒ *机器学习
  ![](media/image6.png)如何使用函数 *f *=*⇒ *推理和问题求解
基于计算机的高级问题求解方法
  ![](media/image7.png)高级数据结构：复杂问题从现实抽象成计算机的图结构描述（增加时空复杂度约束），表格的简化表示；
  ![](media/image6.png)高级算法设计：复杂问题的求解算法，如图遍历（增加时空复杂度  约束）
  ![](media/image6.png)数据库技术的扩展：用数据库的语言来处理和解决部分问题；
  ![](media/image7.png)......
#### 统一到“函数”这个出发点

![](media/image1.png)



  **人工智能讲义**
  **函数的输入与客观世界的状态描述方法**


  February  20, 2020

### ****Outline
  
```
\*\*1\*\*
```
[函数的输入]()
  
```
\*\*2\*\*
```
[用状态向量来描述客观世界]()


AI 在实践中的定位
  ![](media/image33.png)是计算机应用技术的基础
  ![](media/image6.png)包括描述问题、解决问题的一整套方案

为了用计算机解决实际问题，那就要编程，编程的首要任务是数据结构   设计。对应就是 Agent 的数据结构设计，要回答问题：
函数 *f *的输入是什么？
AI 的核心任务
  ![](media/image7.png)![](media/image6.png)设计和制作 Agent，即函数 *f *在机器人内部表示出来函数 *f *的输入，通常是 *n *维的向量
  ![](media/image6.png)*n *很大时，函数 *f *的发现问题也被称之为大数据分析

函数的表示
  ![](media/image6.png)写成形式 *y *= *f*(*x*1*, **x*2*, . . . , **x**n*)，输入信息用向量 (*x*1*, **x*2*, . . . , **x**n*) 来描述
  ![](media/image6.png)其中 *x**i**, **i *= 1*, *2*, . . . , **n *可以是各种类型的标量或向量，比如实数、字符、字符串、序号等等
  ![](media/image7.png)比如，一幅图像，输入到函数 *f*，其自变量就是 *n *个像素点，每个像素的色彩信息，可以是整数值，也可以是 RGB 三种色彩的信息
  ![](media/image5.png)函数的输出 *y *通常简化成标量、整数甚至是最简单的真假（或 0 *− *1）
描述世界的方法
  ![](media/image7.png)![](media/image7.png)把我们对这个客观世界感兴趣的部分用向量描述出来这是一种通用的描述方案
  ![](media/image6.png)比如，描述一个苹果，可以是一张图片，也可以是苹果的颜色，形状，糖分，水分    等物理化学性质构成的向量，也可以是基因序列。这些描述可能看上去不是一个向量，但是，我们总是可以手工或用某种程序把客观世界（包括物体和事件）转换为“实数向量”
  ![](media/image7.png)![](media/image5.png)获得客观事物实数向量描述的过程，称为“特征提取”或者是“表征学习” 因此，我们课程假设描述客观世界的方式就是 *n** *维的实数向量，也恰好是表示agent 的函数 *f** *的输入

![](media/image1.png)



  ***人工智能讲义***
  ***问题求解：搜索***


  March 3, 2020

### ****Outline
  
```
\*\*1\*\*
```
[搜索的定义]()
  
```
\*\*2\*\*
```

```
\*\*3\*\*
```
[搜索问题的例子]()[搜索问题的理解]()
  
```
\*\*4\*\*
```

```
\*\*5\*\*
```
[如何将具体问题转化为搜索问题]()[搜索算法设计]()


给定一个图 G = (*V**, **E*)
  ![](media/image7.png)指定起点/源点为 *I*，终点/目标为 *G *时：
  ![](media/image7.png)![](media/image7.png)若边无权或边权都相等时，求 *I *到 *G *的最短路径，即边数最少的路径。若边上有不完全相同的权值，求 *I *到 *G *的最短路径，即路径上边权值和最小的路径。
  ![](media/image5.png)来自数据结构课程的结论：
      ![](media/image32.png)Dijkstra 算法：计算节点 *I *到其他所有节点的最短路径。主要特点是以起点 *I *为中心向外层层扩展，直到扩展到终点为止。时间复杂度 *O*(*n*2)
      ![](media/image31.png)Bellman-Ford 算法：单源负权边，时间复杂度 *O*(*ne*)
      ![](media/image35.png)Floyd 算法：多源，时间复杂度 *O*(*n*3)，空间复杂度 *O*(*n*2)
添加新的约束条件，获得新问题
  ![](media/image5.png)![](media/image5.png)![](media/image7.png)算法时间复杂度为  *O*(*p*(log *n*))，其中  *p*( · )  表示多项式函数。WHY？现实中大量问题，图的节点数目非常多，是问题规模的指数函数。   算法？AI 中的搜索算法！不能/无法遍历所有的节点。
  ![](media/image7.png)所以我们说 AI 中的搜索就是有时间约束的最短路径问题。


                    ![](media/image36.png)![](media/image7.png)搜索：基于“状态”的定义状态空间：S
                    ![](media/image7.png)后继函数：*successors *: S *→ *2S
                    ![](media/image6.png)![](media/image6.png)初始状态/初态：*s*0 目标测试：
                    *GOAL *: S *→** **{**T**, **F**}*
                    ![](media/image7.png)路径耗散/arc cost：

搜索问题的五要素
  ![](media/image6.png)上述五个组成要素，描述了一个搜索问题。





                    ![](media/image37.jpeg)用状态图来描述搜索问题
                      ![](media/image18.png)每个节点表示一个状态
                      ![](media/image19.png)![](media/image23.png)弧及其两个端点表示后继函数可能包括多个不连通的分量
                      ![](media/image23.png)标注上初态 *I *和终态 *G*，如图所示



                    ![](media/image37.jpeg)路径与最短路径
                      ![](media/image5.png)如图所示
                      ![](media/image38.png)解：从初始节点 *I *到任何目标节点 *G *的一条路径, 沿箭头方向;
                      ![](media/image7.png)最优解：解是路径，可能存在多条从 *I *到 *G *的路径，最优解就是路径耗散 (路径上 cost 之和） 最小的路径


            ![](media/image39.png)

无解的情况
  ![](media/image6.png)如图所示
  ![](media/image5.png)表示初态和终态的节点在不连通的两个分量中。


        ![](media/image40.jpeg)

```
\*⇒\*
```
三国华容道 =搜索问题
  ![](media/image7.png)棋盘的任意一种布局就是一个状态，是状态图中的一个节点，所有可能的的布局构成状态空      间/状态图的顶点集；
  ![](media/image7.png)![](media/image7.png)从棋盘的一种布局“合法地”移动一个旗子，得到另一种布局，即所谓的“后继函数”；任何一种初始布局可为初态，曹操跑出来为终态；
  ![](media/image7.png)每移动一个棋子，路径耗散为 1；
  问题的解：从初态到终态的一个移动序列；最优解：路径耗散/移动次数最少的移动序列。
问题：状态空间有多大？即多少个不同状态？


  ![](media/image41.jpeg)


  ![](media/image42.jpeg)

数码游戏
  ![](media/image7.png)Introduced in 1878 by Sam Loyd
  ![](media/image7.png)dubbed himself “America’s greatest puzzle-expert”
  ![](media/image7.png)
```
\*×\*\*−\*
```
将 *n**   **n *的方格棋盘中的 1*, *2*, . . . , **n*2    1 数字从某个给定的布局调整到另一个给定的布局；棋盘中只有一个空格，调整时，只能把空  格“边相邻”的数字移动到空格中。
  ![](media/image5.png)右上图是一个悬赏，过去 100 多年了，至今无人领取。


  ![](media/image42.jpeg)

数码游戏 =*⇒ *搜索问题
  ![](media/image7.png)每个棋盘布局是状态/节点；
  ![](media/image7.png)![](media/image6.png)移动某个数字到空格是后继函数； 初态和终态给定；
  ![](media/image6.png)路径耗散，单步为 1。
  ![](media/image6.png)搜索问题的解：一个从初态到终态的移动序列。
问题：状态空间有多大？即多少个不同状态？


        ![](media/image43.png)

8 皇后问题
  ![](media/image7.png)
```
\*×\*
```
在 88 的国际象棋棋盘上，寻找放置 8 个相互不能攻击到的皇
  后。（注：皇后的攻击路线是直线和 45 度斜线）；
  ![](media/image7.png)![](media/image38.png)上图展示了一个正确的放置 8 皇后方法和一个错误的放置方法； 问题扩展：在 *n **× **n *的棋盘上放置 *n *相互不能攻击到的皇后。


          ![](media/image43.png)

*n *皇后问题 =*⇒ *搜索问题
  ![](media/image44.png)![](media/image7.png)任意放置 *n *个皇后的棋盘布局就是一个节点/状态； 任意一个皇后移动到相邻的方格，定义为后继函数；
  ![](media/image6.png)初态为任意给出的一个棋盘布局；终态为满足相互攻击不到的棋盘布局（不是某个特殊的棋盘布局，而是满足某些条件的棋盘布局为终态）；
  ![](media/image6.png)路径耗散：一次移动皇后到相邻格子，代价为 1.
  ![](media/image6.png)搜索问题的解：从初态到终态的移动序列。（其实 *n *皇后问题不需要对解要求这么多，仅给出终态即可）
问题：状态空间有多大？即多少个不同状态？


            ![](media/image45.png)
数独游戏
  ![](media/image46.png)数独起源于 18 世纪初瑞士数学家欧拉等人研究的拉丁方阵（Latin Square）
  ![](media/image6.png)20 世纪 70 年代，人们在美国纽约的一本益智杂志《Math Puzzles and Logic Problems》上发现了这个游戏
  ![](media/image7.png)数独盘面是个九宫，每一宫又分为九个小格。在这八十一格中给出一定的已知数字，在其他      的空格上填入 1-9 的数字。使 1-9 每个数字在每一行、每一列和每一宫中都只出现一次。
  ![](media/image7.png)世界数独锦标赛：首届于 2006 年在意大利卢卡举办，第八届于 2013 年在北京举办


            ![](media/image45.png)

```
\*⇒\*
```
数独游戏 =搜索问题
  ![](media/image7.png)状态为某个棋盘布局；要求棋盘不会产生“冲突”；
  ![](media/image6.png)后继函数就是在棋盘上的某个空格填上一个数字；使得棋盘是合法的；
  ![](media/image46.png)![](media/image46.png)初态为初始时刻给出的棋盘布局；终态为填满 81 个数字，且符合要求的布局； 路径耗散：每填写一次数据，代价为 1（忽略删除某个方格内数字的代价）；
  ![](media/image7.png)数独问题的解：从初态到终态的一个填写数字序列。（数独问题的解可以忽略过程，仅包含      符合要求的终态即可）。


状态
  ![](media/image7.png)![](media/image7.png)事物可能的抽象表示，关键属性上相同，不重要细节的影响可以忽略不计    比如棋盘的布局，棋子偏移 1 毫米，对布局/状态没有影响
  ![](media/image7.png)状态空间是离散的，有限或者无限
![](media/image47.jpeg)
构建“好的”状态空间
  ![](media/image46.png)状态数目通常随问题规模指数增加；
  ![](media/image7.png)![](media/image7.png)*n *皇后的例子表明，不同的状态定义方法，影响状态空间的大小。存在大量“不可达/违背约束”的状态！能否尽可能减少它们？


  ![](media/image48.png)


                      ![](media/image49.jpeg)Sam Loyd 不用担心钱被领走！
                          ![](media/image50.png)逆序值: 每个数被逆序的次数之和 + 空格所在行与目标状态空格行行号差（*n *为偶数时加上该项）
                          ![](media/image51.png)逆序值的奇偶性不会被后继函数改变
                          ![](media/image52.png)整个状态图分为两个不联通分量，分别对应逆序值的奇与偶


“好的”状态/状态空间
  ![](media/image46.png)![](media/image46.png)所有状态？尽可能让状态都是可达的/可行的/合法的； 状态数目越少越好，通常是问题规模的指数函数；
  ![](media/image7.png)能方便设计后继函数和搜索算法。

进一步解释
  ![](media/image6.png)不可达的状态，在搜索问题无解时非常重要；
  ![](media/image6.png)状态太多时，计算机存储空间无法存储所有的状态（空间受限）；也无法遍历一遍（时间受限）；
  ![](media/image7.png)从数据结构的角度看：搜索算法的简洁性和高效性，约束状态空间  和后继函数的设计。



                    ![](media/image53.jpeg)后继函数：状态图的边
                      ![](media/image19.png)如左图所示数独求解器的例子。
                      ![](media/image24.png)每个状态可行的所有“行动”的集合，方格内左上角小写的数字
                      ![](media/image19.png)后继函数的返回值，就是行动的结果，称之为后继状态
                      ![](media/image18.png)左图表示状态，其后继函数会导致 138 个不同的后继状态
                      ![](media/image18.png)后继函数是问题建模（现实问题转换为搜索问题）的“关键”！最复杂的部分。


路径耗散
  ![](media/image5.png)通常标注在状态图的边上，表示执行一个行动/动作的花费/代价，可以认为是后继函数的执行代价；
  ![](media/image7.png)也可以认为是一种“奖励”，执行完动作后获得的 reward，但是此时最优解通常对应最大化行动序列获得的奖励之和；
  ![](media/image7.png)一般总是正的；
  ![](media/image6.png)而且我们总是假设路径耗散 *c**i *有一个有限的下界，即大于某个正常数 *c**i **≥ **ϵ &gt; *0
路径耗散的例子
  ![](media/image7.png)数码问题，每移动一次，代价为 1;
  ![](media/image7.png)*n *皇后问题，每放置/撤回一个皇后，代价为 1，从一个状态转移到下一个状态， 花费的代价 *≤ *2*n*;
  ![](media/image7.png)数独问题，填写/擦除一个数字，代价各为 1，从一个状态转移到下一个状态，花费的代价 *≤ *2*n*



初态：单源或多源
  ![](media/image6.png)![](media/image6.png)给出某个状态，并精确地描述出来；如三国华容道，数独问题等；  给出某些状态，它们满足某些共同的性质或条件；
  ![](media/image5.png)仅仅给出某些条件或性质，称满足条件的都是合法的初态，如初始  随机放置 8 个皇后的 8 皇后问题，条件是“有 8 个皇后存在”。

终态
  ![](media/image46.png)![](media/image5.png)可以是一个被精确定义的状态可以是满足某些条件的状态
  可以是满足某些条件的状态集合


  ![](media/image7.png)解：从初态到终态的路径可能有唯一解
  ![](media/image7.png)可能无解
  ![](media/image7.png)可能有多个解，路径耗散最小的称之为“最优解”

解的约束太强了，有些问题可以放松约束
  ![](media/image46.png)很多问题，我们需要解表示的行动序列，比如下棋；
  ![](media/image46.png)然而，如 8 皇后问题，我们并不关心如何从初态调整到终态的过程， 仅仅需要最终的棋盘布局，即终态；因此，可以只要解序列的最后一个状态即可，降低了对解的要求；
  数独问题，对解的要求类似 8 皇后问题，这类问题即通常所谓的“约束满足问题”。


  ![](media/image55.jpeg)
AI 和数据结构
  ![](media/image7.png)数据结构：更侧重在通过程序设计实现从逻辑模型到存储模型 (物理模型） 的转换；数据结构的设计应以程序设计实现的简洁和高效为指导。
  ![](media/image5.png)AI：更多地讨论如何将现实世界建模为逻辑模型，将更复杂的现实问题转  化为各种受限的、带约束的逻辑模型。


    ![](media/image56.png)

建模和编程
  ![](media/image6.png)![](media/image6.png)建模：编码状态/棋盘布局，编码可行的移动，利用基本数据结构数组和树等； 编程实现：在线性内存空间上实现


  ![](media/image57.png)
8 皇后问题的形式化 1：现实问题建模为搜索问题
  ![](media/image6.png)![](media/image6.png)状态，任何 0，1，2，……,8 个皇后在棋盘上时的布局代表一个状态初始状态：0 个皇后在棋盘上
  ![](media/image7.png)![](media/image46.png)目标测试/目标状态：8 个皇后在棋盘上，彼此间不互吃路径耗散：放置一个皇后，代价为 1
  ![](media/image58.png)![](media/image59.png)后继函数：在一个空的格子上放置一个皇后，得到一个新状态  状态空间/状态图：高度为 9 的 64-叉树
约 64 *× *63 *× **. . . **× *57 ∽ 3 *× *1014 states


  ![](media/image60.png)
8 皇后问题的形式化 2：现实问题建模为搜索问题
  ![](media/image7.png)状态，任何 0，1，2，……,8 个皇后在棋盘左侧，且互不攻击时代表一个状态；所谓棋盘左侧互不攻击，就是前 k 列每列一个皇后，互不攻击；
  ![](media/image7.png)初始状态：0 个皇后在棋盘上；
  ![](media/image7.png)![](media/image7.png)目标测试/目标状态：8 个皇后在棋盘上； 路径耗散：放置一个皇后，代价为 1；
  后继函数：在 k+1 列放置第 k+1 个皇后到一个不受攻击的位置； 状态数目急剧减少！
约 2057 states



  ![](media/image61.png)当                                          *n                                              *增 大 时“解”是一个状态，而非从初始态到目标状态的序列；这类搜索问题，一般称为“设计问题”，学术上称为“约束满足问题”；
  ![](media/image62.png)上述形式化方法 2 是否能“简单”求解 N 皇后问题？
      ![](media/image31.png)8 皇后 *→ *2057 个状态
      ![](media/image31.png)100 皇后 *→ *1052 个状态
  ![](media/image7.png)能否有算法能快速求解 N 皇后问题？
      ![](media/image31.png)![](media/image31.png)问题特点：很多个解，解的分布较好（较均匀） 爬山法


      ![](media/image63.png)

路径规划问题形式化：把现实问题转化为搜索问题
  ![](media/image7.png)如上图所示场景，有不可触碰的障碍物 (咖啡色所示)，可能是游戏地图， 可能是汽车自动驾驶地图等；
  ![](media/image7.png)红点是出发点，绿点是目标终点；
  ![](media/image62.png)寻找一条从红点到绿点的路径，或最短路径。


      ![](media/image64.png)

路径规划问题形式化 1：网格化
  ![](media/image6.png)如上图所示，把地图网格化；
  ![](media/image62.png)令网格边长为 1，则对角线距离为 *√*2；
  ![](media/image62.png)状态就用当前位置的坐标 (*x**, **y*) 来表示，所有的整数点坐标值构成状态空间；
  小方格的边为后继函数，后继状态是当前状态的东南西北四个正方向上，距离为 1；
  也可以定义后继函数包括四条 45 度对角线，即后继状态在当前状态周围最近的 8 个整数坐标位置上。


      ![](media/image65.png)

路径规划问题形式化 1：网格化
  ![](media/image6.png)解是一个序列，相邻整数点/状态之间距离 *≤ **√*2，如上图所示
  ![](media/image6.png)最优解，仅仅是网格化的离散空间中的最优解


        ![](media/image66.png)

路径规划问题形式化 2：扫描线方法
  ![](media/image6.png)假设垂直扫描线从左到右进行扫描；
  ![](media/image7.png)![](media/image7.png)![](media/image62.png)遇到障碍物的顶点（不妨设障碍物为多边形）则暂停，标记； 标记方法：对两次暂停之间的被扫描区域染上不同的颜色； 被障碍物割裂的扫描线获得不同颜色的区域。


      ![](media/image67.png)

路径规划问题形式化 2：扫描线方法
  ![](media/image6.png)如上图所示，扫描整个区域后，得到彩色的着色图。


      ![](media/image68.png)

路径规划问题形式化  2：扫描线方法
  ![](media/image7.png)每个染色区域用其重心点作为代表
  ![](media/image7.png)每个重心点代表一个状态，获得状态空间
  ![](media/image7.png)如上图，共有 11 个不同色彩区域，即 11 个不同状态，初始位置和目标位
  置视为额外的两个状态，共 13 个状态。


      ![](media/image69.png)

路径规划问题形式化 2：扫描线方法
  ![](media/image7.png)![](media/image6.png)后继函数：具有相邻边界线的色块之间互为后继获得状态图，如上图所示
  ![](media/image6.png)边/弧的路径耗散/代价为状态点之间的距离，如欧拉距离


      ![](media/image70.png)

路径规划问题形式化  2：扫描线方法
  路径规划问题的解为一条路径，如上图所示路径需要通过某些特定的边界点
  最优路径需要进一步优化和平滑


      ![](media/image71.png)
路径规划问题形式化 3：障碍物边界法
  ![](media/image7.png)取障碍物（不妨设为多边形）的顶点以及初始地点和目标地点构成图的顶点； 对任何顶点，连接其可视顶点（没有被障碍物阻挡），获得后继函数;
  路径耗散/代价：边/弧的长度，顶点间的距离。


      ![](media/image72.png)

  ![](media/image7.png)路径规划问题形式化 3：障碍物边界法路径规划问题的解，如上图所示最优解是连续的


  ![](media/image6.png)赫伯特 · 西蒙：设计实验证明人类解决问题的过程是一个搜索过程路径搜索与导航
  ![](media/image7.png)打包/邮件分发
  ![](media/image7.png)![](media/image7.png)超大规模集成电路布局设计蛋白质比对和折叠
  ![](media/image7.png)制药
  ![](media/image7.png)电脑游戏
  ![](media/image62.png)……

  思考：现实问题建模成通用的“搜索问题”（描述其 5 个要素）。
#   模型 =*⇒ *编程求解*/*算法设计运行


      ![](media/image73.jpeg)

算法思想：利用图的宽度优先遍历算法
  ![](media/image6.png)如上图所示状态图如左，表示一个搜索问题，红点为初态，进行宽  度优先遍历，得到右图的搜索树/生成树
  ![](media/image7.png)我们称宽度优先遍历为求解搜索问题的基准算法，简称为宽度优先  搜索算法


                    ![](media/image74.png)与基准算法对比
                      ![](media/image18.png)仅仅搜索整个状态图的一小部分
                      （状态数的对数多项式量级）就能获得解或最优解
                      ![](media/image18.png)其它算法与基准算法比，相同点：
                        ![](media/image31.png)算法大框架基本一致
                        ![](media/image32.png)所有的状态（可达 + 不可达）构成的状态图
                        ![](media/image17.png)其它算法与基准算法比，不同点：
                        ![](media/image31.png)从状态图中选择/处理的状态子集不一样
                        ![](media/image31.png)状态子集构成的状态子图（弧）不一样，后继函数定义不一样


    ![](media/image75.jpeg)

搜索算法：从状态图到搜索树
  ![](media/image6.png)左边的状态图描述了一个搜索问题
  ![](media/image7.png)![](media/image7.png)右边是在状态图上进行搜索，求解搜索问题（获得路径或最短路径）  注意：状态图中的节点/状态可能被重复访问，体现在同一节点/状态会变成搜索树的多个节点


      ![](media/image76.png)

数码游戏的搜索树
  ![](media/image7.png)如上图所示，8 数码问题的搜索树的一部分
  ![](media/image6.png)搜索树的根节点（蓝色）和最右下角的红色节点，棋盘布局一样，是同一个状态 (状态图的同一个节点)
  ![](media/image7.png)同样的状态，在树中可能有多个节点表示；我们在后面的讲解中区分二者
  ![](media/image62.png)若允许状态被重复访问，即搜索树中同一状态可用多个节点描述，则搜索树可能是无限深的


      ![](media/image77.jpeg)

求解问题，有了模型（逻辑结构，状态图）之后，设计数据结构
  ![](media/image5.png)节点 N 信息包括（深度，路径代价，是否已扩展），其中深度/Depth 就是节点 N 的（从根开始）路径长度，路径代价就是从根开始的路径耗散，节点扩展是对节点的一个操作，若完成扩展操作，则标注为 yes
  通常初始状态为搜索树的根，其深度为 0


                    ![](media/image78.png)搜索算法核心操作：节点扩展
                      ![](media/image19.png)生成搜索树的关键操作；
                      ![](media/image23.png)节点扩展直观理解就是把一个节点用它的后继节点（集合） 来替换；
                          ![](media/image79.png)![](media/image80.png)节点 N 的扩展，包括的处理： 评估状态/状态图节点 N 的后继函数，如到该状态的路径耗散是多少，估计从该状态到目标状态至少还要花费多少路径耗散等等；
                          ![](media/image31.png)对后继函数返回的所有后继状态，在搜索树上分别产生一个子节点与之对应。
                      ![](media/image18.png)节点扩展 *̸*= 节点产生


      ![](media/image81.png)

搜索树的边界：FRINGE
  ![](media/image7.png)如上图中“云”中的那些状态（或搜索树中的节点）
  ![](media/image7.png)![](media/image6.png)未扩展状态的集合，可理解为：在排队等待扩展的那些状态！ 与叶节点不同，叶节点可能已经扩展过了，但是没有子节点；
  ![](media/image7.png)未扩展状态在搜索树上的节点，因为未扩展，所以还没有子节点，看上去“像”叶节点。



搜索策略：FRINGE 中节点的优先次序
  ![](media/image7.png)![](media/image7.png)![](media/image7.png)FRINGE 中的节点是已访问过/处理过状态的后继节点中未扩展的； 通常用“队列”来存储 FRINGE 中的对象；（先进先出是队列的特点）但是我们修改“队列”的存储方式，重新定义一个 FRINGE 中节点的优先数组/有序数组，得到一个“搜索策略”。
      ![](media/image7.png)![](media/image31.png)影响/设计实现搜索策略的核心操作：（类似队列操作） INSERT(node,FRINGE) : 向优先数组 FRINGE 中插入优先级最低的节点 node;
  ![](media/image31.png)REMOVE(FRINGE): 从优先级数组中删除优先级最高的节点。


搜索算法框架: 基准算法
**Input: **G: 状态图; *s*0 : 初态;
**Output: ***path*: 代表解的路径

```
\*←−\*\*←−\*
```
*path*(*s*0 )*, **FRINGE**ϕ** */\* 初始化 \*/;
  **if **(*GOAL*(*s*0 ) = *T**) ***then return ***path *= (*s*0 );
**end**
INSERT(*s*0 *, **FRINGE*);
**while ***T ***do**
||                                                                                                                                                                                                                                                                                                                                                                                                             |
||-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
||**if ***empty*(*FRINGE*) == *T ***then**  **return ***failure */\* 返回 *failure*, 表示无解 \*/;**end**                                                                                                                                                                                                                                                                                                      |
||*N** **←**−*REMOVE(*FRINGE*) /\* 将未扩展节点中队头节点从队列移除到 *N*\*/;*s** **←**−*STATE(*N*) /\* 从节点 *N** *恢复为状态 *s*\*/;节update *path*;**foreach ***s**′  **in** **successors*(*s*) **do**点  为 *s**′ *创建 *N *的新子节点 *N**′*;  **if ***GOAL*(*s**′*) = *T** ***then**扩    **return **(*path**, **s**′*)/\* 找到目标节点，返回解 \*/;  **end**展  INSERT(*s**′*,*FRINGE*);**end**|

**end**


完备性
  ![](media/image82.png)![](media/image83.png)问题有解时，算法能否保证返回一个解？ 问题无解时，算法能否保证返回 failure？
最优性
  ![](media/image7.png)能否找到最优解？
  ![](media/image6.png)返回代价/路径耗散最小的路径？
复杂性: 算法需求的时间和内存
  ![](media/image6.png)![](media/image7.png)搜索树的大小：初态、后继函数和搜索策略决定，影响因素：分支因子（后继的最大个数），最浅目标状态的深度，路径的最大长度时间复杂度：访问过的节点数目
  ![](media/image7.png)空间复杂度：同时保存在内存中节点数目的最大值



算法设计的根本目标：解决问题
  ![](media/image7.png)很多搜索问题是 NP-hard，比如 TSP，数码问题，求解时间是问题规模的指数函数；
  ![](media/image7.png)![](media/image5.png)因此，别期望能在多项式时间内（时间复杂度是问题规模的多项式函数）求解出问题的所有实例（instances），目前没有通用算法！没有免费的午餐定理表明：任意一个算法在所有问题实例上的平均  性能是相同的。
  ![](media/image83.png)算法设计的意义：对每个 instance/每类 instances 找到其最有效
  （尽可能高效）的求解算法。



####   搜索问题求解算法






    盲搜索算法


      有信息搜索 算 法
    变型搜索问题的搜索 算 法

![](media/image1.png)



  **人工智能讲义**
  **盲搜索**


  March 3, 2020

### ****Outline
  
```
\*\*1\*\*
```
[基准算法]()
  
```
\*\*2\*\*
```
[基准算的各种改进]()


搜索算法框架: 基准算法
**Input: **G: 状态图; *s*0 : 初态;
**Output: ***path*: 代表解的路径

```
\*←−\*\*←−\*
```
*path*(*s*0 )*, **FRINGE**ϕ** */\* 初始化 \*/;
  **if **(*GOAL*(*s*0 ) = *T**) ***then return ***path *= (*s*0 );
**end**
INSERT(*s*0 *, **FRINGE*);
**while ***T ***do**
||                                                                                                                                                                                                                                                                                                                                                                                                             |
||-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
||**if ***empty*(*FRINGE*) == *T ***then**  **return ***failure */\* 返回 *failure*, 表示无解 \*/;**end**                                                                                                                                                                                                                                                                                                      |
||*N** **←**−*REMOVE(*FRINGE*) /\* 将未扩展节点中队头节点从队列移除到 *N*\*/;*s** **←**−*STATE(*N*) /\* 从节点 *N** *恢复为状态 *s*\*/;节update *path*;**foreach ***s**′  **in** **successors*(*s*) **do**点  为 *s**′ *创建 *N *的新子节点 *N**′*;  **if ***GOAL*(*s**′*) = *T** ***then**扩    **return **(*path**, **s**′*)/\* 找到目标节点，返回解 \*/;  **end**展  INSERT(*s**′*,*FRINGE*);**end**|

**end**




  
```
Uninformed/ Blind
```

```
VS
```

```
Informed/Heuristic
```


                        FRINGE 是无序的将更有希望的节点放在未扩展节点集合
                      FRINGE 的前面，优先扩展



![](media/image90.png)盲搜索和启发式搜索
![](media/image91.png)如左图所示例子：
                        ![](media/image92.png)盲搜索：*s*1 和 *s*2 的次序是“随机的”，树的结构确定 的，在算法实现时预先“确定”下来的
                        ![](media/image93.png)启发式搜索：状态 *s*2 更接近目标状态（错误位置更少），因此可以优先扩展状态 *s*2



            ![](media/image94.png)

基准算法是盲搜索算法
  ![](media/image7.png)如上图所示的节点扩展过程：
  ![](media/image83.png)新节点/状态插入到未扩展节点队列 FRINGE 的队尾
  ![](media/image83.png)FRINGE = (3, 4, 5) *→ *FRINGE = (4, 5, 6, 7)





  ![](media/image7.png)基准算法：宽度优先搜索算法算法的重要参数:
      ![](media/image31.png)分支因子 *b*，后继函数返回的最大状态数目
      ![](media/image31.png)从初态到目标状态的最小深度 *d*，或者说是宽度优先生成树/搜索树上“埋藏最浅”的目标节点的深度





  基准算法: 评价
#### ![](media/image18.png)完备性？有解时给出解； 无解时告知无解。
    ![](media/image18.png)最优性？返回的是否是路径耗散最小的路径。
    ![](media/image19.png)复杂性？时空代价。
    基准算法评价结论完备的；
    ![](media/image17.png)![](media/image17.png)如果每条边的路径耗散相等，则返回最优解；否则不一定；
    ![](media/image18.png)访问节点数
    
```
\*b\*\*d\*+1\*−\*1\*d\*= \*O\*(\*b\*\* \*)
```
*≤** *1 + *b *+ *b*2 + *. . . *+ *b**d *=
    *b**−*1


      ![](media/image95.png)

  ![](media/image6.png)时间和内存需求的直观认识，如上表，假设： 分支因子：*b *= 10;
  ![](media/image7.png)![](media/image83.png)节点处理速度：1*, *000*, *000*nodes*/*sec*; 节点大小 100*bytes*/*node*



    ![](media/image96.png)

无解时的情况
  ![](media/image7.png)问题无解时，若状态空间无限大或者任意状态可被任意次重复访问，  则宽度优先搜索算法不会停止


      
```
深 度 优先 搜 索
```

```
双向搜索
```

```
回溯算法
```

```
宽度优先搜索
```

```
代 价 一致 搜 索
```

```
深度受限深度优先搜索
```

```
迭 代 深入 搜 索
```



![](media/image111.jpeg)

双向搜索算法
  ![](media/image7.png)分别从初态和终态启动两个宽度优先搜索算法；
  ![](media/image83.png)维护 2 个未扩展节点集合: FRINGE1 和 FRINGE2，分别记录从初态和终态开始搜索的未扩展节点集合；当两个集合相交时，算法结束。
  ![](media/image83.png)时间和空间复杂度是 *O*(*b**d*/2) *&lt;&lt; **O*(*b**d*)（假设两个方向的分支因子都是*b*）;
  ![](media/image6.png)问题: 两个方向的分支因子不一样会怎样?


双向搜索：解释
  ![](media/image6.png)双向搜索，是策略/算法框架的改进，而非“原子的”的搜索算法，双向搜索的两个方向（前向/反向）搜索算法，可以一样，也可以不一样
  ![](media/image7.png)问题：总是能找到“好”的反向搜索算法吗？目标状态是单个精确描述的状态？满足某个条件的状态集合？后继函数的逆函数“前驱函数”能方便地描述或表达吗？（比如象棋的目标状态：获胜的布局，个数？如何描述，等等）
双向搜索：评价
  ![](media/image5.png)时间复杂度：获得极大的优化 *O*(*b**d*/2) *&lt;&lt;** **O*(*b**d*) ，但是“问题本质”（指数时间复杂度）没有变化。这已经是双向搜索带来的明显进步；
  ![](media/image7.png)完备性：完备的；
  ![](media/image7.png)最优性：边的代价都为 1 时，能保证最优性；否则不一定。


    ![](media/image112.png)

深度优先搜索算法
  节点扩展时，新状态/节点总是插入到队列/FRINGE 的“队头”（栈）





评价准则
####   ![](media/image6.png)![](media/image7.png)![](media/image83.png)完备性？有解时给出解；无解时告知无解。最优性？返回的是否是路径耗散最小的路径。复杂性？时空代价。
深度优先搜索算法
  ![](media/image113.png)![](media/image113.png)若搜索树有限，则是完备的； 不一定是最优的；
  ![](media/image113.png)访问节点数（最坏情形）：
  1 + *b *+ *b*2 + *. . . *+ *b**m *= *O*(*b**m*)，空间复杂度 *O*(*bm*)，其中 *m *是叶子节点的最大深度。




回溯法：对深度优先搜索的改进
  ![](media/image83.png)每次扩展节点的时候，只扩展一个节点，节省内存，最多同时保存
  *O*(*m*) 个节点
  ![](media/image7.png)若深度优先搜索树是无限的，则回溯搜索可能是不完备的，也可能  无法得到最优解


深度受限搜索：深度优先搜索的改进
  ![](media/image83.png)![](media/image83.png)设置扩展节点的深度阈值 *k*，当节点深度大于 *k *时，节点不再扩展算法返回结果：
      ![](media/image31.png)解
      ![](media/image31.png)无解 failure
      ![](media/image31.png)深度阈值 *k *内无解

进一步思考与讨论
  ![](media/image7.png)如何容易得到 *k*，算法性能将会得到提升
  ![](media/image7.png)Q: *k *比 *d*(最浅目标状态的深度) 大或小时，会怎样？


迭代深入：当不知到受限深度阈值 *k *时，从小到大一个个试
  ![](media/image83.png)使用不同的受限深度参数 *k *= 0*, *1*, *2*, . . . *不断重复执行“深度受限搜索”；
  ![](media/image5.png)目的：寻找合适的深度受限深度参数 *k *值。

对迭代深入搜索的思考
  ![](media/image7.png)带来的好处：结合了宽度优先和深度优先二者的长处（时空复杂度，  完备性和最优性）
  付出的代价？





评价准则
####   ![](media/image6.png)![](media/image7.png)![](media/image83.png)完备性？有解时给出解；无解时告知无解。最优性？返回的是否是路径耗散最小的路径。复杂性？时空代价。
迭代深度搜索
  ![](media/image113.png)当 *k *= *d *时，是完备的；
  ![](media/image114.png)当单步路径耗散相同时，是最优的；否则不一定；
  ![](media/image114.png)访问节点数（最坏情形）：
  
```
\*−\*\*−\*
```
(*d** *+ 1)(1) + *db** *+ (*d*1)*b*2 + (*d*
  2)*b*3 + *. . . *+ (1)*b**d *= *O*(*b**d*)，空间复杂度 *O*(*bd*)


    ![](media/image115.png)

进一步讨论
  ![](media/image6.png)对未知问题，解的深度未知，付出较小的代价，迭代深入搜索是首  选的盲搜索算法


代价一致搜索：总是优先扩展使得总路径耗散最小的节点
  ![](media/image6.png)基准宽度优先搜索算法，每次在深度最浅的节点中（随机）选择一  个扩展；
  ![](media/image6.png)代价一致搜索：每次在 FRINGE 中选择让目前获得的路径耗散最小的节点扩展，适用于单步路径耗散不同时的情形；
  ![](media/image83.png)![](media/image116.png)当单步路径耗散相同时，代价一致搜索等价于基准算法； 要求单步耗散有下界，即 *c**i** **≥ **ϵ** &gt; *0;
代价一致搜索：讨论
  ![](media/image6.png)路径耗散引导搜索过程；
  ![](media/image7.png)搜索的时空复杂度和 *ϵ *相关；(最坏时 *O*(*b**⌈**C**∗*/*ϵ**⌉*))
  ![](media/image7.png)能保证最优性和完备性，一般来说时空复杂性较基准算法大。



  ![](media/image117.jpeg)


状态被重复访问的产生原因
  ![](media/image7.png)行动可逆，则有可能会出现重复状态，如“三国华容道”；搜索树是无限的
  ![](media/image7.png)行动不可逆，不会出现重复状态，如“8 皇后问题”的形式化方法
  2；搜索树有限
基准算法：避免状态重复访问
  ![](media/image118.png)来自数据结构中的技术：设置一个标识数组，标识状态是否被访问  过/扩展过。
  ![](media/image7.png)若扩展节点得到的后继状态已经被扩展过/访问过，就直接丢弃该状态及其对应节点。

需要多大的存储空间来存放标识数组？


更完善的方法
  ![](media/image118.png)![](media/image118.png)用 CLOSED 表，存储所有访问过（扩展过）的状态未扩展的状态用 OPEN 表来标识
  ![](media/image7.png)若当前待扩展的状态已经在 CLOSED 表中，则丢弃该状态；否则扩展当前状态

OPEN 和 CLOSED 表方法的评述
  ![](media/image6.png)采用该方法避免状态重复访问的算法框架称为“图搜索”算法，直  接探索“状态图”
  ![](media/image7.png)内存需求巨大！
  ![](media/image7.png)最优性如何保证？宽度优先搜索。


      
```
树搜索
```

```
VS
```

```
图搜索
```


  相同与不同
  ![](media/image7.png)树搜索中，不同的节点 *N*1*, **N*2 可能表示的是相同的状态 *s*，分别表示从初态出发，到达状态 *s *的两条不同路径（可能具有不同的路径耗散）
  ![](media/image6.png)图搜索中，相同的状态只有一个节点来表示；不同的节点代表不同  的状态；可以想象成把“树搜索”中具有相同状态的节点合并为一  个节点，得到了“图”
![](media/image7.png)树的“层次遍历”算法类似于图的“宽度优先搜索”遍历算法



代价一致搜索
  ![](media/image7.png)CLOSED 表中保存每个状态的最优路径耗散（从初态出发）
  ![](media/image7.png)若 *s *在 CLOSED 表中，则检查 *s *的代价（从初始状态到 s 的路径耗散），并和当前路径 +*s** *的总路径耗散进行比较，取较小的路径耗散，更新状态 s 的路径耗散；若 *s *不在 CLOSED 表中，则放入CLOSED 中，并开始扩展；
  ![](media/image5.png)![](media/image6.png)将 *s** *的所有不在 CLOSED 表中的后继状态放入 OPEN 表中重复上两步




状态的重复访问与搜索的完备性
  ![](media/image7.png)若状态空间是无限的，一般来说，搜索是不完备的
  ![](media/image7.png)若状态空间有限，但允许状态被任意次重复访问，搜索一般是不完  备的
  ![](media/image5.png)若状态空间有限，访问时重复访问的节点被丢弃，则搜索是完备的，  但是一般不是最优的

![](media/image1.png)



## ********人工智能讲义
  **启发式搜索**


  February 23, 2020

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```

```
\*\*3\*\*
```
[启发式搜索基础]()[启发式函数的例子]()[启发式函数的设计]()
  
```
\*\*4\*\*
```
[设计启发式函数的例子：*A**∗ *算法]()


搜索算法框架改动为启发式搜索算法
**Input: **G: 状态图; *s*0: 初态;
**Output: ***path*: 代表解的路径
*path **←− *(*s*0)*, **FRINGE **←− **ϕ */\* 初始化 \*/;

  **if **(*GOAL*(*s*0) = *T ***then return ***path *= (*s*0);
FRINGE 的优先级次序，表示了搜索的“策略”

**end**
INSERT(*s*0*, **FRINGE*);
**while ***T ***do**
  **if ***empty*(*FRINGE*) == *T ***then**
    **return ***failure */\* 返回 *failure*, 表示无解 \*/;
  **end**
  
```
\*←−\*
```

```
\*←−\*
```
*N*REMOVE(*FRINGE*) /\* 将未扩展节点中队头节点从队列移除到 *N*\*/; *s*STATE(*N*) /\* 从节点 *N** *恢复为状态 *s*\*/;
  update *path*;
  **foreach ***s**′ **in **successors*(*s*) **do**
    为 *s**′ *创建 *N *的新子节点 *N**′ *;
    **if ***GOAL*(*s**′ *) = *T ***then**
    
```
\*⇐ \*在 INSERT 函数中修改该函数的功能，使之=
```
**return **(*path**, **s**′ *)/\* 找到目标节点，返回解 \*/;



**end**
****
**end**
**end**
INSERT(*s**′**, **FRINGE*);
        完成 FRINGE 的优先级排序


最佳优先搜索：从 FRINGE 中选择最佳节点进行扩展
  ![](media/image5.png)何为最佳节点？
  ![](media/image118.png)如何获得最佳节点？
评估节点的优劣：利用状态/节点信息或描述来度量
  ![](media/image7.png)设计评估函数 f，将搜索树的节点 *N *映射为一个非负实数 *f*(*N*) ，表示从初始状态到达某个节点的路径耗散（越小越好！）
  ![](media/image118.png)将整个未扩展节点集合 FRINGE 按增序排列，排在最前面的称为“最佳”（best），优先进行扩展（first），Best-first search
  ![](media/image6.png)若两个节点 f 值相等，则可任意指定其次序，或者添加其他的信息进行进一步排序
注意“最佳”的概念，并非指最后获得的解是最佳的
  ![](media/image5.png)局部贪婪的
  ![](media/image6.png)什么时候能获得最优解？


目前为止，学习的路线/思路
  ![](media/image7.png)搜索问题求解 *⇒ *算法框架 *⇒ *搜索策略 *⇒ *评估函数 *f *的设计
设计节点评估函数 *f *的两种方法：
  ![](media/image118.png)*f*(*N*) = *g*(*N*) + *h*(*N*)，完整解的路径耗散，对应 *A**∗ *算法
  ![](media/image7.png)*f*(*N*) = *h*(*N*)，从当前节点到目标节点的路径耗散，对应 贪婪算法
符号解释说明
  ![](media/image6.png)![](media/image6.png)*N*：当前待判决/估计/评价的节点*g*(*N*)：从初始节点到 *N *的路径耗散
  ![](media/image5.png)*h*(*N*)：从 *N *到目标节点的路径耗散，就是所谓的 启发式函数，估计值
函数 *f *的形式因具体问题而异！


  ![](media/image120.png)

  ![](media/image118.png)机器人导航：问题描述灰格子表示障碍物；
  ![](media/image7.png)红格子表示初态，绿格子表示终态。
  ![](media/image7.png)寻找从红格子到绿格子的路径（路径规划问题）


  ![](media/image121.png)

机器人导航：问题描述
  *f*(*N*) = *h*(*N*)
  *h*(*N*) =Manhattan distance to the goal
  格子中的数字标明了 *f*(*N*) 的值


    ![](media/image122.png)

机器人导航：问题描述
  ![](media/image118.png)*f*(*N*) = *g*(*N*) + *h*(*N*)
  ![](media/image5.png)*h*(*N*) =Manhattan distance to the goal
  ![](media/image6.png)格子中的数字标明了 *f*(*N*) 的值


          ![](media/image123.png)

节点评估函数 *f *的设计，核心在于启发式函数 *h *的设计
  ![](media/image7.png)![](media/image118.png)一般情形下，启发式函数值由当前节点和目标节点二者所确定 *h*(*N*) 应保证的性质：*h*(*N*) *&gt;*= 0*, **h*(*Goal*) = 0*, **h*(*N*) 越小，离目标越近
  ![](media/image118.png)如上图所示 *h*1


          ![](media/image124.png)

数码问题，如上图所示，三种启发式函数的设计如下：
  ![](media/image6.png)*h*1(*N*) = 错误放置的格子数 = 6
  ![](media/image6.png)*h*2(*N*) = 所有数字到其正确位置的 Manhattan 距离之和 = 2 + 3 + 0 + 1 + 3 + 0 + 3 + 1 = 13
  ![](media/image7.png)*h*3(*N*) = 逆序数之和 = *n*5 + *n*8 + *n*4 + *n*2 + *n*1 + *n*7 + *n*3 + *n*6 = 4 + 6 + 3 + 1 + 0 + 2 + 0 + 0 = 16


![](media/image125.png)![](media/image126.png)


![](media/image127.png)![](media/image128.png)
















  ![](media/image129.png)贪婪算法
          *f*(*N*) = *h*1(*N*) = 错误放置的格子数


![](media/image130.png)![](media/image131.png)


![](media/image132.png)![](media/image133.png)










  ![](media/image134.png)A\*
  算法
  *f*(*N*) = *g*(*N*) + *h*1(*N*)*, **h*1(*N*) = 错误放置的格子数


![](media/image135.png)![](media/image136.png)







    贪婪算法


![](media/image140.png)![](media/image141.png)

  ![](media/image5.png)![](media/image5.png)
```
√
```
路径规划问题的启发式函数：如上图，*g** *为目标状态Euclidean distance：*h*1(*N*) =(*x**N** **−** **x**g*)2 + (*y**n** **−** **y**g*)2 Manhattan distance：*h*2(*N*) = *|**x**N** **−** **x**g**|** *+ *|**y**n** **−** **y**g**|*


![](media/image142.png)   

  ![](media/image7.png)启发式函数：*f*(*N*) = *h*(*N*) = 到目标的直线距离最佳优先搜索存在的局部最小问题
  引导搜索进入错误的方向降低了搜索效率


基本要求
  ![](media/image6.png)![](media/image6.png)*h*(*N*) *&gt;*= 0*, **h*(*Goal*) = 0*, **h*(*N*) 越小，离目标越近更多的？
可采纳的/admissiable 启发式函数
  ![](media/image7.png)假设 *h**∗*(*N*) 是节点 N 到目标节点的实际最优路径耗散
  ![](media/image6.png)启发式函数 *h*(*N*) 是“可采纳的”，当且仅当 0 *≤** **h*(*N*) *≤** **h**∗*(*N*)
  ![](media/image6.png)总是“乐观地”估计路径耗散！**！**
定义“可采纳的”启发式函数的理由和方法
  ![](media/image118.png)松弛问题：放宽问题的限制（约束），减少行动限制，获得更好的解，原问题的解仍在松弛问题的可行域中。
  ![](media/image7.png)用松弛问题来构造启发式函数是最常用的技术
  ![](media/image7.png)加强问题：增加问题限制，把原来可行的路径（解）给剪枝掉，可能无解；


          ![](media/image124.png)

数码问题，如上图所示，三种启发式函数的设计如下：
  ![](media/image7.png)*h*1(*N*) = 错误放置的格子数 = 6 可采纳的
  ![](media/image7.png)*h*2(*N*) = 所有数字到其正确位置的 Manhattan 距离之和 = 2 + 3 + 0 + 1 + 3 + 0 + 3 + 1 = 13可采纳的
  ![](media/image7.png)*h*3(*N*) = 逆序数之和 = *n*5 + *n*8 + *n*4 + *n*2 + *n*1 + *n*7 + *n*3 + *n*6 =
  4 + 6 + 3 + 1 + 0 + 2 + 0 + 0 = 16 不可采纳的。反证法：找一个违背可采纳定义的状态


  ![](media/image149.png)


```
√
```
路径规划问题，如上图所示，启发式函数设计如下：
  ![](media/image7.png)
```
\*|\*\*−\*\*||\*\*−\*\*|\*
```
Euclidean distance**： ***h*1(*N*) = (*x**N** **− **x**g*)2 + (*y**n** **− **y**g*)2, 可采纳的Manhattan distance：*h*2(*N*) = *x**N** **x**g** *+ *y**n** **y**g** *，不允许沿对角线移动，则是可采纳的；否则是不可采纳的


        ![](media/image150.jpeg)

对一个可采纳的启发式函数 *h*
  ![](media/image6.png)
```
\*≤\*
```
若它对所有节点都满足三角不等式，即 *h*(*N*)*c*(*N**,** **N**′*) + *h*(*N**′*)， 其中 *N**′** *是 *N** *的后继节点，则 *h** *是一致的或单调的。
  ![](media/image118.png)*c*(*N**, **N**′*) 是节点 *N *到 *N**′ *的单步路径耗散。


        ![](media/image150.jpeg)

性质和理解：一致的/单调的启发式函数
  ![](media/image7.png)*h*(*N*) *≤** **h**∗*(*N*) *≤** **c*(*N**, **N**′*) + *h**∗*(*N**′*)
  ![](media/image7.png)*h*(*N*) *−** **c*(*N**, **N**′*) *≤** **h**∗*(*N**′*)
  ![](media/image7.png)*h*(*N*) *−** **c*(*N**, **N**′*) *≤** **h*(*N**′*) *≤** **h**∗*(*N**′*)
  随着搜索的深度越来越深，对深处节点估计的启发式函数值越来越准确！**！**


          ![](media/image151.png)不满足三角不等式，不是一致的启发式函数



        ![](media/image124.png)数码问题
                      ![](media/image50.png)*h*1(*N*) = 错误放置的格子数 = 6, 可采纳的，一致的
                      ![](media/image152.png)*h*2(*N*) =
                      所有数字到其正确位置的 Manhattan  距离之和   = 2 + 3 + 0 + 1 + 3 + 0 + 3 + 1 = 13,可采纳的，一致
                      的


  ![](media/image149.png)

![](media/image7.png)
```
√\*−\*\*−\*
```
路径规划问题，如上图所示，启发式函数设计如下：
  Euclidean distance**： ***h*1(*N*) =(*x**N****x**g*)2 + (*y**n****y**g*)2, 可采纳的， 一致的
  ![](media/image6.png)
```
\*|\*\*−\*\*||\*\*−\*\*|\*
```
Manhattan distance：*h*2(*N*) = *x**N****x**g**  *+  *y**n**y**g** *，不允许沿对角线移动，则是可采纳的，一致的；否则是不可采纳的，不一致的



AI 中最著名的搜索算法
  ![](media/image7.png)*f*(*N*) = *g*(*N*) + *h*(*N*), 其中
  ![](media/image7.png)*g*(*N*) = 从初始节点到 N 的路径耗散
  ![](media/image7.png)*h*(*N*)：从 *N *到目标节点的路径耗散，可采纳的启发式函数

从 *A**∗ *算法中的启发式函数设计，学习如何设计启发式函数

  ![](media/image153.jpeg)

  ![](media/image7.png)证明：完备性（若 *A**∗ *算法结束，问题有解，则一定会返回一个解） 如图所示
  ![](media/image7.png)未扩展节点集合 FRINGE 中任意节点 *N *满足
  ![](media/image6.png)![](media/image6.png)*f*(*N*) = *g*(*N*) + *h*(*N*) *≥ **g*(*N*) *≥ **d*(*N*) *× **ϵ*, 其中 *d*(*N*) 是节点 *N** *的深度只要 *A**∗ *算法没结束，在 FRINGE 中至少有一个节点 *K** *属于解路径节点扩展会使得路径变长，*K** *将最终被扩展，除非在这之前找到一个到达目标节点的其他路径。
  ![](media/image7.png)条件：状态被重复访问时，节点不被丢弃


              ![](media/image154.png)

证明：最优性（*A**∗ *选择某个目标节点扩展，则到此目标节点的路径一定是最优的)
  ![](media/image5.png)如上图所示
  ![](media/image6.png)*C**∗ *= 最优解的路径耗散
  ![](media/image7.png)*G**′*: 未扩展节点集合中“非最佳”目标节点（为什么只要考虑目标节点？）*f*(*G**′*) = *g*(*G**′*) + *h*(*G**′*) = *g*(*G**′*) *&gt;** **C**∗*
  未扩展节点集合中的节点 *K *位于最优解的路径上:*f*(*K*) = *g*(*K*) + *h*(*K*) *≤ **C**∗*
  所以,*G**′ *不会被选择扩展



问题无解时
  ![](media/image7.png)![](media/image7.png)若状态空间无限或允许状态重复访问，则 *A**∗ *算法的搜索不会停止； 求解实际问题时，通常给一个停止时间/time limit，当停止时间达
  到时，算法停止运行；
  ![](media/image5.png)
```
\*∗\*
```
因停止时间耗完而停止的 *A *算法，无法判断其是否有解或无解， 也无法说明更多的搜索时间可以得到解。



![](media/image155.png)状态图说明
![](media/image156.png)如左图
                      ![](media/image18.png)*h *是一个可采纳的启发式函数，每个节点的 *h *值（估计值）标记在节点附近；
                      ![](media/image23.png)每条边标记了路径耗散 *c*
                      值；
                      ![](media/image19.png)从红色状态节点找一条路径到绿色状态节点。


![](media/image157.jpeg)![](media/image158.jpeg)
![](media/image159.jpeg)![](media/image160.jpeg)
解释说明
  ![](media/image7.png)蓝色节点被访问后，若丢弃该状态，会发生什么事情？
  ![](media/image6.png)次优解（红-黄-蓝-绿），路径耗散 104


![](media/image160.jpeg)![](media/image161.jpeg)

解释说明
  ![](media/image7.png)若不丢弃访问过的状态，运行状态重复访问
  ![](media/image7.png)![](media/image7.png)我们可以得到最优解（红-褐-蓝-绿），路径耗散 102 WHY？付出什么代价了？


      ![](media/image162.png)


    ![](media/image17.png)![](media/image17.png)图搜索：避免状态重复访问状态有限时，是完备的但不保证解是最优的
    树搜索：允许状态重复访问保证获得最优解
    ![](media/image17.png)![](media/image163.png)无解时可能永远停不下来



一个重要的事实
  ![](media/image6.png)丢弃重复访问状态的节点，如果到该节点的新路径的耗散 *g*(*N*) 比以前（访问该状态）的路径耗散更大

  ![](media/image6.png)一致的/单调的启发式函数来自上述重要事实
  ![](media/image6.png)![](media/image6.png)虽然采用一致启发式函数的搜索树的节点仍可能是指数增加的  但实际应用中，能有效地避免许多重复访问状态的节点扩展。


                    ![](media/image164.png)从第二次开始重复扩展的状态总是不如第一次扩展


证明：对一致的 *h*，*A**∗ *算法扩展一个状态节点时，到该状态的路径一定是最优的
  ![](media/image5.png)一致性意味着单调性：(考虑 *N *及其后继 *N**′ *)
  *f*(*N*) = *g*(*N*) + *h*(*N*) *≤** **g*(*N*) + *c*(*N**, **N**′*) + *h*(*N**′*) = *f*(*N**′*)
  ![](media/image7.png)如上图，*K *被选择进行扩展，我们要证明此时路径到 *K *是最优的， 即 *g*(*K*) 最小。考虑在未扩展节点集合中存在一个其他节点 *N*，经*N *到 *K*，*K *的状态此时扩展为节点 *N**′*，存在一条路径，那么
  有：（*N**′** *和 *K** *是同一个状态不同的节点表示）*f*(*N**′*) *≥** **f*(*N*) *≥** **f*(*K*)
  以及 *h*(*N**′*) = *h*(*K*) 所以，*g*(*N**′*) *≥ **g*(*K*)





处理状态的重复访问
  ![](media/image7.png)![](media/image7.png)节点被扩展，则状态进入 CLOSED 表当一个新节点 *N *产生了
      ![](media/image32.png)若 *N *表示的状态在 CLOSED 表中，则丢弃节点 *N*
      ![](media/image32.png)若 *N *表示的状态不在 CLOSED 表中，但是在未扩展节点集合FRINGE 中（不妨设为 *N**′*），则去掉 *f*(*N*)*,** **f*(*N*) 中较大的节点，等价于去掉 *g*(*N*) 和 *g*(*N*) 中较大的节点



  ![](media/image7.png)![](media/image7.png)特殊的一致启发式函数：*h **≡ *0 一致的，当然也是可采纳的等价于单步路径耗散相同
  ![](media/image7.png)*A**∗ *退化为宽度优先搜索，代价一致搜索

为 *A**∗ *设计什么样的启发式函数更好？


            ![](media/image165.png)

  ![](media/image7.png)可采纳的启发式函数 *h*1*, **h*2 对任何节点，*h*1 *≤ **h*2，则称 *h*2 比 *h*1 准确如上图
  ![](media/image6.png)*h*1(*N*) = 错误放置的格子数目
  ![](media/image6.png)*h*2(*N*) = 每个数字到对应目标位置的 Manhattan 距离
  ![](media/image6.png)*h*2 比 *h*1 更准确/精确/更富含信息

*A**∗ ***算法性质 ****4**
解释说明
  ![](media/image7.png)当解存在时，较精确启发式函数导致的被扩展节点集合包括在“不  精确”启发式函数导致的被扩展节点集合中，除了 f 值相同且等于最优解的路径耗散的那些节点.
证明：精确的启发式函数扩展的节点更少一些
  ![](media/image6.png)任何 *f*(*N*) *&lt; **C**∗ *的节点都将会被扩展（在获得最优解之前）。可用绘制等 *g*(*N*) 值线的方式来逐步扩展初始状态为核心的等值线系统， 在最优解路径耗散 *C**∗ *围成的等值线包括了所有 *f*(*N*) *&lt; **C**∗ *的节
  点。（完备性容易由此被证明）
  ![](media/image7.png)
```
\*≤\*
```
所以由 *h*1(*N*)*h*2(*N*) 可知，在找到最优解之前，*h*2 扩展的节点，
  *h*1 都会进行扩展
  ![](media/image7.png)除了最后达到最优解时，可能获得的是不同的最优目标节点！
不精确的启发式函数会访问更多的节点！


      ![](media/image167.jpeg)
有效分支因子 *b**∗*
  ![](media/image7.png)*b**∗ *可以度量启发式函数的有效性
  ![](media/image6.png)通过隐函数来定义：*n *= *b**∗ *+ (*b**∗*)2 + *... *+ (*b**∗*)*d** *, 其中 *n *是被扩展的节点数目，*d *是解的深度
  ![](media/image7.png)如上图，8 数码问题，考虑无信息的迭代深入搜索、h1 和 h2，随机产生 1200 个 instances
  被扩展节点数目 *n*
      *d *= 12*, **h*1 *→** *227*, **h*2 *→** *73
      *d *= 24*, **h*1 *→ *39135*, **h*2 *→ *1641



经验总结
  ![](media/image6.png)![](media/image7.png)基本思路：求解原问题的松弛问题，获得灵感例如 8 数码问题
      ![](media/image31.png)*h*1 的设计：假设错了数字，可以一次就放到正确位置，忽略其它所有因素
      ![](media/image32.png)*h*2 的设计：假设数字可以水平和垂直任意移动，忽略移动目标位置是否被占据
      ![](media/image32.png)更复杂有效的启发式函数设计：假设数字可以水平和垂直移动，使得1，2，3，4 移动到目标位置，忽略 5，6，7，8 的阻挡，计算移动次数 *d*1；使得 5，6，7，8 移动到目标位置，忽略 1，2，3，4 的阻挡， 计算移动次数 *d*2；*h *= *d*1 + *d*2。（产生大约 3024 个状态节点）
  ![](media/image7.png)其他方法：从经验中学习，归纳学习，不同启发式函数的集成等



目标：精确的、一致的启发式函数
  ![](media/image6.png)保证了完备性、最优性，不需要重复访问同一个状态
  ![](media/image6.png)实际上，问题并没有解决。问题规模大时，因为时空要求都是解长  度的指数函数
  ![](media/image7.png)算法时间限制及其设置
  ![](media/image118.png)其它实用的，不可采纳的启发式函数，不能保证最优性和完备性，  但是能快速获得最优解或近似最优解


迭代深入 *A**∗ *算法：*IDA**∗*
  ![](media/image7.png)思想：设置 *f *的阈值，超过 *f *的阈值，节点不再扩展；迭代执行
  ![](media/image7.png)*A**∗*，降低 *A**∗ *算法对内存的需求要求：一致的启发式函数

算法思想
  ![](media/image7.png)初始化 *f *的阈值 *t *为 *f*(*N*0)
  ![](media/image6.png)重复执行下述两步：
      ![](media/image32.png)执行深度优先搜索，扩展 *f*(*N*) *&lt;*= *t *的节点 *N*
      ![](media/image32.png)重新设置 *t *为未扩展节点中 *f *的最小值


优点
  ![](media/image7.png)完备的、最优的
  ![](media/image7.png)比 *A**∗ *要求的内存少
  ![](media/image7.png)避免了未扩展节点集合的排序开销
不足
  ![](media/image168.png)无法充分利用内存，用的内存太少，两次迭代之间只保留阈值 t
  ![](media/image169.png)无法避免重复访问不在路径上的节点
*IDA**∗ *改进为 *SMA**∗*
  ![](media/image7.png)*IDA**∗ *的改进：把内存用光，不能保存节点了，丢掉保存的一个高耗散，最旧的节点，再插入新的节点，这个算法称为：*SMA**∗*

![](media/image1.png)



## ********人工智能讲义
  **优化问题****: ****搜索问题的变型**


  February 24, 2020

### ****Outline
  
```
\*\*1\*\*
```
[优化问题的描述]()
  
```
\*\*2\*\*
```
[优化搜索问题求解算法]()




优化问题

*s**.**t**.*
min *f*(*x*) *h*(*x*) *≤** *0


说明
  ![](media/image6.png)*f*(*x*) 目标函数
  ![](media/image6.png)*h*(*x*) *≤ *0，约束条件，限制 *x *的取值范围，可以没有约束条件


搜索问题是通用模型: 优化问题可建模为搜索问题

  形式化方法 1：
    ![](media/image18.png)状态：一个解当成一个状态，解集构成状态空间
    ![](media/image18.png)后继函数：无
    ![](media/image18.png)目标状态：由目标函数的约束形式定义（最小化/最大化）
    ![](media/image163.png)初始状态：任意指定
    ![](media/image19.png)路径耗散：计算目标函数一次， 代价为 1
    ![](media/image19.png)解：终态
部分解和完全解
  ![](media/image7.png)若 *x *是一个向量，或多个部分构成
  ![](media/image6.png)*x *所有分量都赋值了，则称 *x *是完全解，否则称 *x *是部分解
形式化方法 2：
  ![](media/image18.png)状态：解由多个部分构成时，一个部分解或完整解是一个状态
（参考 8 皇后问题的形式化方法 2）
  ![](media/image23.png)后继函数：无
  ![](media/image17.png)目标状态：由目标函数的约束形式定义（最小化/最大化）
  ![](media/image23.png)初始状态：任意指定
  ![](media/image19.png)路径耗散：计算目标函数一次， 代价为 1
  ![](media/image23.png)解：完整解/终态




当作搜索问题的优化问题，特点：
  ![](media/image7.png)优化搜索问题的解，不需要返回从初态开始的路径，返回终态即可。（初态不唯一）；
  ![](media/image169.png)这降低了对解的要求；
  ![](media/image5.png)后继函数在搜索问题中可以在问题建模时，考虑求解算法的便利和  性能而特别设计；


数值优化问题：min *f*(*x*) = *ax*2 + *bx *+ *c**, **a **&gt; *0
  ![](media/image7.png)状态：用 *x *来标识，任意一个解代表一个状态，可以实数编码或二进制编码 *x*
  ![](media/image7.png)后继函数：
      ![](media/image31.png)若采用爬山法来求解问题，邻域就是后继函数；
      ![](media/image32.png)若用梯度下降法来求解问题，任意 *x *的后继由其梯度信息和步长参数确定；
  ![](media/image169.png)![](media/image7.png)目标状态：*x *的取值使得目标函数 *f *取最小值； 初态：任意指定；
  ![](media/image6.png)![](media/image6.png)路径耗散：每评估/计算一个状态的目标状态值，路径耗散为 1。解：使得 *f *最小的 *x*



组合优化问题：MaxSAT

*n *个布尔变量 *X*，*m *个定义在 *X *上的布尔表达式，求 *X *的一个赋值， 使得能让 *m *个布尔表达式尽可能多地被满足 (为真)。
  ![](media/image7.png)![](media/image7.png)状态：任何一种 0 个或 *k **≤ **n *个布尔变量被赋值的情况为一个状态； 后继函数：如采用爬山法，定义两个解的 *n *个布尔变量中只有一个布尔变量赋值不一样时，二者互为后继；
  ![](media/image6.png)初态：任意指定；
  目标状态：满足让最多布尔表达式为真的赋值方法； 路径耗散：每评估一次所有的布尔表达式，代价为 1.


  ![](media/image170.jpeg)


Landscape: *L** *= (*S**, **f**, **N*)，地貌图
  ![](media/image6.png)![](media/image6.png)状态空间 *S*，编码目标函数 *f*
  ![](media/image7.png)邻居算子 *N*，搜索中的后继函数

建模：状态空间的编码和后继函数的设计相关、重要！

理解 Landscape首先给定一个所有状态构成的集合 S，S 是集合，包含元素之间是无序的；设计一个邻居算子/后继函数，在状态之间建立关系，形成状态图，如左图的横坐标系统，是一个“状态图”；在状态图形成的空间基础上，增加一维对每个状态赋予一个目标函数值 f，这样就得到了 Landscape！


      
```
局部搜索算法
```

```
VS
```

```
全局搜索算法
```



    后继状态是状态空间的子集状态图不是完全图
  边权值为概率，表示状态间转移概率
  后继状态为整个状态空间状态图为完全图
  边权值为 1


  典型代表算法

  局部搜索算法
    ![](media/image18.png)爬山法、梯度下降法、禁忌搜索、局部剪枝搜索、模拟退火
全局搜索算法
    ![](media/image23.png)模拟退火、遗传算法、蚁群算法、粒子群算法、差分算法、EDA(估计分布算法)、Memetic 算法


梯度的概念
  ![](media/image169.png)
```
\*∂\*\*x\*1
```

```
\*∂\*\*x\*2
```

```
\*∂\*\*x\*\*n\*
```
*n *元实值函数 *g*(*x*) 在 *n *维空间中变化速度最快的方向 :*∇**x**g *≜ ( *∂**g** **,** **∂**g** **, . . . ,** **∂**g** *)*t*
  ![](media/image7.png)站在山上，各个方向中，有个方向是最陡峭的方向
算法思想
  ![](media/image6.png)![](media/image6.png)想象一个人被随机扔在群山中，现在他想最快地下山到最低的山谷；  群山很大，视线范围无法覆盖所有区域；
  ![](media/image6.png)假设下山有各个方向都可以选；如何最快下山？找最陡峭的方向
  （负梯度方向）！梯度方向上山最快。
  ![](media/image7.png)你下山时，步幅迈多大？如果你是巨人，一步最大可以跨越两座山  头？合适恰当的步幅设置很重要！
  ![](media/image7.png)梯度下降也称最速下降法。


第一步：初始化，设置算法相关参数/超参数 主要包括两个参数（参数具体使用参看第三步）：
  ![](media/image169.png)算法停止准则 T，当执行 T 次循环时，算法终止；
![](media/image7.png)下降步长/步幅序列，*λ *= [*λ*1*, **λ*2*, . . . , **λ**T*]。该序列一般为递减。第二步：初始化，初态 *X*0
  ![](media/image7.png)![](media/image7.png)初态 *X*0 可设置为某个特殊值也可以用随机值
第三步：循环迭代
  ![](media/image7.png)*for s *= 1*, *2*, ..., **T*
      *X**s*+1 = *X**s** **−** **λ**s**∇**X**g*(*X**s*)*, *其中
      *∇**X**g *= ( *∂**g** **, **∂**g** **, . . . ,** ∂**g** *)*t** *and *X *= (*x*1*, **x*2*, . . . , **x**n*)*t*

  *endfor*
*∂**x*1
*∂**x*2
  *∂**x**n*



评述
  ![](media/image7.png)不能确保获得全局最小解
      ![](media/image31.png)该优化问题面临的是“群山”
      ![](media/image31.png)梯度下降可能落入一个不是最低的山谷，获得一个极小值/局部最优解，无法确保获得全局最小解
      ![](media/image32.png)若将视线范围视为“邻域”，局部最小值是指邻域内最小，也即是视线范围内没有更低的山谷存在
  ![](media/image169.png)算法停止条件和步长序列的设置需要人工经验

改进算法？




  ![](media/image6.png)直线搜索：不知道如何设置步长，就用各种步长来尝试 不知道步长 *λ** *的如何取值时，妥协的做法
  ![](media/image7.png)*λ**∗** *= arg*λ** *min *g*(*X** **−** **λ**v*)，其中 *v** *为梯度方向
  
```
\*∂\*\*x\*1
```

```
\*∂\*\*x\*2
```

```
\*∂\*\*x\*\*n\*
```
*∇**x**g** *≜ (  *∂**g** **,** * *∂**g** **,** **.** **.** **.** **,** * *∂**g** ** *)*t**  *或其它方向。
  ![](media/image7.png)*λ *的取值范围一般设置为一个集合 *{**. . . , **−*2*c**, **−**c**, **c**, *2*c**, . . .**}*


![](media/image173.png)![](media/image174.jpeg)

  ![](media/image5.png)每个点的梯度方向垂直等值线；
  ![](media/image6.png)步长每次都是最优的的 *λ**∗*，如左图；
  ![](media/image7.png)每次前进的方向都是垂直于上次前进方向；
  ![](media/image7.png)![](media/image7.png)zig-zagging/锯齿现象，折线方向走向极小值点，如左图。  右图每一步步长不保证最优。


随机梯度下降引入的原因
  ![](media/image7.png)计算梯度信息的时间代价如果很大，怎么办？
  ![](media/image7.png)
```
\*|\*\*\*) =\*D\*\*\*\*|\*\*train\*
```
算法的每一步，即每一次循环，更新一次 W，都需要完全扫描一次训练数据集，即：

  *W**s*+1 = *W**s** **−** **λ**s**∇**W*(
  ∑
∑(*x**,**y*)*∈**D**train *(*W**s *· *ϕ*(*x*)*−**y*)2

  *W**s **−** **λ**s*
(*x**,**y*)*∈**D**train *2(*W**s *· *ϕ*(*x*)*−**y*)*ϕ*(*x*)
    *|**D**train**|*

  ![](media/image6.png)当训练数据集很大时，包括千万/上亿的行时，算法的时间开销巨大。
  ![](media/image6.png)数据挖掘工程实践中常考虑这类问题。此时训练数据集太大，无法一次载入内存，涉及内外      存数据交换，时间开销更大，因此需要对算法进行改进。

随机梯度下降法
  ![](media/image7.png)计算梯度方向时，只用了一个随机样本的信息，替代经典梯度下降算法要计算所有训练数据      集对梯度方向的贡献。

  ![](media/image169.png)即：*W**s*
= *W**s** **−** **λ**s** *∑(*x**,**y*)*∈**D**train** *2(*W**s** *· *ϕ*(*x*)*−**y*)*ϕ*(*x*) =*⇒** **W**s*=
    

      +1
  *W**s** **−** **λ**s**∇**W*((*W**s** *· *ϕ*(*x**i*) *−** **y**i*)2)
*|**D**train**|*+1

  时间性能得到提升，不需要每次循环都载入一次训练数据集；付出的代价是更多的循环次数。


              ![](media/image175.jpeg)
寻找函数 *g*(*X*) 的根 *X**∗*，使得 *g*(*X**∗*) = 0
  ![](media/image6.png)找 *g*(*X*) 在 *X**n *处的切线，以切线和 *X *轴的交点为新点 *X**n*+1
  ![](media/image7.png)*∇**g*(*X**n*) = * **g*(*X**n*)*−*0     *⇒** **X**n*+1  = *X**n** ** **−** ** ** ** **g*(*X**n*) 


问题：
*X**n*+1*−**X**n*
*∇**g*(*X**n*)

  ![](media/image7.png)算法能快速对可导函数求根
  ![](media/image7.png)但是和优化问题有何相关之处？ 离散的组合优化问题怎么办？

爬山法: 最小化目标函数 *g*(*X*)
**Input: **邻居/邻域算子: *N*(*X*); 目标函数 *g*(*X*)
**Output: ***X**c*: 代表解的终态
随机生成初态, 记为 *X**c */\* 初始化 \*/;
**while ***T ***do**
  
```
\*{\*\* \*\*|\*\*≤\*\*}\*
```
在 *N*(*X**c*) 中找到子集 *N**′*(*X**c*) =  *Y** **g*(*Y*)*g*(*X**c*) ;
    **if ***empty*(*N**′*(*X**c*) **then return ***X**c*
  **end**
  ;
  依据策略 *s *选择 *X**′ **∈ **N**′*(*X**c*);
**end ***X**c **←− **X**′*;
评述：爬山法找到的是局部最优解
  ![](media/image7.png)非常简单、高效的算法，内存需求少，两个关键因素：初始解和邻居算子 *N*( · ) 的定义
  ![](media/image7.png)策略 *s*，常见的有：
      best-found：在 *N**′*(*X**c*) 中选择 *g*( · ) 最小的
      first-found：随机在 *N**′*(*X**c*) 中选择一个，之所以叫 first-found，因为实际实现上述算法时，不需要求出整个
      *N**′*(*X**c*)，在对 *X**c *的邻域遍历时，遇到第一个更好的邻居时，本次循环就结束；
      ![](media/image176.png)Random Walk: 在 *N*(*X**C*) 而非 *N**′*(*X**c*) 上随机选择一个当成下次循环迭代的 *X**c*，一种随机采样


理解：与梯度下降的相关性
  ![](media/image5.png)![](media/image6.png)Best-found：梯度下降的离散化版本； first-found: 随机梯度下降；

爬山法的改进算法
  ![](media/image7.png)用不同的随机初始值重启算法，对于上百万个皇后问题，不到一分  钟，随机初值重启的爬山法能求解出
  ![](media/image7.png)局部最优的存在是和邻域结构的定义相关，故就有“变”邻域结构  结构的局部搜索算法。比如迭代爬山法，到达局部最优解后，调整邻居算子，实现“扰动”，然后再回到局部搜索。
  ![](media/image7.png)模拟退火 (= 爬山法 + 随机行走）




LBS/局部剪枝搜索: 爬山法的并行改进
  ![](media/image7.png)![](media/image7.png)初始时刻，开始 *k *个随机种子/初始值/初态，准备执行爬山法接下来的步骤，是循环迭代过程，可以有不同的策略：
      ![](media/image31.png)策略一：假设每个解有 *l *个后继，每一步会在所有 *lk *个后继中选择最优的 *k *作为当前的 *k *个解
      ![](media/image32.png)策略二：所有 *lk *个后继对应一个被选择的概率分布，例如以每个后继的目标值在所有后继目标值中的占比作为该后继被选择的概率
    （最大化问题），然后依次概率分布，随机选择 *k** *个出来


模拟退火思想：
  ![](media/image7.png)一定程度上解决爬山法容易陷入局部最优的困境
  ![](media/image7.png)小概率允许“坏”的移动，而不是像爬山法一样，每次都选最好的  移动
  ![](media/image7.png)分类上，介于全局搜索和局部搜索算法之间
模拟退火: 最小化目标函数 *g*(*X*)
**Input: **邻居/邻域算子: *N*(*X*); 目标函数 *g*(*X*)
**Output: ***X**c*: 代表解的终态
随机生成初态, 记为 *X**c */\* 初始化 \*/;
**while ***T ***do**
  随机选择 *X**′ **∈ **N*(*X**c*); **if ***g*(*X**′*) *≤ **g*(*X**c*) **then ****end ***X**c **←− **X**′*
**end **以概率 *p*：*X**c **←− **X**′*;



概率 *p*
  ![](media/image6.png)概率 p 的设计思想来自冶金学：
  ![](media/image7.png)开始时刻，温度较高，有较大概率移动到“坏”解，随着搜索的进  行，温度降低，移动到“坏”解得概率指数下降；
  ![](media/image7.png)
```
\*−\*
```
公式：*p** *= *e**−*∆*g*/*T*，其中 ∆*g** *= *g*(*X**′*)*g*(*X**c*) 是解和它的邻居的目标函数之差

温度 *T*
  ![](media/image7.png)温度 *T *的下降过程，称为 *schedule*,
  ![](media/image7.png)可以证明，*T *下降得足够慢，算法找到最优解的概率逼近 1


Tabu 搜索
  ![](media/image7.png)简单、带记忆的局部搜索算法
  ![](media/image7.png)不是真正意义的“原子算法”，是一种策略，可以添加到各种局部搜素算法中
Tabu 搜索算法核心
  ![](media/image7.png)
```
\*−\*
```
一个长度有限的（不妨设为 *k*）最近历史解列表 *Tabulist*（用队列实现）
  ![](media/image169.png)![](media/image169.png)在搜索过程中，发现的新解如果出现在 *Tabu **− **list*，直接放弃*Tabu **− **list *能一定程度上防止在局部最优不动了
Tabu 搜索算法问题
  ![](media/image7.png)*Tabu **− **list *的长度 *k *多少最好？


```
\*⇒\*\*−\*
```
从局部搜索到全局搜索：爬山法 =(1 + 1)*EA*
**Input: **目标函数 *g*(*X*)
**Output: ***X**c*: 代表解的终态/最优解
随机生成初态/初始解, 记为 *X**c */\* 初始化 \*/;
**while ***T ***do**
  在状态空间中随机选择一个解为 *X**c *的后继状态 *X**′ */\* 爬山法是从邻居集合中选择一个后继 \*/;
  **if ***g*(*X**′*) *≤** **g*(*X**c*) **then ****end ***X**c **←− **X**′*
  ;
**end**
评述：(1 + 1) *− **Evolutionary Algorithm*
  ![](media/image5.png)算法中当前解的后继，仍可以认为是邻居算法产生的；
  ![](media/image169.png)此时的邻居算子能够有一定概率一步访问到其它任何一个解，这是一个特殊的邻     居算子，称为全局邻居算子
  
```
\*−\*
```
可能不同解之间的跳转概率不一样，一般 (1 + 1)*EA** *会“系统地”设置这样一个概率分布，比如依据 *X**c**,** **X**′** *的差异大小，设置相应的跳转概率



类似于 *LS **→ **LBS*，*λ *个 (1 + 1) *− **EA *并行执行
  ![](media/image7.png)当前解集中的每个解产生 *µ *个后继解，在所有的 *λµ *个解中选择 *λ*
  个作为下次循环的当前解集
  ![](media/image7.png)
```
\*−\*
```
选择的策略可以是：（这些算法称为：(*λ,** **λµ*)*ES*）
      ![](media/image31.png)最好的 *λ *个；
      ![](media/image31.png)按解质量的设置“生存概率”，以此选择 *λ** *个解等；
      ![](media/image31.png)随机选择 *k *个解，选择其中最好的一个，重复 *λ *次，锦标赛选择；
  ![](media/image7.png)若选择下次循环的当前解是在本次循环和其后继，共 *λ *+ *λµ *个解中进行，那么算法称为 (*λ *+ *λµ*) *− **ES*


EA: 后继函数，产生的后继，全局范围内/整个解集范围内
  ![](media/image6.png)从当前解集的一个解产生一个/多个后继，可类似于生物界的无性繁殖
  ![](media/image6.png)从当前解集的两个或多个解产生一个/多个后继，可类似于生物界的有性繁殖
EA: 后继函数的典型例子
  ![](media/image7.png)在当前 *k** *个解中，随机选择 2 个，产生“后继/孩子”，这称为“交叉”算子/crossover，一般性的演化算法/进化算法
  ![](media/image6.png)
```
\*−\*
```
在当前 *k *个解中，选择 3 个 *a**, **b**, **c*, 计算后继为 *x *= *a *+ *ζ*(*b c*)， 得到差分演化算法
  ![](media/image7.png)在当前 *k *个解中，全部选择，用来估计一个模型/分布，该模型我们选择用来描述整个解集，解集获得的过程我们称为从该模型中进行“采样”，这就是估计分布算法，EDA




EA: 更多后继函数的典型例子
  ![](media/image7.png)在当前 *k *个解中寻找后继时，考虑 *k *个解的搜索历史，找到每个解历史最佳解和 *k *个历史最佳中的最佳解，以这些解为基础，设计“速度函数”，获得 *k** *个解的后继；该算法称为“粒子群算法”
  ![](media/image7.png)在当前 *k *个解中，每个解的后继是以该解为初始解，执行局部搜索
  （例如爬山法），得到局部极值解，以此局部极值解为后继；该算法称为“memetic 算法”



EA: 状态空间的设计/编码 *→ *遗传算法
  ![](media/image6.png)![](media/image6.png)解/状态的表示：二进制串表示一个解交叉算子：两个二进制串的混杂/分解
  ![](media/image7.png)变异算子：二进制串的某些位置的概率“翻转”(0 *→ *1*, *1 *→ *0)
  ![](media/image7.png)选择算子：在“后继”或者“后继 + 当前解集”中用某种方式选择出“新的”当前解集。

后继函数的设计和状态空间的设计密切相关，上述二进制串的状态表示，   得到“遗传算法”。

EA: 状态空间的设计/编码 *→ *遗传规划
  ![](media/image7.png)解/状态的表示：树型结构表示一个解
  ![](media/image169.png)寻找一个计算机程序/计算方法，达到目的
![](media/image177.jpeg)


当采用形式化方法 2 来定义搜索问题的时候任一状态可以用一个 *n** **− **D** *的向量来描述，故
  ![](media/image7.png)经典搜索问题的解是从初态向量到终态向量构成的一个“向量链”,  如 *MaxSAT** *问题，路径是从没有任何布尔变量被赋值，到所有布尔变量被赋值，长度为 *n** *+ 1 的向量链；
  ![](media/image169.png)
```
\*−\*
```
后继函数的设计，一般取 *nD** *中一维的值变化得到后继，例如
  8-皇后问题
  ![](media/image6.png)
```
\*−\*
```
构造性算法：*nD** *的取值，一个一个地确定，得到节点指数增加的搜索树
  ![](media/image6.png)路径：表示部分解和完整解

我们称这是构造性算法（解的各个部分/分量逐步被构造出来）


    ![](media/image178.jpeg)

  ![](media/image6.png)每个状态如何保存？前面讨论状态图的搜索时，我们没考虑；
  ![](media/image7.png)![](media/image7.png)有限状态机（FSM) 是对上述简单状态图的扩展，引入时序、输出、输入、代价和状态转移等概念，得到更具体的状态图；如图例子；
  ![](media/image7.png)每个状态用一个向量来描述，一个输入导致状态转移到其它状态，同时会输出，     会付出一定代价；在连续的输入作用下，状态会连续的转移；


部分解和完整解
  ![](media/image6.png)把有限状态机看成是状态图，在其上定义新的搜索问题：寻找遍历  所有节点的路径，使得路径的某个属性达到最小（类似于 TPS 问题）
  ![](media/image7.png)
```
\*∗\*
```
在有限状态机上执行 *A *算法，*g*(*N*) 是部分解的路径耗散，对解的缺失（未确定）部分进行估计（heuristic）
优化问题求解一般都针对完整解进行评价
  ![](media/image6.png)![](media/image6.png)能不能在优化问题求解时，考虑部分解？ 对构成解的“成分”进行分析？
  ![](media/image6.png)解的“成分”，包括成分的“取值”和成分构成解时的“次序”（考虑解是路径时，次序重要）
  对采用形式化方法 2 的优化搜索问题，设计算法？


动机
  ![](media/image6.png)![](media/image7.png)解的哪一个成分更重要？哪一个成分的哪个取值更重要？ 所谓“重要”即更小的代价获得更多的“收益”，heuristic?

蚁群算法思想
  ![](media/image6.png)分布式的策略来估计
  ![](media/image7.png)让 *n** *只蚂蚁在有限状态机上爬行，并留下“信息素”，来标记爬行历史；该过程迭代重复
  ![](media/image7.png)在评价好的“状态转移”边上，将会有跟多的蚂蚁在上面爬行，留  下信息素；

![](media/image1.png)



## ********人工智能讲义
  **CSP****：约束满足问题**


  February 24, 2020

### ****Outline
  
```
\*\*1\*\*
```
[例子]()
  
```
\*\*2\*\*
```

```
\*\*3\*\*
```

```
\*\*4\*\*
```
[CSP 问题建模]()[CSP 问题求解算法]()[CSP 的应用]()


                  ![](media/image179.jpeg)用 *k *种色彩对地图着色
                      ![](media/image180.png)能否用 *k *种色彩对地图染色，一个国家一种颜色，相邻国家颜色不一样
                      ![](media/image180.png)四色定理：第一个用计算机证明的数学定理，证明的正文 300 页，“是否存在四色定理的一个简短证明，……使得一个合格的数学家能在（比如说）两个星期里验证其正确性呢？”（摘自汤米·R·延森和比雅尼·托夫特《图染色问题》）

着色问题思考
  ![](media/image7.png)优化问题？NO! 没有优化的目标函数，仅仅是优化问题的特例：满足优化问题的约束条件即可，是否是最优解，不关心
  ![](media/image6.png)搜索问题？YES! 一个染色过程（序列），不考虑路径耗散，也可以不需要具体路径，给出终态即可，通用搜索问题的特例



形式化定义 *CSP *= (*X**, **D**, **C*)，是一个三元组，其中：
  ![](media/image7.png)![](media/image7.png)*X *是一组变量，不妨假设为一个 *n *维向量 *X *= (*X*1*, **X*2*, . . . , **X**n*) *D *是值域，定义了每一个变量的值域，*D *= (*D*1*, **D*2*, . . . , **D**n*)
  ![](media/image7.png)*C *是一个约束组，*C *= (*C*1*, **C*2*, . . . , **C**m*)，是 *m *个计算公式，约束
  *X *分量之间取值的关系；
    ![](media/image5.png)
```
\*v\*\*∀\*
```
*i**, **X**i** *从 *D**i** *中取值，所有变量都给一个取值，形成一个“赋值”
    = (*x*1*,** **x*2*,** **.** **.** **.** **,** **x**n*)，或者说是一个“解”，可以参与 *C*1*,** **C*2*,** **.** **.** **.** **,** **C**m*
  表示的约束计算公式的计算，判断约束是否被满足。


          ![](media/image181.png)

3-SAT
  ![](media/image169.png)*n *个变量 *x*1*, **x*2*, . . . , **x**n*
  ![](media/image169.png)每个变量的取值域为：*{*0*,** *1*}*，（另一种说法：变量是布尔变量, 此时值域 *{**T**, **F**}*）
  ![](media/image7.png)*m** *个约束，每个约束是少于等于 3 个变量的析取式，或者将 *m** *个约束表示为一个合取式约束条件，如上图所示。
  ![](media/image6.png)求一个真值指派 (*x*1*, **x*2*, . . . , **x**n*) = (*v*1*, **v*2*, . . . , **v**n*)，使得上述每个析取式都被满足（为真），或使得上述合取式为真。

[每年的 SAT 竞赛网址：http://www.satcompetition.org/](http://www.satcompetition.org/)


            ![](media/image182.png)

地图着色问题，如上图所示
  ![](media/image7.png)7 个变量：*{**WA**, **NT**, **SA**, **Q**, **NSW**, **V**, **T**}*
  ![](media/image7.png)每个变量的取值范围都一样：*{**red**, **green**, **blue**}*
  ![](media/image6.png)约束条件：任何两个相邻的变量色彩不一样，即 *WA **̸*= *NT**, **WA **̸*= *SA**, **NT **̸*= *SA**, **NT **̸*=
  *Q**, **SA **̸*= *Q**, **SA **̸*= *NSW**, **SA **̸*= *V**, **Q **̸*= *NSW**, **NSW **̸*= *V*



                  八皇后问题，如图所示
                      ![](media/image183.png)![](media/image93.png)8 个变量：*x*1*, **x*2*, . . . , **x*8
                      ![](media/image93.png)每个变量的取值范围:1*, *2*, *…*, *8，表示行编号
                      ![](media/image93.png)约束条件，包括两类：
                        ![](media/image31.png)若 *x**i** *= *k*, 则
                        
```
\*̸\*\*\*\*∀\*\*\*\*̸\*
```
*x**j** *= *k**, **j *= 1*, *2*, *…*, *8*, **j *= *i*, 第 *k** *行只能放一个皇后
                        ![](media/image32.png)
```
\*i\*\*−\*\*j\*
```
每个对角线只能放置一个皇后，即任意两个皇后 *∀**i**, **j**, **x**i** *= *k**, **x**j** *= *l*, 满足约 束 *l**−**k** **̸*= *±*1


        ![](media/image184.png)

推理问题
  ![](media/image6.png)![](media/image5.png)
```
\*→\*\*⇔\*
```
5 个变量表示 5 个人，每个人有 5 种属性，每种属性的取值域如图约束条件如下：
      The Englishman lives in the Red house.*N**i** *= *EnglishC**i *= *red*
      
```
\*→\*\*⇔\*
```
The Spaniard has a Dog.*N**i ** *= *SpaniardA**i *= *Dog*
      
```
\*→\*\*⇔\*
```
The Japanese is a Painter.*N**i** *= *JapaneseJ**i *= *Painter*
      
```
\*→\*
```
The Italian drinks Tea.*. .** **.*
      
```
\*→\*
```
The Norwegian lives in the first house on the left. *. . .*
      The owner of the Green house drinks Coffee.
      The Green house is on the right of the White house. The Sculptor breeds Snails.
      The Diplomat lives in the Yellow house. The owner of the middle house drinks Milk.
      The Norwegian lives next door to the Blue house. The Violinist drinks Fruit juice.
      The Fox is in the house next to the Doctor’s.谁有斑马？
      The Horse is next to the Diplomat’s.





有限和无限 CSP：解的数目是否是有限的
  ![](media/image7.png)判断的方法：变量的取值域是有限还是无限？
  ![](media/image7.png)一旦有一个变量的取值范围是无限的，则 CSP 问题就是无限的
  （此时解的个数是无限的）
  ![](media/image5.png)若每个变量的取值个数是有限的，则得到有限 CSP 问题，典型问题是 SAT


符号和概念定义
  ![](media/image169.png)
```
\*←←\*\*←\*
```
有效赋值：对 *n *个变量 *x*1*, **x*2*, . . . , **x**n*，一个一个地赋值，不妨设前 *k *个赋值为: *x*1      *v*1*, **x*2      *v*2*, . . . , **x**k**      **v**k*，此时的赋值，会使前 *k *变量相关的约束条件都满足；
  ![](media/image6.png)完全赋值：*k *= *n*，也就是 *n *个变量都被赋值，使得所有的约束条件都得到了满足。

系统化方法
  ![](media/image7.png)![](media/image6.png)状态/状态空间：有效赋值/所有可能有效赋值初始状态：*{}**, **k *= 0
  ![](media/image6.png)后继函数：*{**x*1 *← **v*1*, **x*2 *← **v*2*, . . . , **x**k** **← **v**k**} → {**x*1 *← **v*1*, **x*2 *←*
  *v*2*, . . . , **x**k** **← **v**k**, **x**k*+1 *← **v**k*+1*}*
  ![](media/image7.png)目标测试：*k *= *n*
  ![](media/image7.png)路径耗散：假设单步路径耗散为 1



        ![](media/image185.jpeg)

图解后继函数，如上图
  ![](media/image7.png)剩下 *r** *= *n** **− **k** *个变量，不妨设每个变量的取值个数相同，都是 *s*， 则有 *b** *= *s** **× **r** *个后继，即分支因子是 *b*


        ![](media/image185.jpeg)

特点/性质：可交换性
  ![](media/image5.png)变量的赋值次序和完全赋值的可达性无关，CSP 的关键属性之一
  ![](media/image7.png)带来的好处之一：扩展节点的时候，任意选择一个未赋值的变量，考查其所有可能的赋值即可（扩展节点），后继节点的数目 *s** **×** **r** **→** **s*
  ![](media/image7.png)带来的好处之二：不需要存储到达当前节点（已有有效赋值）的路径，所以可用回溯算法
  （使用递归的简化深度优先算法）


          ![](media/image186.png)![](media/image187.png)![](media/image188.png)


```






  若此时 \*X\*2 的任何赋值都无法满足约束条件，则需要“回溯”， 重新调整 \*X\*3 甚至 \*X\*1 的赋值
```
*X*1 *←** **v*11

![](media/image190.png)![](media/image191.png)

*X*1 *←** **v*11
*, **X*3
*← **v*31


![](media/image189.png)
```




  \*X\*1 \*← \*\*v\*11\*, \*\*X\*2 \*← \*\*v\*32
```
 
```



      此时 \*X\*2 的任何赋值都无法满足约束条件, 需要“回溯”
```




                    
```




      \*X\*1 \*←\*\* \*\*v\*12
```
![](media/image195.jpeg)![](media/image196.jpeg)可以改变变量赋值次序


                    *X*1 *← **v*12 *X*2 *←** **v*21
*X*1 *← **v*12*, **X*2 *← **v*21*, **X*3 *← **v*31


算法框架：CSP-BACKTRACKING(*A*)
**Input: **约束条件; 有效赋值 *A*
**Output: ***A*: 完全有效赋值
  **if **有效赋值 *A *是完全的 **then return ***A*
**end**

```
\*←\*
```
*X*选择一个未赋值变量;

```
\*←\*
```
*D*选择一个 *X** *所有可能取值的次序，例如随机次序;
  
```
\*←\*
```

```
\*←\*
```
**foreach ***v **in **D ***do ***Add*(*Xv*) to *A*; **if**** ***A** *是有效的 **then**
    *result*CSP-BACKTRACKING(*A*) /\* 递归调用 \*/;
      
```
\*̸\*
```
**if ***result *= *failure ***then return ***result*;
    **end**
  **end**

**end ***Remove*(*X **← **v*) from *A*;
**return ***failure*;
算法启动：CSP-BACKTRACKING(*{}*)


CSP-BACKTRACKING(*A*): 减少回溯，提高算法效率
**Input: **约束条件; 有效赋值 *A*
**Output: ***A*: 完全有效赋值
  **if **有效赋值 *A *是完全的 **then return ***A*

```
\*X \*\*← \*选择一个未赋值变量;
```

```
\*D \*\*← \*选择一个 \*X \*所有可能取值的次序，例如随机次序;
```

```
关键之处
```

```
\*\*foreach \*\*\*v \*\*in \*\*D \*\*\*do\*\*
```
**end**


  
```
\*←\*
```
*Add*(*Xv*) to *A*;
  **if**** ***A** *是有效的 **then**
    
```
\*←\*
```
*result*CSP-BACKTRACKING(*A*) /\* 递归调用 \*/;
      
```
\*̸\*
```
**if ***result *= *failure ***then return ***result*;
    **end**
  **end**
**end ***Remove*(*X **← **v*) from *A*;
**return ***failure*;


下一步选择哪个变量进行赋值？
  ![](media/image7.png)为什么会回溯？当前的赋值不一定会最终得到解，继续赋值下去，  可能会发现后续变量的赋值总会和以前的某些赋值一起违背某些约束，我们称之为“冲突”，“冲突”导致回溯的产生
  ![](media/image5.png)选择一个变量，让冲突更早来到！可以减少回溯

待赋值变量 *x** *的 *s** *个取值，赋值给 *x** *的次序是什么？
  ![](media/image6.png)理想状态，每次给每个变量的赋值都是“最佳的”，那么就不会有回溯出现，快速地获得了解

具体的技术方法？









![](media/image197.png)检测冲突的方法
前向检验：以 8 皇后问题为例
  ![](media/image198.png)假设赋值 *x*1 = 5，导致图中涂黑圆的格子成为其它变量 *x*1*, . . . , **x*8 等的取值“禁区”，可以将这些格子从这些变量的取值域中“丢弃”;
  ![](media/image152.png)
```
\*{}\*
```
发展这个思想，每增加一个变量的赋 值，引发了某些未赋值变量取值范围的缩小（要求满足约束条件而造成的），确定这些变量缩小的变量取值范围， 一旦某个变量的取值范围为空集， 则发现了“冲突”，这就是“前向检验”


![](media/image199.jpeg)![](media/image200.png)
![](media/image201.jpeg)![](media/image202.png)![](media/image201.jpeg)![](media/image203.jpeg)![](media/image204.jpeg)![](media/image205.png)




![](media/image204.jpeg)![](media/image206.png)
![](media/image207.png)![](media/image208.png)

  产生“冲突”
  ![](media/image6.png)
```
\*{←←←\*\*}\*
```
*SA** *的值域为空集: 当前赋值 (*WAR*)*,** *(*QG*)*,** *(*VB*) 将不会出现在最终解中



```
\*←\*
```
当一个变量赋值 *xv** *加入到 *A** *之后，执行下述操作：
forward-checking(*D**A*¯ *,** **x**,** **v**,** **A*)
  ![](media/image7.png)for each 变 量 *y *not in *A *do:
      ![](media/image31.png)for each 约束 *c *in *C *do:
        ![](media/image31.png)![](media/image31.png)if c 和 y 不相关 then continue; for each *u *in *D**y *do:
  if *A **∪ **{**y**} ← **u *使得 *c *不被满足 then *remove*(*u**, **D**y*)

解释说明
  ![](media/image7.png)*A *已经赋值的变量集合
  ![](media/image7.png)*C *约束集合
  ![](media/image7.png)*D**y** *变量 *y *的值域,*D**A*¯ 不在 *A *中的变量的取值域
  ![](media/image7.png)*remove*(*u**, **D**y*) 表示从 *y *的值域 *D**y** *中删除 *u*

### ********改进的回溯算法 1
改进的回溯算法
CSP-BACKTRACKING(*A**,** **D**A*¯ )
**Input: **约束条件; 有效赋值 *A*
**Output: ***A*: 完全有效赋值
  **if **有效赋值 *A *是完全的 **then return ***A*
**end**

```
\*←\*
```
*X*选择一个未赋值变量;

```
\*←\*
```
*D**X***选择一个 *X** *所有可能取值的次序，例如随机次序;
**foreach ***v **in **D**X** ***do**
  *Add*(*X **← **v*) to *A*;
  新值域 *D**A*¯  *←** **forward** **−** **checking*(*D**A*¯ *,** **X**,** **v**,** **A*);
  **if**** ***D**A*¯   的每个变量的值域都非空 **then**
    
```
\*←\*
```
*result***CSP-BACKTRACKING(*A**,** **D**A*¯ ) /\* 递归调用 \*/;
      
```
\*̸\*
```
**if ***result *= *failure ***then return ***result*;
    **end**
  **end**
**end ***Remove*(*X **← **v*) from *A*;
**return ***failure*;


下一步选择哪个变量进行赋值？
  ![](media/image7.png)![](media/image6.png)启发式函数：选择约束最强的变量/残留值域最小的变量理由：分支因子最小，后继最少！
![](media/image209.png)

例子如图所示
  ![](media/image169.png)*SA *的残留值域大小为 1，*Q *的残留值域大小为 2，其它三个的残留值域大小都是 3
  ![](media/image169.png)选择 *SA *上色


下一步选择哪个变量进行赋值？
  ![](media/image7.png)![](media/image7.png)启发式函数：选择约束最强的变量/残留值域最小的变量理由：分支因子最小，后继最少！

存在问题
  ![](media/image6.png)很多个变量，残留值域大小相同，怎么办？如何选择？
  ![](media/image7.png)新的启发式函数  2：找到一个变量，在未满足约束组（还有变量未被赋值，所以无法判断是否满足）中出现的次数最多，称为“最多  被约束着的变量”
  ![](media/image7.png)理由：使将来残留值域缩减得更多！降低分支因子


    ![](media/image209.png)

例子，如上图所示
  ![](media/image169.png)启发式函数 1 和启发式函数 2 复合成完整的启发式函数，实现对“下一个变量”的选择第一个变量赋值之前，所有变量的残留值域大  小都是 3，选谁？
  ![](media/image7.png)*SA *同时出现在 5 个未被满足的约束条件中，故选择之赋值。



变量 *x *选择出来了，如何给其残留的值域排序？
  ![](media/image7.png)
```
\*→\*
```
启发式函数 3：选择值 *v** **x*, 满足使得从未赋值的变量的残留值域中删除的值最少。
  ![](media/image169.png)理由：这个 *v*，被称为“最少被约束着的值”，也就是说这个赋值对未来的影响最小，以防将来没办法给其它变量找到赋值
  ![](media/image7.png)具体做法：对每个不同的 *v*，都需要进行前向检验，然后检查前向检验的结果，看哪个 *v** *值对残留值域大小的影响最小！（操作比较复杂，费时间）


    ![](media/image210.png)

地图着色的例子，如上图所示
  ![](media/image169.png)此时，假设 *Q *被选出，准备执行上色，*Q *的残留值域大小为 2，红色或蓝色
  ![](media/image7.png)若 *Q *上蓝色，则 *SA *的残留值域大小为 0；
  ![](media/image7.png)若 *Q *上红色，则 *SA *的残留值域大小为 1，故选择 *SA *残留值域最大的着色方式

改进的回溯算法
CSP-BACKTRACKING(*A**,** **D**A*¯ )
**Input: **约束条件; 有效赋值 *A*
**Output: ***A*: 完全有效赋值
  **if **有效赋值 *A *是完全的 **then return ***A*

**end**
*X **← *选择一个未赋值变量;
=*⇒ *用启发式函数 1 和启发式函数 2 来代替


```
\*←\*
```
*D**X***选择一个 *X** *所有可能取值的次序，例如随机次序;
**foreach ***v **in **D**X** ***do**
  *Add*(*X **← **v*) to *A*;
  新值域 *D**A*¯  *←** **forward** **−** **checking*(*D**A*¯ *,** **X**,** **v**,** **A*);
  **if**** ***D**A*¯   的每个变量的值域都非空 **then**
=*⇒ *用启发式函数 3 来代替

    *result** **←*CSP-BACKTRACKING(*A**,** **D**A*¯ ) /\* 递归调用 \*/;
    **if**** ***resultfailure** ***then**


**end**
****

**end**
**return ***result*;

**end ***Remove*(*X **← **v*) from *A*;
**return ***failure*;



约束传播: 更好的冲突检测机制或方法
  ![](media/image169.png)![](media/image6.png)一个变量 x 的赋值后，其它未赋值变量中一个变量的赋值可能会影响另一个未赋值变量的残留值域，找到这种变化，实现“约束传播”！相容的概念：一个变量 *x *的任何一个赋值，另一个变量 *y *至少存在一个赋值，这些赋值不违背任何约束，则称 *x**, **y *是 2 相容的
  ![](media/image6.png)二元约束的传播算法：*AC*3


约束传播方面内容，感兴趣同学课后阅读。


每个变量是一个节点，变量间连边，构成图
  ![](media/image169.png)连边规则：两个变量参与某个约束就连边。“边”意味着边两端的变  量在赋值时需要考虑另一个变量的取值。
  ![](media/image6.png)某些顶点/变量赋值后，这些顶点间的连边参与的约束条件被满足， 可以移除这些边，图有可能变成不连通的子图；对子图递归求解。
![](media/image211.jpeg)
问题：划分子图的方式太多，如何选择，使得每个子图都很容易求解？


一些例子
  ![](media/image169.png)![](media/image169.png)![](media/image7.png)教务处排课电路布局设计任务调度
  ![](media/image7.png)*. .** **.*

优化问题 =*⇒*CSP 问题
  ![](media/image6.png)未知最优解的最优化问题，不知道什么时候搜索停止；
  ![](media/image6.png)实际工程中，往往可以设置一个可接受的解的质量水平，将这个解  质量看成是一个约束条件，最优化问题的优化目标就转化成了约束  条件，得到了一个 CSP

![](media/image1.png)




## ********人工智能讲义
  **马尔科夫决策过程**


  February 25, 2020

### ****Outline
  
```
\*\*1\*\*
```
[搜索问题的变型]()
  
```
\*\*2\*\*
```
[马尔科夫决策过程描述]()
  
```
\*\*3\*\*
```

```
\*\*4\*\*
```
[MDP：最优策略]()[折扣因子]()


            ![](media/image214.jpeg)
搜索问题的一点小改变
  ![](media/image6.png)![](media/image7.png)任何一个状态用 *n **− **D *的向量描述，每一维称为状态的一个影响因素或表现特性。现实应用问题中，后继函数 *successors*(*s**, **a*) 在当前状态 *s *和行动 *a *的联合作用
  下，产生的后继通常不是 确定的？Why?
  ![](media/image169.png)模型的的不确定性，太多的影响因素没有被模型所考虑，用一种不确定的概率 *p*
  
```
=\*⇒\*
```
来综合所有其它影响因素。

|         |       |        |         |
|---------|-------|--------|---------|
|节点/状态|行动   |结果状态|代价/收益|
|*. . .*  |*. . .*|*. . .* |*. . .*  |


|                |                        |    |        |       |
|----------------|------------------------|----|--------|-------|
|节点/状态 (部分)|节点/状态 (部分)*⇒ **p*|行动|结果状态|代价   |
|*. . .*         |*. . .*                 |    |        |*. . .*|



```
=\*⇒\*
```

  ![](media/image215.jpeg)


|         |       |        |         |
|---------|-------|--------|---------|
|节点/状态|行动   |结果状态|代价/收益|
|*. . .*  |*. . .*|*. . .* |*. . .*  |


|                |                        |    |        |       |
|----------------|------------------------|----|--------|-------|
|节点/状态 (部分)|节点/状态 (部分)*⇒ **p*|行动|结果状态|代价   |
|*. . .*         |*. . .*                 |    |        |*. . .*|



          ![](media/image216.png)

解释说明
  ![](media/image7.png)如图，1,2,3,4 表示 4 个状态
  ![](media/image7.png)*p**ij*: 表示状态 *i **→ **j *的跳转概率
  ![](media/image169.png)上图只表示了一个行动 *a *导致各个状态之间的发生的状态跳转可能性，不同行动得到类似上图的，不同的状态转移图
  ![](media/image5.png)而经典搜索问题，图上的任何一条边就是一个具体的“行动”


经典搜索问题
  ![](media/image217.png)行动 *a*，确定地让搜索沿一条边前进；
  ![](media/image5.png)解：从初态到终态的一条路径或状态序列，表示为（初态，边 1，边 2，*. . . *，边
  *m*，终态）或者（初态，状态 1，状态 2，*. . . *，状态 *m*，终态）
  ![](media/image6.png)解也可以用行动来表示：（初态，行动 1，行动 2，*.** **.** **.** *，行动 *m*，终态）

新搜索问题：MDP
  ![](media/image7.png)行动 *a*, 随机地让搜索沿多条边前进；
  ![](media/image7.png)我们的目的是从找到初态到终态的路径/最优路径，但是行动 *a *带来后果是随机的，如何描述解？
  ![](media/image7.png)问题的解：每个状态，给出一个“最优行动”*a**∗**i** *，所谓最优，即尽管行动的后果不确定，但是“平均”看来，该行动得到的好处对于找“初态到终态”的路径是最大    的。
  ![](media/image7.png)此时问题的解，不是一条路径，而是“策略”：一组从状态到行动的映射关系。


            ![](media/image218.jpeg)
说明
  ![](media/image6.png)![](media/image7.png)游戏为回合制，每个回合开始时，你有两个选择：继续游戏或者退出游戏；    若你选择退出游戏，则你得到¥15，且游戏结束；
  ![](media/image7.png)
```
\*∼\*
```
若你选择继续游戏，则你得到¥4，游戏继续；此时产生一个 0 9 的随机数，若该随机数为 0，1，2，则游戏直接结束；否则，该回合结束；
  ![](media/image7.png)你的决策是什么？为了获得最多的钱！


          ![](media/image219.png)

问题分析
  ![](media/image6.png)![](media/image7.png)![](media/image7.png)第一回合主动退出收益：15*, *100%; 第二回合主动退出收益：19*, *70%； 第三回合主动退出收益：23*, *49%；
  ![](media/image7.png)*.** **.** **.*(第 *k** *+ 1 回合主动退出)：收益：15 + *k** **∗** *4, 获得该收益的概率 0*.*7*k*
  ![](media/image220.png)每回合都不主动退出的期望收益，参考上图
  
```
\*∗∗∗∗∗\*\*∗\*
```
0*.*3 4 + 0*.*7 0*.*3 8 + 0*.*7 0*.*7 0*.*3 12 + *. . . *= 40/3
  理解为：*n *个人参加游戏，都选择不主动退出，大家的平均收益



          ![](media/image221.png)

随机数游戏/一种掷骰子游戏: 描述为状态转移图
  ![](media/image7.png)![](media/image7.png)如上图所示，线型表示不同行动概率为 0 的边删除

MDP/马尔科夫决策过程: 一种搜索问题的变型
  ![](media/image7.png)![](media/image7.png)**S**: 状态空间初态：*s*0
  ![](media/image220.png)行动：*Action*(*s*)，给定状态 *s **∈ ***S**，合法行动集合
  ![](media/image220.png)状态转移概率：*T*(*s**, **a**, **s**′*)，从状态 *s *出发，采用行动 *a*，导致结果状态 *s**′ *的概率；
  ![](media/image5.png)![](media/image6.png)奖励：*Reward*(*s**, **a**, **s**′*)，状态转移 (*s**, **a**, **s**′*) 得到的收益目标测试：*isEnd*(*s*)
解释说明
  ![](media/image5.png)行动和状态转移概率一起定义了经典搜索问题的后继函数。
  ![](media/image6.png)奖励就是经典搜索问题中的路径耗散，这里我们关注最大化奖励，区别于    最小化路径耗散。
  ![](media/image7.png)马尔科夫性：下一时刻状态的概率分布（下一时刻各个状态出现的概率） 仅依赖当前时刻的状态相关。(注意：视频讲解中这里些没讲清楚）这里，    也和行动 *a** *相关，视行动 *a** *为当前状态的一个属性即可。


  ![](media/image7.png)![](media/image220.png)例子：形式化为 MDP **S **= *{ *结束，游戏中} *s*0 = *{ *游戏中}
  ![](media/image220.png)![](media/image220.png)行动：*Action*(*s*) = *{ *继续，退出} 状态转移概率：*T*(*s**, **a**, **s**′*)

```
()()
```
结束游戏中
*T*(*s**,** *继续*,** **s**′*) =10  结束*T*(*s**,** *退出*,** **s**′*) =  1   0
                0*.*3    0*.*7 游 戏中1    0
  ![](media/image6.png)奖励：*Reward*(*s**, **a**, **s**′*)，状态转移 (*s**, **a**, **s**′*) 得到的收益
  *Reward*(*s**,** *继续*,** **s**′*) = (0    0)*Reward*(*s**,** *退出*,** **s**′*) = ( 00)

4 4
  目标测试：*isEnd*(*s*)
  15 0



          ![](media/image221.png)

理解 MDP：定义在有向图上的搜索
  ![](media/image5.png)*n *个节点，每个节点的每个行动/策略会有一定的概率转移到其它的状态，故每个节点的每个行动/策略有 *n** *条“出边”，每条边用 “行动/策略，概率，收益”来标记
  经典搜索问题是 MDP 在概率只能取值为 0 或 1 时的特例



状态转移：*s **→ **s**′*
  ![](media/image5.png)
```
∑
```
任意给定一个状态 *s *和任意一个行动 *a*，其状态转移到一个可能的“后继状态”集合，而转移到这些可能后继状态的概率形成一个分布，即概率和为 1
  ![](media/image7.png)用公式描述，即*s**′**∈***S ***T*(*s**, **a**, **s**′*) = 1
  ![](media/image7.png)若重新定义概念“后继状态”：若 *s**′** *是 *s** *的后继状态，当且仅当
  *T*(*s**, **a**, **s**′*) *&gt; *0
  ![](media/image7.png)那么，经典搜索问题相当于，对任意给定的一组状态 *s *和行动 *a*， 有唯一后继状态 *s**′ *或没有后继状态。


解：对任何状态 *s*，定义一个最优行动 *a**∗*
  ![](media/image7.png)MDP 的解被称为“策略”，映射表
  ![](media/image7.png)![](media/image7.png)通常会造成许多从初态到终态的随机路径； 路径的数目是状态数目的指数函数；

  ![](media/image6.png)如何评价 MDP 的解策略评估！
  ![](media/image5.png)经典搜索问题，任何行动的结果是唯一确定的，所以只有唯一一条  从初态到终态的最优路径。


行动收益
  ![](media/image7.png)对每个行动 *s*，定义其收益为它导致状态转移带来的奖励： *U*(*s**, **a**, **s**′*) = *Reward*(*s**, **a**, **s**′*)
  ![](media/image7.png)
```
∑
```
该收益获得的概率是 *T*(*s**, **a**, **s**′*)
  ![](media/image7.png)该行动的期望收益：*s**′**∈***S**** ***T*(*s**,** **a**,** **s**′*)*U*(*s**,** **a**,** **s**′*)
路径收益
  ![](media/image220.png)路径 *s*0*, **a*0*, **s*1*, **a*1*, . . . , **s**e** *上所有行动带来的收益之和；
策略收益
  ![](media/image7.png)一个策略 (记为 *π*) 会造成多条从初态到终态的路径，每条路径的出现概率可能不一样，收益可能也不一样；
  ![](media/image7.png)所有从初态到终态的路径的收益期望，我们将之定义为 策略的价值，即策略收益，记为 *V**π*。


  ![](media/image6.png)计算一个策略的价值/值：枚举法计算每条随机路径的收益 *u**i*
  ![](media/image7.png)计算每条随机路径的出现概率 *p**i*
  ![](media/image7.png)求加权和 ∑*i **u**i**p**i*
存在问题
  ![](media/image7.png)有多少条随机路径？无穷条路径！如随机数游戏，可能永远不会退  出；可造成任意长度的路径；
  ![](media/image220.png)因此，上述计算一个策略的价值的方法，实际上是无法实现的；时  间需求太大/无限大。
  ![](media/image7.png)策略评估存在困难，基于策略评估的问题：如何在多个策略中选择“最优策略”？会更困难。


例子：如何计算一个策略的价值
  ![](media/image7.png)记策略/policy 为 *π *= *{*游戏中：继续*, *退出：\**}*
  ![](media/image7.png)策略 *π *的收益为：
  
```
\*×\*\*×\*
```
*V**π*(游戏中) = 30%4 + 70%(4 + *V**π*(游戏中))，解之，得到
  *V**π*(游戏中) = 40/3
推广：计算策略价值的方法
  ![](media/image220.png)
```
∑
```
思路：找到递推公式，后解之；
  ![](media/image220.png)通用地推公式：*V**π*(*s*) =*s**′**∈***S**** ***T*(*s**,** **a**,** **s**′*)[*U*(*s**,** **a**,** **s**′*) + *V**π*(*s**′*)]
  ![](media/image7.png)上述公式中 *s *表示初态/当前状态；每个状态都可以列出一个上述递推式，联立这些递推式，得到方程组（*n *个状态，*n *个未知数*V**π*(*s*),*n** *个线性方程），解之。


  ![](media/image7.png)![](media/image6.png)策略评估算法思想：解递推方程组的方法初始化所有状态的策略价值 *V**π*(*s*) = 0 Repeat *T *次:
      ![](media/image32.png)对每个状态 *s **∈ ***S**，执行：
      ![](media/image32.png)利用递推方程循环更新 *V**π*(*s*) = ∑*s**′**∈***S**** ***T*(*s**,** **a**,** **s**′*)[*U*(*s**,** **a**,** **s**′*) + *V**π*(*s**′*)]

算法评述
  ![](media/image7.png)![](media/image7.png)算法停止条件：相邻两次对 *V**π*(*s*) 的更新足够小，不妨设为 *T *次仅仅需要存储最近一次的 *V**π*(*s*) 的值
  ![](media/image7.png)时间代价：*O*( 状态数目 *× *循环次数 *× *后继状态数目)


策略 *π *: *s **∈ ***S ***→ **a **∈ **Action*(*s*)
  ![](media/image7.png)即 *a *= *π*(*s*)
  ![](media/image7.png)策略评估算法能计算一个策略的价值 *V**π*(*s*)

策略空间的大小
  ![](media/image7.png)假设有 *n *个状态 *s*1*, **s*2*, . . . , **s**n*
![](media/image220.png)策略空间的大小：Π*s**i**∈***S***|**Action*(*s**i*)*|*，状态数目 *|***S***|** *的指数函数
# 如何找到最优策略？


  ![](media/image222.jpeg)
Q-value
  ![](media/image7.png)Q-value: *Q**π*(*s**, **a*) 定义为从状态 *s *出发，采用行动 *a *后继续采用策略 *π *的价值/收益；
  ![](media/image6.png)Q-value 与 *V**π** *的区别：在状态 *s *时，采用了不同的行动，故 *V**π*(*s*) 仅仅是 *π, **s *的函数，而 *Q**π*(*s**, **a*) 是 *π, **s**, **a *的函数
  ![](media/image220.png)为什么要引入 Q-value? 讨论在状态 *s *下，哪一个行动会得到更多的收益。


```
\*V\*\*π\*(\*s\*) = ∑\*s\*\*′\*\*∈\*\*\*S\*\*\*\* \*\*\*T\*(\*s\*\*,\*\* \*\*a\*\*,\*\* \*\*s\*\*′\*)[\*U\*(\*s\*\*,\*\* \*\*a\*\*,\*\* \*\*s\*\*′\*) + \*V\*\*π\*(\*s\*\*′\*)] =
```

```
\*π \*( \*, \*\*a\*) =
```

```
\*s\*\*′\*\*∈\*\*\*S\*\*\*\* \*\*\*T\*(\*s\*\*,\*\* \*\*a\*\*,\*\* \*\*s\*\*′\*)[\*U\*(\*s\*\*,\*\* \*\*a\*\*,\*\* \*\*s\*\*′\*) + \*V\*\*π\*(  \*′\*)]
```
*Q*∑*s**′**∈**s** ***S**** ***T*(*s**,*∑*π*(*s*)*,** **s**′*)[*U*(*s**,** **π*(*s*)*,** **s**′*) + *V**π*(*s**′*)]    *s*



策略改进算法
  ![](media/image7.png)输入一个策略 *π*，输出一个更新的改进策略 *π**new*，充分利用马尔科夫性
  ![](media/image7.png)对任意状态 *s*，执行下述操作：
      ![](media/image31.png)![](media/image31.png)对不同的行动 *a **∈ **Action*(*s*)，计算 *Q**π*(*s**, **a*)； 更新 *π**new** *= arg max*a**∈**Action*(*s*) *Q**π*(*s**, **a*)

评述
  ![](media/image220.png)优点类似爬山法，把状态 *s *所有可能的行动都尝试一遍，找到期望奖励最大的行动，用来更新策略 *π*。

  ![](media/image7.png)
```
\*←\*
```
*π*任意初始化值
  ![](media/image7.png)Repeat *T*1  次（或者 *π** *不再变化为止）：
      ![](media/image31.png)评估策略，计算 *V**π*；
      ![](media/image31.png)![](media/image31.png)执行策略改进算法，得到 *π**new** **π **← **π**new*
算法评述
  ![](media/image220.png)保证全局最优性
  ![](media/image220.png)时间复杂度和初始解、状态数、行动数、后继状态数、迭代次数等  相关
问题:
  ![](media/image7.png)每次循环都要精确计算“经历过”的每个策略的价值，没有必要！  我们只要最优值！

  ![](media/image7.png)![](media/image7.png)对所有状态 *s** *初始化 *V*0*op**t*(*s*) *←** *0; for *t *= 1*, *2*, . . . , **T*0 次:
      ![](media/image31.png)对每一个状态 *s*，执行：
      *V**t**    ** *(*s*) *←** *max*a**∈**Action*(*s*) ∑ *′** ** **T*(*s**,** **a**,** **s**′*)[*Reward*(*s**,** **a**,** **s**′*) + *V**t**−*1(*s**′*)]
      ![](media/image31.png)


值迭代算法
*opt**s*
*opt*

  ![](media/image220.png)把策略评估和策略改进两个独立的过程结合在一起，放入一个过程  中完成
  ![](media/image5.png)同样能保证全局最优性
  ![](media/image6.png)对中间经历过的策略没有完整评估过。
  ![](media/image6.png)
```
\*opt\*
```
订正：视频讲解中有误。*V**t**−*1(*s**′*) 中 *t** *不是时刻，是指第 *t** *次迭代，第 *t *次迭代会用到前一次迭代算出来的结果。


计算路径收益时，因为未经过的路径是否会经历，不确定
  ![](media/image7.png)所以，添加一个折扣因子 *λ*，来重新计算/估计路径的收益

```
∑
```
一条随机路径：*s*0*, **a*1*, **r*1*, **s*1*, . . .*
  ![](media/image220.png)没有引入折扣，路径收益为：*i** **r**i*
  ![](media/image223.png)引入折扣因子后，路径收益为：*r*1 + *λ**r*2 + *λ*2*r*3 + *λ*3*r*4 + *. . .*
  ![](media/image224.png)
```
\*≤\*
```
折扣因子：0 *&lt;** **λ*1，通常意味着将来可能的收益是有可能无法实 现的，因此在当前考虑行动时，行动带来的将来的收益需要“打折”，而且离现在越远的将来，将来收益打折的强度越大。

```
∑
```
MDP：引入折扣因子的变化
  ![](media/image6.png)递推方程：*V**π** *=*s**′** **T*(*s**,** **a**,** **s**′*)[*Reward*(*s**,** **a**,** **s**′*) + *λ**V**π*(*s**′*)]
  ![](media/image5.png)*λ *= 1 的特殊情形

![](media/image1.png)



## ********人工智能讲义
  **强化学习**


  February 26, 2020

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```

```
\*\*3\*\*
```

```
\*\*4\*\*
```

```
\*\*5\*\*
```
[引入问题]()[强化学习]()[更新参数]()[选择行动]()[函数逼近]()


MDP/马尔科夫决策过程
  ![](media/image224.png)![](media/image224.png)**S**: 状态空间初态：*s*0
  ![](media/image7.png)行动：*Action*(*s*)，给定状态 *s **∈ ***S**，合法行动集合
  ![](media/image7.png)状态转移概率：*T*(*s**, **a**, **s**′*)，从状态 *s *出发，采用行动 *a*，导致结果状态 *s**′ *的概率
  ![](media/image6.png)![](media/image6.png)奖励：*Reward*(*s**, **a**, **s**′*)，状态转移 (*s**, **a**, **s**′*) 得到的收益目标测试：*isEnd*(*s*)
  ![](media/image7.png)折扣因子 *λ*

如果描述不完备，会怎样？


MDP/马尔科夫决策过程
  ![](media/image6.png)![](media/image7.png)**S**: 状态空间初态：*s*0
  ![](media/image7.png)行动：*Action*(*s*)，给定状态 *s **∈ ***S**，合法行动集合
  ![](media/image7.png)状态转移概率：*T*(*s**, **a**, **s**′*)，从状态 *s *出发，采用行动 *a*，导致结果状态 *s**′ *的概率
  ![](media/image7.png)![](media/image224.png)奖励：*Reward*(*s**, **a**, **s**′*)，状态转移 (*s**, **a**, **s**′*) 得到的收益目标测试：*isEnd*(*s*)
  ![](media/image224.png)折扣因子 *λ*
如何找到缺失的部分？
  ![](media/image7.png)![](media/image7.png)通常现实应用中我们并不知道状态转移概率和奖励的细节。  强化学习！


      ![](media/image225.jpeg)
问题描述
  ![](media/image6.png)老虎机（one-arm bandit）是一种用零钱赌博的机器，因为上面有老虎图案的筹码而得名。
  ![](media/image7.png)老虎机有三个玻璃框，里面有不同的图案，投币之后拉下拉杆，就会开始转，如果出现特定的图形（比如三个相同）就会            吐钱出来，出现相同图型越多奖金则越高。
  ![](media/image7.png)1895 年——查理·费 (Charlie Fey ,Jzplay Com) 发明第一台商业老虎机。
  ![](media/image7.png)![](media/image7.png)若有两台老虎机 *A *或 *B*，需要投币进行游戏，游戏返回奖励的金额和概率是不知道的，可能是随机的结果； 假设赌客可以连续有选择地投币，进行重复游戏。
  赌客如何选择才能最大获益？


  ![](media/image7.png)MDP                                                          与 强 化 学 习MDP：存在一个上帝，知道了所有的转移概率和奖励情况，寻找最优策略；称为“离线”决策
  ![](media/image226.png)![](media/image226.png)MDP：所有的决策判断过程都可以在头脑中“虚拟一遍”/仿真一次； MDP：*f *已知
  ![](media/image226.png)强化学习：没有人知道所有的转移概率和奖励情况，只能看到部分情况，寻找最     优策略；称为“在线”决策
  ![](media/image7.png)强化学习：需要花费代价去尝试或“探索”未知的情况（转移概率和奖励），然后逐步调整策略。
  ![](media/image7.png)强化学习：*f *未知，在寻找最优策略的过程中，逐步了解/完善 *f*
思考
  ![](media/image7.png)![](media/image6.png)电脑游戏“高手”和“低手”之间的差别在哪儿？ 玩牌，打麻将的水平差异在哪儿？
  ![](media/image5.png)招聘时工作经历的作用是什么？


    ![](media/image227.png)

            强化学习的例子：生活经验
  生活中的任何一个行动，会得到好的/不好的收益
  人会从行动/收益中汲取经验教训，调整自己今后的行动
  人的一生在不停地行动、收集反馈、学习、行动、收集反馈、......



问题描述
  ![](media/image7.png)已知：序列 *s*0*, **a*1*, **r*1*, **s*1*, **a*2*, **r*2*, . . . , **a**n**, **r**n**, **s**n*，其中 *s**i**, **i *= 0*, *1*, . . . , **n*
  表示状态，*a**i**, **i *= 1*, *2*, . . . , **n *表示行动，*r**i**, **i *= 1*, *2*, . . . , **n *表示奖励
  ![](media/image7.png)求解：给每个状态确定一个“最佳行动”，即找到最优策略

分析与理解
  ![](media/image7.png)与 MDP 的差异在于已知条件
      ![](media/image31.png)强化学习，已知样本数据序列，可能不止一个序列；
      ![](media/image31.png)MDP，已知转移概率和奖励的全部信息。
  ![](media/image6.png)强化学习和 MDP 所要求目标是一致的。


算法框架
  ![](media/image6.png)for *t *= 1*, *2*, . . .*
      ![](media/image31.png)
```
\*−\*
```
选择行动 *a**t** *= *π*(*s**t** *1)
      ![](media/image31.png)收集反馈奖励 *r**t*，获得新状态 *s**t*
      ![](media/image31.png)更新参数

分析与理解
  ![](media/image6.png)通用框架，解释了什么是强化学习。类似于机器学习中的增量式学  习、在线学习。
  ![](media/image7.png)![](media/image7.png)选择行动 *a**t** *= *π*(*s**t**−*1)，*π*( · ) 从何而来？ 更新参数，参数是什么？怎么更新？


强化学习：参数及其更新 思想： 强化学习较之于 MDP，就少了转移概率和奖励，那么想方法把转移概率和奖励计算出来，问题得解。
  ![](media/image226.png)已知：*s*0*, **a*1*, **r*1*, **s*1*, **a*2*, **r*2*, . . . , **a**n**, **r**n**, **s**n*
  ![](media/image228.png)求参数：*T*(*s**, **a**, **s**′*) 和 *U*(*s**, **a**, **s**′*)

蒙特卡洛方法：出现频率代替概率
  ![](media/image5.png)从已知数据中任何状态 *s *开始，(*s**, **a**, **r**, **s**′*) 视为“一个/一段/一组数据”，原数据序列被分割成 *n** *段；
  ![](media/image7.png)
```
\*#\*(\*s\*\*,\*\*a\*)
```

```
\*#\*(\*s\*\*,\*\*a\*\*,\*\*s\*\*′\*)
```
计数，并计算 *T*ˆ(*s**,** **a**,** **s**′*) =  *#*(*s**,**a**,**s**′*) *,** **U*ˆ(*s**,** **a**,** **s**′*) =  ∑*r**  **in**  *(*s**,**a**,**r**,**s**′*) *r*
  ![](media/image7.png)用 *T*ˆ(*s**,** **a**,** **s**′*) 近似估计 *T*(*s**,** **a**,** **s**′*)*,** **U*ˆ(*s**,** **a**,** **s**′*) 近似估计 *U*(*s**,** **a**,** **s**′*)


例子：
  ![](media/image228.png)已知数据：*s*1*, **A**, *3*, **s*2*, **B**, *0*, **s*1*, **A**, *5*, **s*1*, **A**, *7*, **s*1
  ![](media/image229.png)估计参数/模型：*T*ˆ(*s*1*,** **A**,** **s*1) = 2/3*,** **U*ˆ(*s*1*,** **A**,** **s*1) = (5 + 7)/2 = 6

存在问题
  ![](media/image6.png)样本数据是否满足独立性假设；
  ![](media/image6.png)很多状态的行动没有数据，或者说很多计数是 0
  ![](media/image6.png)样本数据量要求大
  ![](media/image7.png)这一类方法称为：基于模型的蒙特卡洛方法。所谓模型，就是所有  的转移概率和奖励构成的集合。
              不求模型，可以吗？


  *V**π*(*s*) = ∑*s**′**∈***S**** ***T*(*s**,** **a**,** **s**′*)[*U*(*s**,** **a**,** **s**′*) + *λ**V**π*(*s**′*)]
来自同一策略的已知数据
  ![](media/image7.png)![](media/image7.png)若所有已知数据来自同一策略 *π*，能否求得策略 *π *的价值/value? 当 *T*( · )*, **U*( · ) 未知时，用基于模型的蒙特卡洛方法估计其值，无法获得“完美”描述的 MDP，因为很多 (状态, 行动) 对没有出现；

执行策略 *π*，得到一条随机路径
  ![](media/image7.png)已知数据：*s*0*, **a*1*, **r*1*, **s*1*, **a*2*, **r*2*, . . . , **a**n**, **r**n**, **s**n*
  ![](media/image7.png)![](media/image7.png)定义引入折扣因子的时刻 *t** *的收益：*u**t** *= *r**t** *+ *λ**r**t*+1 + *λ*2*r**t*+2 + *. . . *用 *u**t** *的均值估计/当成 *Q**π*(*s**, **a*)：即将 *u**t** *按 (*s**, **a*) 不同取值分组， 然后求组内均值。


例子
  ![](media/image230.png)已知数据：*s*1*, **A**, *3*, **s*2*, **B**, *0*, **s*1*, **A**, *5*, **s*1*, **A**, *7*, **s*1
  ![](media/image7.png)*Q**π*(*s*1*, **A*) = (*u*1 + *u*3 + *u*4)/3 = (15 + 12 + 7)/3 = 34/3

等价的算法描述：增量式地计算
  ![](media/image6.png)对任意时刻 *t*，对应数据段 (*s**, **a**, **r*):
      ![](media/image31.png)
```
令：\*ξ \*=
```
计算出 (*s**, **a**, **u**t*)
          ![](media/image32.png) 1 (*s**,**a*)更新次数+1
      ![](media/image32.png)更新：*Q**π*(*s**, **a*) = (1 *− **ξ*)*Q**π*(*s**, **a*) + *ξ**u**t*
注意体会和理解 *Q**π** *的更新计算过程
没用到模型相关的东西！所以称为“模型无关”的方法


Q 值的更新：*Q**π*(*s**, **a*) = (1 *− **ξ*)*Q**π*(*s**, **a*) + *ξ**u**t*
  ![](media/image7.png)
```
\*−\*\*−\*
```
也可写成：*Q**π*(*s**,** **a*) = *Q**π*(*s**,** **a*)*ξ*(*Q**π*(*s**,** **a*)*u**t*)，其中 *u**t** *的估计是否准确，称 Q 值更新的关键

模型无关的方法 *u**t** *= *r**t** *+ *λ**r**t*+1 + *λ*2*r**t*+2 + *. . .*，仅从数据中来估计 *u**t** **Q**π*(*s**, **a*) = (1 *− **ξ*)*Q**π*(*s**, **a*) + *ξ**u**t*


```
\*⇒\*
```
自助法 =   SARSA 算法 *u**t** *= *r**t** *+ *λ**Q**π*(*s**′**,** **a**′*)，从以前的积累 *Q**π*(*s**′**,** **a**′*)
和新数据中估计 *u**t*
*Q**π*(*s**,** **a*) = (1 *−** **ξ*)*Q**π*(*s**,** **a*) + *ξ*(*r**t** *+ *λ**Q**π*(*s**′**,** **a**′*))



最优策略：方法一
  ![](media/image231.png)模型无关的方法评估给定的策略 *π*
  ![](media/image7.png)利用策略改进算法获得新策略 *π **← **π**new*
  ![](media/image7.png)![](media/image6.png)循环迭代上述过程，需找最优策略。对应 MDP 中的策略迭代算法。

最优策略：方法二
  ![](media/image7.png)Q-学习
  ![](media/image7.png)思想：模型无关的方法来获得 *Q**opt*
  ![](media/image7.png)对应 MDP 中的值迭代算法。


MDP 中：值迭代 *⇒ *最优策略
  ![](media/image7.png)Q 值更新：

  
```
\*←\*\* \*\*a\*\*∈\*
```

```
\*′\*\*∈\*
```
*Q**opt*(*s**,** **a*)*max*
*Action*(*s*)
*s*∑**S**** ***T*(*s**,** **a**,** **s**′*)[*Reward*(*s**,** **a**,** **s**′*) + *λ**V**op**t*(*s**′*)]



强化学习中：Q 学习 *⇒ *最优策略
  ![](media/image6.png)Q 值更新：
  *Q**opt*(*s**,** **a*) *←** *(1 *−** **ξ*)*Q**π*(*s**,** **a*) + *ξ*(*r** *+ *λ**a**′**∈** **max*
**
*Q**π*(*s**′**, **a**′*))
*′*


比较：SARSA 算法 *⇒ *评估策略 *π*
*Action*(*s *)

  Q 值更新：*Q**π*(*s**,** **a*) *←** *(1 *−** **ξ*)*Q**π*(*s**,** **a*) + *ξ*(*r**t** *+ *λ**Q**π*(*s**′**,** **a**′*))


算法框架
  ![](media/image232.png)for *t *= 1*, *2*, . . .*
      ![](media/image31.png)
```
\*−\*
```
选择行动 *a**t** *= *π*(*s**t** *1)
      ![](media/image31.png)收集反馈奖励 *r**t*，获得新状态 *s**t*
      ![](media/image31.png)更新参数

解释说明
  ![](media/image232.png)三台老虎机：你选择哪一台去试试？Exploration
  ![](media/image232.png)如果我对某一台老虎机，不妨设为  A，的特点有一定了解了，我想了解得更精确一点，那么我继续试 A。Exploitation
  ![](media/image6.png)了解少的老虎机也许意味着更大的机遇，相应存在更多风险；了解多的老虎机能够给出较稳定的回报，但是我们要追求回报“最大化”

### ********Exploration VS Exploitation
特例 1：贪婪策略

  ![](media/image5.png)选择行动：arg*max*
          *a**∈**Action*(*s*)
  ![](media/image6.png)最强 Exploitation
*Q**opt*(*s**, **a*)


特例 2：随机策略
  ![](media/image7.png)![](media/image7.png)选择行动：*random*(*Action*(*s*)) 最强 Exploration

平衡二者
  ![](media/image7.png)通常认为要兼顾二者。
  ![](media/image7.png)*ϵ**− *贪婪：(*ϵ *随时间减小)

  *π*(*s*) = arg*max*
        *a**∈**Action*(*s*)
*Q**opt*(*s**, **a*) with probability 1 *−** **ϵ*

  *π*(*s*) = *random*(*Action*(*s*)) with probability *ϵ*



Q 学习：能处理已经出现过的状态和行动，
  ![](media/image6.png)现实应用中，可能还有更多的状态和行动从来没有出现过，如何计  算 *Q*(*s**, **a*)?

用“函数逼近”来近似未出现的 (*s**, **a*)
  ![](media/image6.png)如线性回归模型，用已有的 (*s**, **a*)Q 值来估计没出现的 (*s**, **a*) 的 Q
  值，相似 (*s**, **a*) 的 Q 值的线性组合
  ![](media/image6.png)何谓相似 (*s**, **a*)？特征相似，状态 *s *和行动 *a *的特征，比如都能带来好收益的特征，带来糟糕收益的行动等



例子：线性回归逼近
  ![](media/image232.png)定义 *ϕ*(*s**, **a*) 是 (*s**, **a*) 的特征向量，而定义
  *Q**opt*(*s**, **a*; *w*) = **W **· *ϕ*(*s**, **a*)
  ![](media/image5.png)根据已有数据（用机器学习的算法）训练出 **W**，然后就可以对任意未观测到的 (*s**, **a*) 实现 *Q *值的估计。

问题
  ![](media/image7.png)![](media/image7.png)函数模型/形式如何确定？ 特征提取函数如何设计？

![](media/image1.png)



## ********人工智能讲义
  **博弈与对抗性搜索**


  February 26, 2020

### ****Outline
  
```
\*\*1\*\*
```
[博弈论简介]()
  
```
\*\*2\*\*
```
[博弈、MDP 和搜索]()
  
```
\*\*3\*\*
```

```
\*\*4\*\*
```
[博弈树：描述博弈的扩展形式]()[基于博弈树的推理]()


囚徒困境问题描述
  ![](media/image7.png)假设有两个疑犯被警察抓住。并且被分开关押在不同的囚室。警察  强烈怀疑他们和一场抢劫案有关，但是，没有充足的证据。然而， 他们都拒捕的事实也是可判刑的。两个疑犯都被告知以下结果：
  ![](media/image5.png)“如果你坦白，而另外一人抵赖，则你马上释放；另外一人将承担全  部罪行，将会被判刑 10 年
  ![](media/image7.png)如果你们都坦白，你们的罪行将被证实。但由于你们有认罪的表现
  ——判刑 4 年。
  ![](media/image7.png)如果你们都不坦白，那么没有证据证明你们的抢劫罪，我们将以拒  捕罪控告你们——判刑 1 年。
  ![](media/image7.png)另外一方也正在接受这样的审讯。你是坦白还是抵赖？”


        ![](media/image233.png)

  ![](media/image7.png)描述博弈的收益矩阵：解释说明适用于 二人博弈；
  ![](media/image7.png)行代表一个 player1，列代表另一个 player2；行表示 player1 的不同策略/行动；列表示 player2 的不同策略/行动；
  ![](media/image7.png)![](media/image232.png)每个单元格的数对含义为 (player1 的收益*, *player2 的收益); 一个简单的表格清晰地描述了复杂的博弈问题。


![](media/image233.png)![](media/image234.png)
![](media/image235.png)![](media/image236.png)

![](media/image237.jpeg)![](media/image238.png)
![](media/image239.jpeg)

博弈的基本要素
  ![](media/image7.png)参与者/player：*P*1*, **P*2*, . . . , **P**n**, **n **≥ *2；
  ![](media/image7.png)![](media/image7.png)策略集/行动集：每个参与者都有一个行动备选项/可能的策略，策略选中后执行就变成了“行动”；*P**i**  *的行动集合记为 *{**a**i*1*,** **a**i*2*,** **.** **.** **.**}*；收益/payoff: *P**i*(*a*1*j*1 *, **a*2*j*2 *, . . . , **a**nj**n *) 表示参与者 *P**i** *在所有人的策略为 (*a*1*j*1 *, **a*2*j*2 *, . . . , **a**nj**n *) 时的收益。
进一步解释
  ![](media/image232.png)“完美信息”是指每个参与者对博弈信息完美了解；了解别人如同了  解自己；
  ![](media/image6.png)“静态博弈”是指所有参与者同时选择策略并行动；
  ![](media/image6.png)参与者都是“理性的”：追求自己利益的最大化；也知道其他人都是如此；
  ![](media/image7.png)独立决策：参与者之间不协商。


![](media/image240.png)![](media/image241.png)

寻找给定其他参与者的策略时的最佳应对
  ![](media/image232.png)如上图所示，当疑犯 2 采用“抵赖”策略时，疑犯 1 的 最佳应对是“坦白”；
  ![](media/image232.png)最佳应对：针对参与人 *P*2 的策略 *T *=’ 抵赖’，若参与人 *P*1 采用策略 *S *=’ 坦白’ 产生的收益大于或等于自己的任何其他策略，则称参与人 *P*1 的策略 *S *是参与人 *P*2 的策略 *T *的最佳应对。
  *P*1(*S**, **T*) *≥ **P*1(*S**′**, **T*), 其中 *S**′ *是参与人 *P*1 的所有策略。
  ![](media/image6.png)最佳应对一定存在，不一定唯一。
  ![](media/image7.png)严格最佳应对（最佳应对的定义中 *≥*变成 *&gt;*）不一定存在。


![](media/image237.jpeg)![](media/image238.png)

最佳应对 =*⇒ *占优策略
  ![](media/image6.png)如上图所示，不管疑犯 2 采用哪种策略，疑犯 2 的最佳应对都是
  “坦白”，所以“坦白”是疑犯 1 的占优策略；
  ![](media/image7.png)参与者的占优策略 *S*，是指该策略对于其他参与者的所有策略组合都是最佳应对；
  ![](media/image7.png)参与者的 严格占优策略 *S*，是指该策略对于其他参与者的所有策略组合都是严格最佳应对；
  如果参与人有严格占优策略，则可预期他会采取该策略。 占优策略可以用来简化求解过程。


    ![](media/image242.png)

办法
  ![](media/image6.png)![](media/image6.png)混合策略； 纳什均衡。


三客户博弈问题描述
  ![](media/image7.png)假设有两家公司，都希望和 A、B、C 三个大客户之一洽谈生意。每家公司都有三种可能的策略：是否找客户 A、B 或 C。它们决策的考量如下：
  ![](media/image6.png)![](media/image6.png)若两家公司都找同一个客户，则该客户会给每个公司一半的业务。  公司 1 规模太小，以至于不能靠自身找到客户源。所以，只要它和
  公司 2 分别寻找不同的客户洽谈生意，则公司 1 获得的收益将会是
  0（生意做不成）。
  ![](media/image232.png)假设公司 2 单独寻找客户 B 或 C 洽谈生意，则会得到客户 B 或 C 的全部业务。但是 A 是一个大客户。寻找客户 A 洽谈生意时，必须和公司 1 合作才能接下业务。
  ![](media/image7.png)因为 A 是一个大客户，和它做生意的收益是 8（假设两家公司合作， 则每家公司会得到收益 4）。但是，和 B 或 C 做生意的收益价值是 2（合作的话，每个公司收益是 1）。


![](media/image243.png)![](media/image244.png)

解释说明
  ![](media/image6.png)![](media/image7.png)两家公司都没有严格占优策略如何讨论博弈的走向（结果）？
  ![](media/image7.png)若博弈可以重复（假设了解了对方行动之后，可以撤回决定，重做决定），结果不确定！


纳什均衡认知
  ![](media/image5.png)假定参与者 *P*1 选择策略 *S*，参与者 *P*2 选择策略 *T*。若 *S** *是 *T** *的最佳应对，且 *T** *也是 *S** *的最佳应对，则称策略组 (*S**, **T*) 是一个纳什均衡。

纳什均衡的理解
  ![](media/image7.png)![](media/image7.png)在均衡状态，任何参与人都没有动机（理性的理由）去换一种策略;  纳什均衡可以被看成是一种信念上的均衡互;
  因为是最佳应对，谁也不可能通过单方面改变策略而得到额外好处，  尽管如果两人都改变可能都会更好（相比都不改变而言）。


    ![](media/image245.png)


硬币配对游戏：零和博弈的例子
  ![](media/image6.png)![](media/image7.png)两个参与者甲乙各持一枚硬币，同时选择自己硬币的朝向/正反面； 若两人选择的朝向相同，则已获胜，赢得甲的硬币；反之，甲赢得已的硬币。
![](media/image246.png)

  不存在一组互为最佳应对（纯策略意义下的纳什均衡）.

思考
  ![](media/image7.png)![](media/image7.png)若这样的博弈重复进行若干次，你会如何考虑自己的策略？  预测对方采用不同策略的概率，据此确定自己的策略
![](media/image7.png)不要让对方了解自己采用不同策略的概率混合策略
  ![](media/image232.png)此时，“策略”可以看成是在两种固定策略（纯策略）之间选择的概率。
混合策略均衡：互为最佳应对
  ![](media/image7.png)在各自概率策略的选择下，双方的收益期望互为最大（任何单方面改变不    会增加收益）
  ![](media/image7.png)纳什的奠基性贡献：证明了具有有限参与者和有限纯策略集的博弈一定存在纳什均衡（包括混合策略均衡），纳什均衡定理
  ![](media/image6.png)一般来说，找到混合策略的纳什均衡是很困难的，但在某些特定条件下可    能有系统的方法。



石头、剪刀、布
  ![](media/image247.png)![](media/image5.png)当你知道对手的策略是 (*p*1*, **p*2*, **p*3) 之后，你一定 不会输！ 你的最佳应对是什么？
  ![](media/image6.png)双方的策略是互为 最佳应对/纳什均衡吗？
  ![](media/image6.png)你是理性的人，当你不知道对手的策略（习惯）时，该如何选择策略？最佳应对 (1/3,1/3,1/3)，不要让对方知道你的概率（习惯），否则你的对手稍微聪明一点，你就输了。



动态博弈：参与者依次行动
  ![](media/image6.png)与静态博弈的区别在于各个参与者的行动不是同时的
  ![](media/image5.png)静态博弈时，我们把策略和行动等同看待，因为参与者“同时”进  行决策，没有观察到其他参与人采取了什么行动，所以实施行动时  没有针对性。同步
  ![](media/image7.png)动态博弈中，后行动的参与人采取行动之前已观察到了先行动参与  人的行动结果，所以可以根据观察到的结果采取有针对性的行动。  异步
  ![](media/image7.png)行动是“做什么”；策略是“在什么情况下做什么”。


    ![](media/image248.png)

  Othello/翻转旗: Murakami vs. Logistello
![](media/image5.png)1997: The Logistello software crushed Murakami by 6 games to 0
  ![](media/image6.png)![](media/image7.png)动态博弈，两个参与者依次执行行动； 零和博弈；


![](media/image249.jpeg)![](media/image250.jpeg)
  Mr.  Tinsley VS. Chinook
  ![](media/image5.png)![](media/image6.png)![](media/image7.png)Name: Marion Tinsley Profession: 数学老师Hobby: 西洋跳棋
  ![](media/image7.png)Record: 45 年仅仅输掉 7 次棋
  ![](media/image7.png)1992 年 8 月，Mr. Tinsley 对上 Chinook，4 胜 2 负 33 平，Tinsley 40 多年遇到的第 6、7 负，保持了 40 多年的世界冠军纪，对手对上他，祈求的是“平局”，胜利是想都不敢想的，1995 年去世。


      

              卡斯帕罗夫 VS. 深蓝
  ![](media/image6.png)1[A9I ]()97: Deep Blue 3Fe胜bruar1y 26负, 20220  平

  20/54

### ********Alpha Go

![](media/image253.jpeg)

  异步行动：两个棋手依次落子。动态博弈的例子

                    ![](media/image254.jpeg)中国象棋：博弈描述
                      ![](media/image23.png)参与者/agent：
                      *{**Red**, **Black**}** *≜ *{**P*1*, **P*2*}*
                      ![](media/image163.png)状态 *s*：棋局中任何一个“局面”（棋子分布情况）
                      ![](media/image255.png)![](media/image23.png)策略/行动：参与者 *P**i *可以执行的让棋子进行的“合法”移动。终态：某个参与者胜利或平局；
                      ![](media/image19.png)
```
\*−\*\*−\*
```
效用函数：胜利的参与者获得奖励 *r** *= +1，失败者获得*r *= 1 的奖励；平局都获得 0 的奖励； 零和。
说明
  ![](media/image7.png)行动、策略、混合策略：策略被执行就变成行动，混合策略是各种行动的执行概率。
  ![](media/image256.png)![](media/image5.png)零和博弈动态博弈


MDP =*⇒ *动态博弈
  ![](media/image6.png)![](media/image7.png)完美信息下的动态博弈：每个参与者知道一切可以知道的公共信息；  将对手视为 MDP 建模中无法观察和了解的未知因素；
  ![](media/image256.png)完美信息下的动态博弈就是一个参与者和所有未知因素综合而成的  虚拟“虚拟参与者”之间的二人博弈，也就是 MDP。

  ![](media/image7.png)下棋并非 MDP，而是强化学习不知道转移概率
  ![](media/image256.png)![](media/image256.png)不知道每步/每次行动的奖励需要逐步去了解和学习


博弈即搜索
  ![](media/image256.png)![](media/image256.png)状态：参与者的行动/策略及其各自对应的收益； 后继函数：参与者可能的各种新策略；
  ![](media/image7.png)初态：随机或某个给定初态；
  ![](media/image7.png)终态：均衡态（不管任何一个参与者如何调整策略/行动，各自的收益不再增加）；
  ![](media/image6.png)路径耗散：单步路径耗散为常数 *c*
解释说明
  ![](media/image7.png)![](media/image7.png)参与者、参与者的行动及其各自收益，是描述状态的向量的分量； 博弈问题描述为搜索问题时，解序列并不是追求的目标；“均衡的”终态才是关注的目标。
  ![](media/image7.png)路径耗散在博弈中不大关注。


效用函数可能只在终态是有意义
  ![](media/image5.png)博弈中，中间状态的效用可能不重要，比如，下棋尽管丢子很多，  但是最终早一步取得胜利

  ![](media/image7.png)博弈有两个/多个相互“拆台”或“合作”的参与者交替“寻找”路径而经典搜索问题只有一个参与者
  ![](media/image7.png)博弈可理解为从初态开始的寻路过程中，两个参与者交替给路径添  加一条边，但是二者的目标状态集合不一样。
  ![](media/image7.png)参与者不关心路径的长度，不过分“纠结”眼前的利益大小，到达  自己的目标状态就是“胜利”。
  ![](media/image6.png)一个参与者不知道其他参与者“将来”会如何行动
需要新的方法来描述博弈搜索过程：博弈树


来自 MDP
  ![](media/image5.png)策略是任意状态到行动的映射机制。执行策略会产生大量的随机路  径，所有随机路径的期望收益就是 MDP 的策略收益。
  ![](media/image6.png)策略评估是依据 MDP 策略收益来评价策略的优劣。

博弈评估
  ![](media/image6.png)具有对抗性。
  ![](media/image6.png)只能控制部分状态下的策略；因此博弈（的策略）评估包含对对手  策略的“假设”。
  ![](media/image7.png)博弈评估中，路径中“分支”不会额外付出“代价”作为参与者的“收益”，仅仅描述终态的收益在博弈树非叶结点上的聚集。



  ![](media/image257.png)

从哪个盒子中抽取？
  ![](media/image6.png)![](media/image5.png)假设三个黑盒 A、B、C 中的数 (钱) 都是公开的，但是看不见； 甲一个人从中抽取一个数，获得相应的数额的钱，他该如何选择？
  若甲乙两个人依次从中抽取，数字大则赢，各自该如何决策/行动？


      ![](media/image258.jpeg)

期望最大化
  ![](media/image7.png)计算每个黑盒的期望收益
  ![](media/image7.png)![](media/image7.png)然后比较各个黑盒的期望收益，取最大者边上权值是选择该边的概率
  ![](media/image6.png)叶子节点是各种结果最终的收益。
博弈树


![](media/image259.jpeg)![](media/image260.jpeg)

情况发生改变：两个人（甲乙）玩同一个游戏
  ![](media/image6.png)每个节点表示参与者的一个决策状态；
  ![](media/image256.png)从跟到叶的一条路径表示一个解，一条搜索路径。
  ![](media/image256.png)对抗性智力游戏中：路径是两个“相互拆台”的参与者共同“生产”出来，不同于华容道等      问题，一个参与者“生产”出来。
  ![](media/image6.png)故分别用不同的节点符号（正立的三角形和倒立的三角形）区分两个参与者，如右图。
  ![](media/image6.png)
```
\*⇒\*
```
期望最大化 =   每个参与者都希望在多个可能性中选择对自己最好的/最有利的。零和博弈：对甲最好，则是对已最差。
  ![](media/image7.png)右上图中，节点的“值”表示参与者甲的收益。甲能控制的是正立三角形（尖角朝上），会选择各分支中的最大值（正立三角形的决策）；乙能控制的是倒立三角形（尖角朝下），乙的收益是负得越多越好（负是指甲付出代价，图中顶点的权值的参照物都是参与人甲），所以甲就会思考“已是一个理性的聪明人，他会做出对他自己最有利的决策，乙会在他所有的决策中选择负得最多的分支”，即倒立三角形的决策是“取各个分支中最小值”

![](media/image261.png)绿色和黄色方框分别表示两个不同参与者参与决策/控制的“局面” 绿色参与者的收益标注在节点附近。绿色
参与者最求收益最大。

黄色参与者的收益与绿色参与者的收益和为 0，所以黄色参与者的收益在以绿色参与者为参照时，可以认为黄色参与者追求图中收益数值的最小。





  叶子节点的权值表示从根开始到叶的搜索路径，参与者获得的收益


              ![](media/image261.png)

博弈树的构造
  ![](media/image7.png)绿色参与者以他当前面对的棋局为根节点，考虑对手（黄色参与者）  的行动；构建博弈树/搜索树；
  ![](media/image7.png)黄色参与者有两种行动，绿色参与者都进行了“进一步”的考虑，  成为博弈树的第二层节点；
  ![](media/image7.png)黄色参与者的任何行动，绿色参与者有可以有各自的不同应对；该  过程可以循环迭代下去，构成博弈树。


![](media/image261.png)![](media/image262.png)![](media/image263.png)

基于博弈树的推理
  ![](media/image6.png)绿色参与者在有限的时间内，假设能思考到前进 *h** *层，可能没有达到博弈结束；
  ![](media/image256.png)棋手水平的高低，可用思考的“深度”*h *来衡量；
  ![](media/image256.png)经典的搜索算法：估计将来 *h** *层节点的“收益”，向树根方向执行 “最小最大值”算法



![](media/image264.png)![](media/image265.png)



![](media/image266.png)![](media/image267.png)



![](media/image268.png)![](media/image269.png)



![](media/image270.png)![](media/image271.png)



![](media/image272.png)![](media/image273.png)



![](media/image274.png)![](media/image275.png)



![](media/image276.png)![](media/image277.png)



![](media/image278.png)![](media/image278.png)



![](media/image279.png)![](media/image280.png)



![](media/image281.png)![](media/image282.png)

*α **− **β ***剪枝**
![](media/image283.png)
*α **− **β *剪枝原理：减少需要检验的分枝数量
  ![](media/image6.png)*α *值：任何一个需极大化的节点，以其为根的子树中，目前找到的极大值
  ![](media/image7.png)*β *值：任何一个需极” 小” 化的节点，以其为根的子树中，目前找到的极小值
  ![](media/image7.png)存在问题：如何确定每层节点的检验次序？对搜索效率至关重要。



基本原理
      ![](media/image256.png)![](media/image32.png)![](media/image31.png)算法的主体是蒙特卡洛树搜索，但是加入两个深度网络来改进： policy network：卷积神经网络，嵌入强化学习思想，收集已有棋谱， 估计对手落子的区域，即随机路径产生的过程中，对手“机器人”不是均匀随机的；对当前棋局的每个对手落子给出一个条件概率分布； value network：卷积神经网络，给出自己每个落子收益；（部分采用随机落子）
  ![](media/image7.png)强化学习
  ![](media/image7.png)是否需要先验知识（AlphaGo or AlphaZero)


问题：指数增加的树如何构造、存储和评价分枝？
  ![](media/image6.png)博弈树/搜索树随着深度增加，节点数目指数膨胀，即使是最小最大值方法，也无法解决该问题；
  ![](media/image7.png)随机模拟来估计每个分枝的“收益”/“转移概率”
  ![](media/image7.png)给定每一步的时间限制（例如每步最多 5min），假设两个“随机棋手”从当前棋局开始下棋，二者都是随机落子；二人多次以给定的  初始棋局开始，重复随机博弈，统计实际路径中每个节点的收益。  随机路径的数目由时间限制来约束。
  ![](media/image6.png)每次随机博弈的胜利方收益为 1，多次（大量）重复随机博弈，得到了博弈树的部分随机路径（子树），对该子树执行最小最大值算法或者估计经过节点的收益估计值和转移概率，并以之为实际值的  一种估计。
  ![](media/image7.png)类比 MDP 和强化学习。


![](media/image284.png)![](media/image285.png)
算法思想
  ![](media/image256.png)![](media/image7.png)选择：使用树策略从根节点开始采取行动，直到选择到一个最紧急  的可扩展节点（叶子节点或是含有部分未探索的行动的中间节点）  扩展：在该节点上通过树策略选择一个可行的动作，并将其指向的  节点添加到搜索树中。
  ![](media/image6.png)模拟：从新节点开始采用默认策略进行模拟，直到达到一个终端状  态并得出奖励。
  ![](media/image6.png)回溯：模拟得出的奖励回传到从新节点到根节点的每一个经由节点  上，回传的奖励将会影响树策略。

![](media/image286.png)


![](media/image7.png)
```
\*n\*\*j\*
```

```
√
```
上置信界和树的上置信界
  *UCB** *= *X*¯*j** *+2 ln *n** *，其中 *X*¯ *j**  *是节点 *j** *获得的平均奖励，*n**j** *表示节点 *j** *被探索的次数，*n** *为探索的总次数
  ![](media/image7.png)
```
\*n\*\*j\*
```
*UCT** *= *X*¯*j** *+ 2*C**p*√ 2 ln *n*

作用
  ![](media/image6.png)平衡搜索的强度和广度
  ![](media/image7.png)平均奖励越高, 即 *X*¯*j**  *越大，越倾向于对节点 *j** *进行搜索，*n**j**  *也越大，第二项也就越接近 0；
  ![](media/image7.png)平均奖励小，第二项 *n**j** *也会小，但是总搜索次数 *n *在增加，第二项的作用越来越大，值有可能成为 UCB 和 UCT 的主要部分，推动对节点 *j *的搜索。


    ![](media/image287.png)

树策略
  ![](media/image7.png)只要当前节点不是游戏终端状态/叶节点，如果当前节点的所有动作未被完全扩展，则扩展本节点的其他动作并返回下一个新节点，否则选择一个    最佳子节点。若
  ![](media/image6.png)到达了终端节点，则返回终端节点。
  ![](media/image6.png)扩展节点 *v*：选择节点 *v *没有被访问的一个动作，并把该动作指向的节点
  *v**′ *添加到树中，同时记录下指向节点 *v**′ *的动作，返回节点 *v**′*。
  ![](media/image256.png)选择最佳子节点 *v**′*：应用 UCT，在树策略中寻找下一个最佳子节点。


    ![](media/image288.png)

默认策略
  ![](media/image6.png)用于模拟时使用，随机选取当前节点的一个动作，直到模拟到最终  的节点，并返回其终端状态对应的奖励。

奖励回溯
  ![](media/image7.png)从当前扩展节点到根节点的每一个节点的访问次数 +1，奖励增加。




优点：
  ![](media/image7.png)不需要特定领域的启发式算法
  ![](media/image7.png)但是如果采用了启发式算法会极大地降低模拟次数、减少分支，就  是说可以结合启发式方法，提高效率
  ![](media/image5.png)结合启发式方法提高效率，带来的问题是会减少探索的空间，容易  陷入局部最优


Bandit Algorithm for Smooth Trees (BAST)
  ![](media/image6.png)使用了奖励是平滑的的假设，可以识别出是否是最优分支，并且会  不断扩展最优分支，并假设如果时间无限则只有最优分支会被不断  扩展上去，而普通的 UCT 则会扩展全部的分支
Temporal Difference Learning (TDL)
  ![](media/image7.png)TDL 和 MCTS 都是根据状态对应的价值或者状态行动对来选取行动的。
  ![](media/image6.png)差异在于 TDL 是提前运行好全部的过程并保存下来，而 MCTS 是一边运行一边计算
Single-Player MCTS (SP-MCTS)
  ![](media/image6.png)
```
\*n\*\*j\*
```

```
\*n\*\*j\*
```
*UCB** *= *X*¯*j** *+ √ 2 ln *n** ** *+ √*σ*2  + *D*
![](media/image7.png)
  增加第三项，代表单个玩家可能带来的偏差

Multi-player MCTS
  ![](media/image256.png)在 Minimax 方法中，每名玩家都希望自己奖励最大化，敌人奖励最小化。而多玩家对应于每个节点都存储一个奖励向量，在计算时整  体考虑本联盟的奖励，从字面上理解为使得我方 *n** *个队友的奖励和最大，这有可能对于本玩家并不是最大奖励。其将会考虑减少不利  于友方玩家的影响，就好像都是自己的一部分一样。对于多个合作  的对手，可以看成单一有效的对手。对于多玩家的不同联盟情况有  三种决策方法:
      ![](media/image31.png)![](media/image31.png)Paranoid UCT：认为所有人都是敌对的UCT with Alliances：有明确的联盟成员名单
      ![](media/image31.png)Confident UCT：对每一个玩家进行搜索比较，确定是否可以形成联盟
Multi-agent MCTS 和 Ensemble UCT
  ![](media/image7.png)有些研究认为在默认策略的模拟阶段，采用并行化的多个智能体单  独模拟并结合分析结果，产生的结果要优于只有一个智能体模拟的  结果。

结合领域知识
  ![](media/image7.png)不管是否是通用方法，领域知识对特定问题总是能带来提高
UCB 公式的改进
  ![](media/image6.png)用于平衡搜索的强度和广度
树策略的改进
  ![](media/image6.png)超参 *C**p *选择，行动分组，保存模拟搜索数据，对每个行动预评分/利用领域知识
模拟结果的利用方法
  ![](media/image7.png)用在同层次的其它节点，压缩存储模拟结果等
提升模拟能力
  ![](media/image7.png)利用领域知识，利用历史，加快模拟
改进回溯
  ![](media/image7.png)奖励加权，后期奖励更有效；非 +1 和-1 的奖励，允许-1 +1 之间的实数；奖励沿路径衰减机制等
并行化
  ![](media/image7.png)由于 MCTS 的每次模拟都具有独立性，因此可以采用并行化来加快运行速度。

![](media/image1.png)



## ********人工智能讲义
  **机器学习概念**


  March 3, 2020

### ****Outline
  
```
\*\*1\*\*
```
[什么是机器学习]()
  
```
\*\*2\*\*
```
[*h** *的评估]()
  
```
\*\*3\*\*
```
[*h** *的获得]()


    ![](media/image289.jpeg)

  ![](media/image256.png)牛顿力学：力、质量、速度的函数关系如何实验发现的？
  ![](media/image256.png)![](media/image7.png)收集实验数据，填入“表格”（不完整的函数关系）假设函数关系，验证函数关系
  ![](media/image7.png)发现的函数关系是“知识”，规律，是压缩实验数据表格的“压缩方法”
  ![](media/image7.png)函数、知识和函数描述的复杂性


      ![](media/image290.jpeg)
自动驾驶技术
  ![](media/image7.png)面对各种不同情况/路况，自动选择驾驶策略（速度/方向）等；路径规划问题的在线版本；
  ![](media/image7.png)路况无法穷举，状态数目近乎无穷，最佳应对如何实现？


  ![](media/image291.jpeg)
推荐系统：依据用户的习惯和爱好，给出商品的推荐品
  ![](media/image256.png)将所有的商品和用户对，施加一个判别：“喜欢”和“不喜欢”
  ![](media/image256.png)如何在很少的已知数据（用户喜欢和不喜欢某些商品）条件下，实  现对极大数量的用户和商品对的判别？规律？知识？


      ![](media/image292.png)
生物学：在 DNA 链/字符串中找出一个不连续的片段，判定它是否是基因
  ![](media/image7.png)列表枚举所有可能的基因，然后可能性太多，能获得的表格中的数据太少；
  ![](media/image256.png)
```
\*⇒\*
```
专业领域内的知识 + 数据分析技术手段；生物学 + 机器学习 = 生物信息学；机器学习称为通用的“科学发现”手段。





                          ![](media/image293.png)语言：句子是单词的排列
                            ![](media/image114.png)自动阅读或意思识别，可以用表格将所有的句子都枚举出来（有限）
                            ![](media/image114.png)但是能否压缩描述？找到规律或知识？


    ![](media/image294.jpeg)
设计一个程序打败人类
  ![](media/image7.png)从失败中逐步学会调整策略，现在能够战胜人；
  ![](media/image7.png)设计程序思路：一个映射表，枚举了所有的棋局和最佳应对，在失败中不断调整失败的应对。


含义 1：获得完整的数据表格
  ![](media/image6.png)![](media/image6.png)现实中，总是能针对某个事物收集到一些数据数据总是能填写到表格中去
  ![](media/image7.png)得到的表格一般都是不完整的，有缺失的
  ![](media/image7.png)机器学习：获得完整的表格。 (表格对应一个函数 *f*)
含义 2：压缩完整表格的存储空间
  ![](media/image6.png)完整表格的行数通常是列数的指数函数
  ![](media/image7.png)当列数较大时，在计算机内存储完整的表格通常是不可能的
  ![](media/image7.png)压缩表示完整表格，即用描述长度较小的函数来表示描述长度最大
  （描述复杂性最高）的完整表格；
  ![](media/image256.png)机器学习：获得描述长度较小的函数 *f*。


        ![](media/image295.png)
机器学习：寻找 *f *近似值 *h *的过程
  ![](media/image6.png)*D**train*：训练数据集
  ![](media/image7.png)*Learner*: 学习器，从训练数据集中归纳出 *h *的机器/程序/算法等
  ![](media/image6.png)![](media/image7.png)*f*: 函数，*y *= *f*(*x*)，可以是现实世界的一个过程/机制/方法等的抽象*h*: 函数 *f *的近似值，模型/假设
  ![](media/image6.png)*x*: 输入变量/自变量
  ![](media/image7.png)*y*: 输出变量/响应/因变量



假设输入是一个向量，不妨设 *X *= (*X*1*, **X*2*, . . . , **X**n*)，第 *i *个分量的值域大小记为 *|**X**i**|*, 其第 *j *个取值为 *v**ij** *，则如下表格完全表示一个函数：

|              |              |       |                  |                                      |
|--------------|--------------|-------|------------------|--------------------------------------|
|*X*1          |*X*2          |*. . .*|*X**n*            |*f*(*X*1*, **X*2*, . . . , **X**n*)   |
|*v*11         |*v*21         |*. . .*|*v**n*1           |*y*1                                  |
|*v*11         |*v*21         |*. . .*|*v**n*2           |*y*2                                  |
|*. . .*       |*. . .*       |*. . .*|*. .** **.*       |*. .** **.*                           |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|*y**\|**X*1*\|\|**X*2*\|**...**\|**X**n**\|*|

  Table: *n *元函数的表示


机器学习的对象与结果：*h*
  ![](media/image7.png)又称“假设”或“模型”，包括两层含义：
      ![](media/image31.png)![](media/image31.png)预定义在 *h** *中的“知识”，用于压缩函数的描述长度；对所有输入都定义了输出/响应
建模/学习：模型选择与训练
  ![](media/image7.png)![](media/image7.png)确定 *h *的过程，更精确地讲，分为两步： 模型选择：
      ![](media/image31.png)![](media/image32.png)枚举模型/表格模型，用完整表格，最大的复杂性来定义 *h*，一般认为此时在模型中没有预定义任何“知识”，也因此它是最通用的模型；用对数据的先验知识，假定数据输出和输入之间呈线性关系；此时预定义的知识就是“输入”和“输出”之间体现为线性关系。
  ![](media/image256.png)训练：确定模型的参数，比如把表格不全；或确定线性表达式的系  数等。


准确性：*h *和 *f *之间的差异
  ![](media/image7.png)*h *近似 *f*，近似的准确程度是多少？这是最关键的评估标准

复杂性：*h *的描述长度是多少？
  ![](media/image6.png)*h *的描述长度通常和计算的时空代价相关，因此我们要确保 *h *的描述长度在合理、有效的范围内。

完备性：*h *是否对 *f *的每个输入都定义了一个响应？
  ![](media/image6.png)机器学习一般情形下要求结果具备完备性；而数据挖掘一般没有此  要求。



```
∑
```
*h *准确性的定义
  ![](media/image7.png)
```
∑\*|\*\*X\*\*|\*\*\*2平方误差：\*err\*\* \*\* \*(\*h\*\*,\*\* \*\*f\*) =(\*f\*(\*x\*\* \*) \*−\*\* \*\*h\*(\*x\*\* \*)) ，适用于 \*y\*\* \*取连续值的情形2\*i\*\*\*\*i\*\*i\*
```

```
=1
```
绝对误差：*err*1(*h**,** **f*) =*|**i**X**|** **|**f*(*x**i*) *−** **h*(*x**i*)*|*，适用于 *y** *取连续值的情形
  ![](media/image7.png)=1
  ![](media/image6.png)
```
=1
```
误差计数：*err*0(*h**,** **f*) = ∑*|**i**X**|** *1[*f*(*x**i*) *̸*= *h*(*x**i*)]，适用于 *y** *取离散值的情形
准确性计算方法及存在问题
  ![](media/image6.png)对所有的输入，比较 *f *和 *h *输出的差异, 然后求和；
  ![](media/image6.png)问题 1: *h *的输入 *x *的值域太大，通常时间上不允许遍历 *x *的值域，所以精确计算准确性存在困难。
  问题 2：上述误差和 *x *的值域大小相关，通常将上述误差除以 *x *值域大小，得到误差均值，并用之来评估准确性。


准确性的近似计算方法的思想
  ![](media/image7.png)从完整映射表中随机抽样若干行，检测在这些行中 *h *的错误率，用该错误率近似真实的错误率。

实际应用中
  ![](media/image7.png)从已知 *y *真实值的行中，选择保留一部分行，不参与训练（寻找*h*），这部分被保留的行，被称之为“测试数据集”，用测试数据集的错误率，近似估计 *h *的错误率
  ![](media/image256.png)已知数据集/真实数据划分为：
      ![](media/image31.png)训练数据集 *D**train*
      ![](media/image31.png)测试数据集 *D**test*
准确性的近似值
  ![](media/image7.png)*err*2(*h**, **f*) = ∑*x**∈**D**test *(*f*(*x*) *− **h*(*x*))2，类似可重新定义 *err*1*, **err*0



数学上最简单的表达式为线性
  ![](media/image5.png)*y *= *ax *+ *b*

  ![](media/image7.png)机器学习中最重要的、最简单的 *h *也是线性模型机器学习中用线性模型来近似 *y *= *f*(*x*)
  ![](media/image7.png)*y *= *Wx*，*x *是标量
  ![](media/image7.png)*y *= **W **· **x **= Σ*x**wx*，**x **是向量
  ![](media/image7.png)上面的 *W**, ***W **是线性表达式的系数， · 表示内积/点积

我们从线性 *h *开始了解机器学习












  
```
\*h \*的获得
```

```
线性回归
```

```
&quot; 线性处理 方 法
```

```
\*y \*取 连 续 值
```

```
线性分类
```

```
线性 \*h\*\*  \*不能很好地近似  \*f\*
时, 需要一些复杂的非线性的 \*h\*\* \*来适应更广泛的问题
```
*y *取 离 散 值

![](media/image1.png)



## ********人工智能讲义
  **线性回归**


  March 3, 2020

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```

```
\*\*3\*\*
```
[从例子开始]()[损失函数]()[最小化损失]()


        ![](media/image301.jpeg)

手写体数字识别：问题描述
  ![](media/image7.png)每个手写体字符 **x **是 100\*100 的像素点方阵，每个像素点取值 0 或 1，也就是说每个输入变量是长度为 100\*100 的 0-1 方阵（二维矩阵）
  ![](media/image6.png)每个手写体字符的输出离散化为 0,1,2,3,4,5,6,7,8,9。
  ![](media/image6.png)我们也可以将输出定义为任意实数 *y*，然后视 *y *和这 10 个数字字符的远近做离散化近似。如 *y *= 2*.*4 时，y 可以离散化为 2；
  *y *= *−*20 时，*y *可以离散化为 0 等


手写体数字识别问题分析 1: *f *是什么？
  ![](media/image256.png)![](media/image7.png)人眼看到输入，人脑对输出做出判决； 该 *f *目前无法用数学函数来显示表达；
  ![](media/image7.png)该 *f *由视觉/光学/神经信息处理等等一系列物理过程构成，非常复杂
手写体数字识别问题分析 2: *h *是什么？
  ![](media/image7.png)用最简的线性函数 *h*(**x**) = **W **· **x **+ *b *来近似 *f*
  ![](media/image7.png)公式中的点表示两个矩阵的点积：两个矩阵对应位置的元素相乘然  后全部加起来
  ![](media/image6.png)其中 **W**** **是 100\*100 的实数矩阵，对图片 *x** *的每个像素点给一个权值，描述其在识别过程中的作用。每个像素点对每个字符的贡献可  能会不同/有冲突，权值该如何设置？


  *h*(**x**) = **W **· **x **+ *b **∼** **f*

      手写体数字识别：解决问题 搜索最优的 **W **和 *b*
  ![](media/image6.png)线性函数 *h*(**x**) 由其系数矩阵 **W **和常数项 *b *确定，这二者称为线性函数 *h*(**x**) 的参数
  ![](media/image7.png)不同参数得到的不同 *h*(**x**)，最后识别字符时，准确率会有差异，找到使得差异最小的那组最优参数
  ![](media/image7.png)找最优参数的方法：最小二乘法


*h*(**x**) = **W**** **· **x**** **+ *b** **⇒** **h*(**x**) = **W**** **· *ϕ*(**x**)
  ![](media/image6.png)完整的线性函数应该包括常数项 *b*
  ![](media/image7.png)但是，我们把输入变量 **x **做一个简单的变换，
  
```
\*−→\*
```
**x**** **= (*x*1*, **x*2*, . . . , **x**n*)*t*****x**** **= (*x*1*, **x*2*, . . . , **x**n**, *1)*t*，就可以消去线性函数中的常数项 *b*
  ![](media/image7.png)更一般地，我们将输入变量 **x**，做一次变换，即
  
```
\*−→\*
```
**x***ϕ*(**x**) = (*ϕ*1(**x**)*, **ϕ*2(**x**)*, . . . , **ϕ**n*(**x**))*t** *，不管 **x**** **是几维变量，经过一次变换，成为 *n** *维向量，我们称变换后的结果为“输入特征向量”，该变换称为“特征提取函数”。
  ![](media/image6.png)故线性 *h** *的表达式 *h*(**x**) = **W**** **· **x**** **+ *b** *就变成 *h*(**x**) = **W**** **· *ϕ*(**x**)，以之作为我们讨论线性 *h** *的标准表达式

从评价标准：准确性出发
  ![](media/image7.png)从分析事情要达到的目标出发，反向思考，我们应怎么去找 *h*
  ![](media/image7.png)我们称 *h*(*x*) 和 *f*(*x*) 在某个输入 *x *上值不一样，为“误差”或“损失”
      ![](media/image31.png)![](media/image31.png)![](media/image31.png)绝对损失：*loss*1(*h**, **f**, **x*) = *|**f*(*x*) *− **h*(*x*)*|*，适用于连续 *y *值情形平方损失：*loss*2(*h**, **f**, **x*) = (*f*(*x*) *− **h*(*x*))2，适用于连续 *y *值情形计数损失：*loss*0(*h**, **f**, **x*) = 1[*f*(*x*) *̸*= *h*(*x*)]，适用于离散 *y *值情形
线性 *h** *的“一行”损失函数
  ![](media/image7.png)所谓“一行”是指用表格描述 *h*，一行代表 *x *的某一个取值；有时也称一个数据的损失。
  ![](media/image7.png)*h *为线性函数时，损失函数如下：
      ![](media/image31.png)![](media/image31.png)![](media/image32.png)绝对损失：*loss*1(**W***, **f**, **x*) = *|**f*(*x*) *− **h*(*x*)*|** *= *|***W**** **· *ϕ*(*x*) *− **f*(*x*)*| *平方损失：*loss*2(**W***, **f**, **x*) = (*f*(*x*) *− **h*(*x*))2 = (**W**** **· *ϕ*(*x*) *− **f*(*x*))2 计数损失：*loss*0(**W***, **f**, **x*) = 1[*f*(*x*) *̸*= **W**** **· *ϕ*(*x*)]
以下我们仅考虑线性 *h *的情形。


    ![](media/image302.jpeg)

若令 *y *= *f*(*x*),
  ![](media/image7.png)我们定义：**W **· *ϕ*(*x*) *− **y *为残差/residual
  ![](media/image7.png)例子如上图所示，绿点为真实数据，红线为我们找到的近似线性 *h*， 黑色虚线长度表示了残差的大小，
  ![](media/image7.png)残差有正负


        ![](media/image303.jpeg)
解释说明
  ![](media/image256.png)红色曲线是平方残差损失函数，*loss*2(**W***, **f**, **x*) = (*f*(*x*) *− **h*(*x*))2 = (**W**** **· *ϕ*(*x*) *− **f*(*x*))2
  ![](media/image7.png)绿色曲线是绝对值残差损失函数，*loss*1(**W***,** **f**,** **x*) = *|**f*(*x*) *−** **h*(*x*)*|** *= *|***W**** **· *ϕ*(*x*) *−** **f*(*x*)*|*


  ![](media/image7.png)
```
∑∑∑
```
或者说完整映射表 *h *中，所有行的损失之和以平方损失为例：
*x** **loss*2(**W***,** **f**,** **x*) =*x*(*f*(*x*) *−** **h*(*x*))2 =*x*(**W**** **· *ϕ*(*x*) *−** **f*(*x*))2
  ![](media/image7.png)![](media/image6.png)仅具备理论价值，是我们评价 *h *近似 *f *的准确性的最理想标准然后计算的时空代价使得其不实用。

为什么要把各个不同 *x *的损失加起来？
  ![](media/image7.png)通常 *x *的取值数目是很多的，超过了 *W *中的未知参数个数，也就是若每个 *x*（称为样本）都要求是损失为 0，那么每个样本数据就是一个线性方程，整个方程组很有可能无解，因此必然有部分/全部样本损失不为 0，所以用求和来代替，看整体效应。


实用的评价标准
  ![](media/image7.png)
```
\*|\*\*D\*\*|\*\*train\*
```
*TrainLoss*(*D**train**, ***W**) = ∑(*x**,**y*)*∈**D**train **loss*(*x**,**y**,***W**)
  ![](media/image7.png)也称为 “训练误差”


训练集上为什么会有损失？
  ![](media/image7.png)模型/假设 *h *不准确，例如线性 *h *太简单了，几乎不能描述世上绝大多数的事物。
  ![](media/image256.png)训练数据集有噪声（如测量不准确，错误数据等）。


也称“经验风险”
  ![](media/image6.png)
```
\*|\*\*D\*\*|\*\*test\*
```
*TestLoss*(*D**test**, ***W**) = ∑(*x**,**y*)*∈**D**test **loss*(*x**,**y**,***W**)
  ![](media/image304.png)通常用测试集上的所有损失来作为 *h *的评价标准。

  ![](media/image305.png)如何降低训练集和测试集上的损失？ 如何最小化损失之和？
  ![](media/image305.png)测试集不能被直接使用，只能用在最后的评估过程中，所以我们只  能尽可能最小化训练集上的误差。


涉及的主要工作
  ![](media/image7.png)选择恰当的损失函数，即确定一个数据/一行/一个样本的损失函数的定义
  ![](media/image7.png)
```
\*|\*\*D\*\*|\*\*train\*
```
求解最小化 *TrainLoss*(*D**train**, ***W**) = ∑(*x**,**y*)*∈**D**train **loss*(*x**,**y**,***W**) 问题
最小化问题分析
  ![](media/image305.png)已知量：*D**train*，残缺的表格，样本数据集，训练数据集，每一个数据可表示为 (*x**i**, **y**i*)
  ![](media/image7.png)未知量：**W**，线性 *h *的系数，也是我们最小化 *TrainLoss*( · ) 所需要调整的、搜索的变量。
  ![](media/image7.png)寻找最优的 **W**，使得 *TrainLoss*( · ) 最小。寻找一个 **W**，减少某个样本的残差，容易; 寻找一个 **W**，减少所有样本上的残差，困难， 可能不同的样本对 **W**** **的要求有冲突。


考量的方面
  ![](media/image7.png)平方损失函数：近似寻找 *y *的均值，综合所有样本的影响
  ![](media/image6.png)绝对损失函数：近似寻找 *y *的中值，抵抗离群点/样本的影响

当采用平方损失函数时，
  ![](media/image7.png)
```
∑\*x\*(\*\*W\*\*\*\* \*\*· \*ϕ\*(\*x\*) \*−\*\* \*\*f\*(\*x\*))2
```
*TrainLoss*( · ) = ∑ *loss*2(**W***, **f**, **x*) = ∑*x*(*f*(*x*) *−** **h*(*x*))2 =
  即为著名的 最小二乘法


梯度下降法
  ![](media/image7.png)算法略。（参考“优化问题求解”一章）

算法时间复杂度
  ![](media/image306.png)算法的每一步，即每一次循环，更新一次 W，都需要完全扫描一次

  训练数据集，即：*WW*
  ∑(*x**,**y*)*∈**D**train *(*W**s *· *ϕ*(*x*)*−**y*)2

  

*s*+1 =
∑
*s **−** **λ**s**∇**W*(
    *|**D**trai**n**|***) =

  *W**s** **−** **λ**s*
(*x**,**y*)*∈**D**train *2(*W**s *· *ϕ*(*x*)*−**y*)*ϕ*(*x*)
    *|**D**trai**n**|*

  ![](media/image6.png)当训练数据集很大时，包括千万/上亿的行时，算法的时间开销巨大。
  数据挖掘工程实践中常考虑这类问题。此时训练数据集太大，无法  一次载入内存，涉及内外存数据交换，时间开销更大，因此需要对  算法进行改进。


随机梯度下降法
  ![](media/image5.png)计算梯度方向时，只用了一个随机样本的信息，替代经典梯度下降
  算法要计算所有训练数据集对梯度方向的贡献。

  ![](media/image7.png)即：*W**s*+1
= *W**s** **−** **λ**s** *∑(*x**,**y*)*∈**D**train** *2(*W**s** *· *ϕ*(*x*)*−**y*)*ϕ*(*x*) =*⇒** **W**s*=

  
```
\*|\*\*D\*\*|\*\*train\*
```

```
+1
```
*W**s** **−** **λ**s**∇**W*((*W**s** *· *ϕ*(*x**i*) *−** **y**i*)2)


              时间性能得到提升，不需要每次循环都载入一次训练数据集；付出的代   价是更多的循环次数。

![](media/image1.png)



## ********人工智能讲义
  **线性分类**


  May 7, 2019

### ****Outline
  
```
\*\*1\*\*
```
[从例子开始]()
  
```
\*\*2\*\*
```

```
\*\*3\*\*
```
[分类的几何意义]()[线性 SVM]()


电子邮件地址识别：问题描述
  ![](media/image6.png)输入 *x*: 表示给定的一个字符串，
  ![](media/image7.png)输出：判断 *x *是不是电子邮件地址。
      ![](media/image32.png)输入是字符串 *x*
      ![](media/image32.png)输出是-1 或 +1，+1 表示是电子邮件地址，-1 表示否

例子
  ![](media/image7.png)*x *=[”zhangsan@gmail.com” ](mailto:zhangsan@gmail.com)*−→ **y *= +1 是电子邮件地址
  ![](media/image7.png)*x *=”abcd.efgh.ijk” *−→ **y *= *−*1 不是电子邮件地址

电子邮件地址识别：问题分析
  ![](media/image7.png)输入字符串 *x *的“预处理”: 特征提取函数
  ![](media/image7.png)*x *变化范围太大，非结构化的，处理不方便，先预处理，提取描述 *x*
  的特征向量，即 *x *=*⇒ **ϕ*(*x*) = (*ϕ*1(*x*)*, ϕ*2(*x*)*, . . . , ϕ**d*(*x*))
  ![](media/image307.png)![](media/image307.png)特征提取函数输出一个长度为 *d *的向量，描述输入 *x *的特征在图像和语音识别研究中常用，且是其基本研究内容之一
  ![](media/image7.png)
```
\*⇒\*
```
例子如图所示，*x** *=*ϕ*(*x*) = (*length** **&gt;*
  10*, **fracOfAlpha**, **contains*_@*, **endsWith*_*.**com**, **endsWith*_*.**org*)
![](media/image308.jpeg)


          ![](media/image309.jpeg)

电子邮件地址识别：特征提取函数
  ![](media/image6.png)如上图所示，任意一个字符串 *x*，经过特征提取函数的处理获得一个长度为 5 的实数向量
  ![](media/image5.png)特征向量可以视为 5-维空间中的一个点
  ![](media/image6.png)问题：存在很多特征提取函数，特征提取函数有优劣之分 评价标准？
  ![](media/image6.png)评价方法？


  ![](media/image6.png)电子邮件地址识别问题分析 1: *f *是什么？ 人眼看到输入，人脑对输出做出判决；
  ![](media/image5.png)函数 *f *涉及复杂的知识背景，心理活动等；难以用数学函数完美定义。

电子邮件地址识别问题分析 2: *h *是什么？
  ![](media/image5.png)用最简的线性函数 *h*(*x*) = **W **· *ϕ*(*x*) 来近似 *f*
  ![](media/image5.png)注意到 **W **是一个一维向量，*x *变成了特征提取函数 *ϕ*(*x*)，同时线性表达式的常数项 *b *丢掉了 (为什么可以丢掉常数项？)


                    权向量 **W **的解释
                      ![](media/image310.jpeg)![](media/image18.png)权向量描述每一个特征的在判决是否是电子邮件地址时的贡献
                      ![](media/image23.png)如图所示例子，字符串长度大于 10 时，对是电子邮件地址的判决作用是负面的， 权值为-1.2
                      ![](media/image255.png)字符串中包含 @ 字符，对判决是电子邮件的作用是正面的，权值为 3
                      ![](media/image18.png)权值绝对值越大，表明对应特征对最终判决的影响越大


  ![](media/image311.jpeg)

分数:*score*
  ![](media/image7.png)*h*(*x*) = **W **· *ϕ*(*x*)
  ![](media/image7.png)图中两个向量 **W***, ϕ*(*x*) 的点积/内积, 是核心计算过程:
      ![](media/image31.png)两个实数向量的内积，输出是实数，并不能作为真实 f 的输出
      
```
\*∈\*\* \*\*{\*\*}\*
```
*y*0*, *1 的近似，因为 *y** *是离散的-1 和 +1
      ![](media/image32.png)重新定义两个向量的内积为 *score*/分数，不是真实 *f *的输出 *y*，而是给 *y** *打出的一个“分数”，即：*score** *≜ *W** *· *ϕ*(*x*)




从分数 *score *到输出 *y*
  ![](media/image307.png)将“分数”离散化为 *{−*1 + 1*}*
  ![](media/image307.png)
```

```

```
 +1 , if \*W \*· \*ϕ\*(\*x\*) \*&gt; \*0
```
如下给出一种可选方法：

  *h*(*x*) = *sign*(*W** *· *ϕ*(*x*)) =
  1  , if *W** *· *ϕ*(*x*) *&lt;** *0

```
\*−\*
```
 *∗*, if *W** *· *ϕ*(*x*) = 0




  ![](media/image6.png)电子邮件地址识别：总结问题描述
  ![](media/image5.png)问题分析：特征提取，*h *选择线性函数
  ![](media/image5.png)问题求解：最优 **W **的确定、及其意义的说明、分数定义及其到输出响应 *y *的变换等。

与回归问题的区别？


                      ![](media/image312.jpeg)解释说明
                        ![](media/image18.png)考虑图示二维的情形：**x **= (*x*1*, **x*2) *y **∈ **{*实心点, 空心点*}*
                        ![](media/image18.png)直线方程 *ax*1 + *bx*2 + *c *= 0, 可扩展到 *d *维空间 **W **· **x **+ *b *=
                        *w*1*x*1 + *w*2*x*2 + *. . . *+ *w**d**x**d** *+ *b*
                      ![](media/image23.png)三维时，是平面，*d*(*&gt; *0) 维时称为“超平面”
                        ![](media/image313.png)直线上的点满足 *ax*1 + *bx*2 + *c** *= 0, 实心点满足 *ax*1 + *bx*2 + *c** **&gt; *0, 空心点满足 *ax*1 + *bx*2 + *c** **&lt; *0
                        ![](media/image17.png)
```

```
*h** *的线性表达式为 0 时，就是该超平面，也称“决策边界/分类器”: *h*(*x*) = *sign*(*W** *· *ϕ*(*x*)) =
                          
```
\*−\*
```
+1 , if *W** *· *ϕ*(*x*) *&gt;** *0 1   , if *W *· *ϕ*(*x*) *&lt; *0
                         *∗   *, if *W *· *ϕ*(*x*) = 0


以二分类问题为例：*y *= *{*+1*, **−*1*}*
  ![](media/image7.png)分数 *score *≜ *W *· *ϕ*(*x*)，描述了对 *f *的输出 *y *进行预测时，对预测结果有多大程度的“信任”，是个打分，正得越大表示越相信 *y** *是
  +1，负得越多表示越相信 *y *是-1
  ![](media/image6.png)间隔 *margin** *≜ *W** *· *ϕ*(*x*)*y*，表示对 *f** *的输出 *y** *进行预测时，对预测结果的正确性有多大把握，数值越大，把握越大；
      ![](media/image31.png)间隔为负，表示预测错误
      ![](media/image32.png)间隔的定义和符号函数 *sign*( · ) 定义的的离散化方法相比，保留了更多的信息。
      ![](media/image32.png)
```
\*{\*\*−\*\* \*\*}\*
```
“将简单粗暴的   +1*,**    *1   的硬判决搞得温柔一些”，用间隔来实现，间隔的大小具有一定的“物理意义/几何意义”

```

```
符号函数：

*h*(*x*) = *sign*(*W** *· *ϕ*(*x*)) =
  +1 , if *W** *· *ϕ*(*x*) *&gt;** *0 1  , if *W** *· *ϕ*(*x*) *&lt;** *0

```
\*−\*
```
 *∗*, if *W** *· *ϕ*(*x*) = 0


  ![](media/image314.jpeg)间隔若为负，表示“距离错误”/“分类错误”，越小表示“错误犯得越厉害”间隔越大，直观概念就是离分类面的距离越远；







![](media/image18.png)间隔：平面外点 *P *到平面的距离的 *∥***W***∥ *倍

*−→−→*

    平面 *α** *方程：*−**W**→** *· *−**→**X** *+ *b** *= 0
    ![](media/image23.png)平面外一点 *P** *到 *α** *的垂足为点 *O*， 平面的单位法向量为 *−**→**n**  *= *−**W**→*/*∥**−**W**→**∥*
    ![](media/image18.png)*Q *为平面内任意一点；辅助计算
    *dist*(*P**, α*)
  *dist*(*P**, α*) = *∥**PO**∥** *= *∥**PQ**∥**cos**θ *=
  *−**P**→**Q** *· *−**→**n** ** *= *−**P**→**Q** *· *−**W**→*/*∥**−**W**→**∥** *=
  (*−**→**P** ** **−** **−**→**Q** *) · *−**W**→*/*∥**−**W**→**∥** *= *−**→**P** *· *−**W**→*/*∥**−**W**→**∥** **−*
  *−**→**Q** *· *−**W**→*/*∥**−**W**→**∥** *= *−**→**P** *· *−**W**→*/*∥**−**W**→**∥** *+ *b*/*∥**−**W**→**∥** *= (*−**→**P** *· *−**W**→** *+ *b*)/*∥**−**W**→**∥*




              ![](media/image315.jpeg)无法应用梯度下降法（没有梯度信息可以利用）！




          简单粗暴的方法：符号函数 *sign*( · )
  ![](media/image6.png)**W **· *ϕ*(*x*)*y **&lt; *0, *loss*(*x**, **y**, ***W**) = 1

  ![](media/image7.png)**W**** **· *ϕ*(*x*)*y** *= 0, *loss*(*x**,** **y**,** ***W**) = 1
  ![](media/image307.png)**W**** **· *ϕ*(*x*)*y** **&gt;** *0, *loss*(*x**,** **y**,** ***W**) = 0
硬判决！





  可用梯度下降法求最优 **W**
  基于 *logistic *损失函数获得的最优 **W **或
  ![](media/image316.jpeg)*h *被称为 *logistic *回归或 *logistic *分类器




改进方法：软判决，使得梯度信息存在且有意义
  ![](media/image6.png)![](media/image6.png)如图中的黄色曲线，连续的，大于 0 的，光滑曲线。基本趋势：间隔越大，损失越小。
  ![](media/image7.png)![](media/image7.png)*logistic *回归：用该损失函数作为计算训练损失的核心。虽然名为“回归”实际干的活却是“分类”。
  黄色曲线的方程：*loss**logistic*(*x**, **y**, ***W**) = log(1 + *e**−***W **· *ϕ*(*x*)*y*)。


              ![](media/image317.jpeg)*loss**hinge*(*x**, **y**, ***W**) = *max**{*1 *−** ***W **· *ϕ*(*x*)*y**, *0*}*

  可用梯度下降法求最优 **W**





改进方法：把关键部分的梯度信息变成非 0
  ![](media/image7.png)如上图所示绿色曲线，称之为 *hinge *损失函数，如同门的“转轴/*hinge*”
  ![](media/image7.png)梯度信息不再是处处为 0
  ![](media/image7.png)任意一个绿点定义的损失值都大于相同间隔的红点定义的损失值，也就是说相对于“简单粗暴法”的损失函数定义，我们把损失“夸大”了（上界），我们更激烈地反对“严重错误”
  注意到间隔在 (0,1) 之间的时候，我们也定义了非 0 的损失，这迫使我们优化的时候要考虑间隔要大于等于 1，即正确的分类判断要足够有说服力（间隔大于 1）
  *hinge *损失函数，可以让我们用梯度下降法来求线性表达式的参数 **W**





  ![](media/image6.png)*hinge *损失函数不仅仅是为了可以使用梯度下降法推导出另一种求解最优 **W **的方法
  ![](media/image6.png)从几何结构入手，重新定义最优化问题，然后求解最优 **W**



代数间隔
  ![](media/image6.png)*a **− **margin *≜ **W **· *ϕ*(*x*)*y*，或
  ![](media/image6.png)*a **−** **margin *≜ (**W **· *x *+ *b*)*y*

几何间隔：数据点到分类平面的距离
  ![](media/image6.png)
```
\*∥\*\*\*W\*\*\*∥\*
```
*g **−** **margin *≜ **W **· *ϕ*(*x*)*y*
  ![](media/image7.png)
```
\*∥\*\*\*W\*\*\*∥\*
```
*g **−** **margin *≜ (**W **· *x*+*b*)*y*

从几何结构上来看，追求代数间隔大于等于 1
  ![](media/image307.png)从 *hinge *损失函数的定义看，我们需要让代数间隔大于等于 1，使得 *hinge *损失为最小值 0；
  ![](media/image7.png)即 *loss**hinge*(*x**, **y**, ***W**) = *max**{*1 *− ***W **· *ϕ*(*x*)*y**, *0*} *= 0*, **⇒ ***W **· *ϕ*(*x*)*y **≥ *1
  ![](media/image6.png)用几何间隔来描述，即 **W**** **· *ϕ*(*x*)*y** **≥** *1 ，即任何一个数据点，它到分类面的距

  
```
\*\*W\*\*
```
离都大于等 1 
*∥ ∥*
新优化问题描述
*∥***W***∥*
*∥***W***∥*

  ![](media/image7.png)
```
\*\*W\*\*
```
约束条件：找到一个分类面 *h*(*x*) = **W **· *ϕ*(*x*)，使得它能分开所有的训练数据，且使得任意一个数据点到分类界面的距离（几何间隔）大于等于 1 
*∥ ∥*
  ![](media/image7.png)优化目标： 1 越大越好，因为 1 是训练数据到分类面的距离的下界，下界
        *∥***W***∥∥***W***∥*
  
```
\*∥\*\*\*W\*\*\*∥\*
```
越大，说明分类器分类带来的置信程度越高。最大化 1 可等价于最小化 *∥***W***∥*
  ![](media/image7.png)该优化问题来自对分类问题几何意义的理解和形式化。我们称该优化问题是追求     “结构风险最小化”, 不同于定义在训练集上的损失最小的“经验风险最小化”问题。
  如何求得最优 **W**?


  ![](media/image318.png)
如图所示，不同的分类面
  ![](media/image7.png)**W **定义的超平面很多，每个数据点离不同超平面的距离会有所不同
  ![](media/image7.png)这些点中有些点离决策边界/超平面很关键，即距离最短，是离超平面最近的点。超平面可以由这些点来完全确定（计算出来），这些点称为“支持向量”/*sv*
  ![](media/image7.png)非支持向量有什么用？当你选择的 W 发生改变的时候，有些非支持向量就会变成支持向量，原来的支持向量可能就不是支持向量了
  ![](media/image307.png)因此，这些非支持向量就是一种“约束”，它约束你选择的 **W**** **确定的决策面及对应的支持向量间的距离达到“最大”


线性 SVM 优化问题：适用于线性可分的数据集/问题
  
```
2
```
min*∥***W***∥** **⇐⇒ *min 1 **W **· **W**

*s**.**t**.*
    1 *−** *(**W **· **x **+ *b*)*y **≤** *0*, **∀*(**x***, **y*) *∈** **D**train*



解释说明
  ![](media/image6.png)每个样本/训练数据带来一个约束条件
  ![](media/image6.png)约束条件表明所有的训练数据都被正确分开 (**W **· **x **+ *b*)*y **≥ *1 *&gt; *0
  ![](media/image7.png)且分开得足够远，即代数间隔 *&gt; *1

        如何求解？带有约束条件，梯度下降？


对约束条件的处理
  ![](media/image7.png)
```
\*≥\*
```
每个样本/训练数据，对应一个非负乘法因子 *α**i***0，并带入对应的约束条件中，使得
  [1 *−** *(**W **· **x***i** *+ *b*)*y**i*]*α**i** *= 0*, **∀*(**x***i**, **y**i*) *∈** **D**train*
  ![](media/image6.png)
```
\*−\*
```
意义：离分类界面最近的训练数据，因为 1(**W**** **· **x***i** *+ *b*)*y**i** *= 0， 所以 *α**i** *取值可以随意变化；而非最近的数据，必须要让 *α**i** *= 0， 来确保 [1 *−** *(**W**** **· **x***i** *+ *b*)*y**i*]*α**i** *= 0
  ![](media/image7.png)然后，把所有的约束条件加起来：
    
```
∑(  \*i\*\*,\*\* \*\*i\*)\*∈\*\* \*\*train\*\*−\*\*≤\*
```
**x **** ***yD*[1(**W**** **· **x***i** *+ *b*)*y**i*]
    (**x***i**,**y**i*)*∈**D**train *[1 *−** *(**W **· **x***i** *+ *b*)*y**i*]*α**i** *= 0
  ![](media/image7.png)其实就是把 SVM 优化问题的原始约束条件右端的 0，设计了一个等于 0 的计算公式（利用引入的参数 *α**i*)




对目标函数的处理
  ![](media/image6.png)![](media/image5.png)
```
2
```

```
\*i\*
```

```
\*i\*
```

```
\*train\*
```
*L*(**W***,** **b**,** **α*) ≜ 1 **W**** **· **W**** **+ ∑(**x**** ***,**y** *)*∈**D*
[1 *−** *(**W **· **x***i** *+ *b*)*y**i*]*α**i*

  把原问题的目标函数加上等于 0 的约束条件，并写成自由参数
  **W***, **b**, α *的函数式 *L*(**W***, **b**, α*)
  ![](media/image307.png)原问题（带约束）的最小值，就等于 *L*(**W***, **b**, **α*)（无约束）的最小值。



  拉格朗日乘子法的核心在于把约束条件去掉（加到目标函数中去）


有没有更好一点的方法来求 *L*(**W***, **b**, α*) 的最小值？
  ![](media/image307.png)
```
\*L\*
```
由问题满足 KKT 条件，以及对偶性等，可以将对(**W***,** **b**,** **α*) 最小化问题转化为：
  
```
2
```
max*α** *∑*i** **α**i** **−** *1 ∑*i**,**j** **α**i**α**j**y**i**y**j***x***i** *· **x***j***(1)



解释说明
*s**.**t**.*
∑*i **α**i**y**i** *= 0*, **∀**α**i** **≥** *0(2)

  ![](media/image6.png)因为非支持向量的 *α**i *为 0，所以目标函数公式 (1) 中仅仅包含非零 *α**i *的支持向量间的内积运算，并求最大值；
  ![](media/image7.png)也就是说，若知道支持向量是哪些训练样本，那么直接带入公式 (1)，然后求最大值对应的 *α**i**  *值即可。然而我们并不知道谁是“支持向量”！
  ![](media/image307.png)另有两组隐含的等式：**W **= ∑*i **α**i**y**i***x***i**, **b *= *y**i **− ***W **· **x***i**, **∀*(**x***i**, **y**i*) is a SV
有兴趣看推导过程的请去查阅相关材料。(极值点导数为 0)



SMO：序贯最小化算法/Sequential Minimal Optimization  算法思想：(假设数据集有 *m *个样本/训练数据)
  ![](media/image307.png)
```
\*−\*
```

```
\*−\*
```
每次固定 *m *2 个乘法因子 *α**i*，让其余两个任意变化，寻找这两个任意变化乘法因子的最佳值；循环迭代调整固定不同的 *m *2 个乘法因子 *α*，直到收敛。
  ![](media/image7.png)局部搜索的思想，寻找最佳的自由变量 *α**i*，也就是对应的支持向量及其非零的 *α**i*
  ![](media/image7.png)训练过程中（解优化问题时），尽量避免每次循环迭代都扫描一遍训练数据（这类算法不适用于海量数据/样本的学习问题）


SMO：关键点之一
  ![](media/image6.png)
```
\*−\*
```
每次固定 *m *2 个乘法因子 *α**i*，让其余两个任意变化，寻找这两个任意变化乘法因子的最佳值；此时为含等式约束的二元二次函数的  优化；
  ![](media/image7.png)可以通过约束等式，把可变参数变成一个，即获得一元二次函数，  其最大值计算有简单的公式和方法，可快速计算；

SMO：关键点之二
  ![](media/image7.png)如何确定可变的两个乘法因子 *α**i**, α**j*，使得整个循环迭代的次数最少，实现最快收敛？
      ![](media/image31.png)![](media/image31.png)随机次序固定次序
      ![](media/image31.png)*heuristics*/启发式函数确定次序

### ********线性 SVM 求解
时空复杂性
  ![](media/image7.png)线性空间需求，参照数据集大小 *m*
  ![](media/image307.png)时间代价：数据集大小的若干倍，视情况而定，看哪个大，如：数  据特征维数，*sv** *的个数的平方等等，有 *heuristics*，很难获得精确估计。

进一步思考
  ![](media/image307.png)计算过程要多次扫描数据集，大数据量时，如何优化？可能大部分  数据都非支持向量，可能没太多用处，能否缩小数据集大小？
  ![](media/image307.png)非线性可分的情况如何处理？

![](media/image1.png)



## ********人工智能讲义
  **非线性处理**


  May 7, 2019

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```

```
\*\*3\*\*
```
[非线性 SVM]() [*K** *近邻方法]()[决策树]()


            ![](media/image319.png)

如图所示，线性不可分或不同类支持向量靠得太近
  ![](media/image6.png)原因可能是测量误差造成的噪声，比如黑圈内的蓝点，作为 *sv*，其几何间隔由黑色平行虚线间隔确定；而忽略黑圈内蓝点，得到红色实线确定的几何间隔更大
  ![](media/image7.png)若黑圈内的蓝点受噪声影响偏离较大，那么我们得到的黑虚线判决界面过分地信任“错误/噪声数据”，对今后的判决会造成泛化能力变差；
  ![](media/image5.png)因此，我们尝试将某些数据看成是有噪声的，因此，在他们被选择为支持向量的时候，进行      “松弛”







![](media/image320.jpeg)松弛变量法
  约束条件：*∀*(*x**i**, **y**i*) *∈ **D**train*
  ![](media/image19.png)1 *−** *(*W *· *x *+ *b*)*y **≤** *0 =*⇒*
  1 *−** *[(*W *· *x**i *+ *b*)*y**i *+ *ξ**i*] *≤** *0
  ![](media/image19.png)
```
∑=\*⇒\*\* \*min(   \*W\*\* \*· \*W\*\* \*+ \*C\*\*\*\*ξ\*\* \*)\*i\*\*W\*\*,ξ\*\*\*\*i\*
```
目标函数：
1
        
2
  ![](media/image23.png)训练误差：原来线性可分时，误差为 0=*⇒** *∑*i** **ξ**i*

  ![](media/image307.png)如图所示，假设真实/我们想要的分类面如灰实线所示，*x**i**  *错分了，“越界”了，*x**j** *“调皮”或因为噪声，跑到“禁区”里了
  ![](media/image6.png)![](media/image6.png)添加 *ξ**i**, **ξ**j *把 *x**i**, **x**j *给“拉回”各自的“支持向量”边界。我们称 *ξ**i**, **ξ**j *为松弛变量
  上述操作，体现在公式中或问题中，如右上所示。

SVM 中训练误差的产生
  ![](media/image7.png)被平移了的数据点，虽然成了 *sv*，但是它们带来了训练数据的误差/损失，非支持向量带来 0 误差/损失
  ![](media/image6.png)两类支持向量，它们的拉格朗日乘法因子 *α**i **&gt; *0
  ![](media/image7.png)一类 *ξ**i *= 0, 它们是真正的 *sv*，损失/误差为 0
  ![](media/image7.png)一类 *ξ**i **&gt; *0, 它们是平移后的 *sv*，损失/误差为一类 *ξ**i*
  ![](media/image7.png)当获得最优解时，*ξ**i *= 1 *− *(*W *· *x**i *+ *b*)*y**i*，这就是样本 (*x**i**, **y**i*) 的 *hinge *损失
正则化：引入新的优化目标
  ![](media/image5.png)
```
2
```

```
2\*C\*
```
min*W**,ξ*( 1 *W *· *W *+ *C *∑*i **ξ**i*)，也即 min*W**,ξ*( 1 *W *· *W *+ ∑*i **loss**hinge*)
  ![](media/image307.png) 
```
其中原线性 SVM 的优化目标 min\*W\*\* \*1 \*W\*\* \*· \*W\*\* \*被称为正则化项，训练集上的
```

  ![](media/image7.png)
```
2
```
*hinge *损失 ∑*i **ξ**i *称为训练误差最小化项
  新优化目标既考虑了训练误差最小，又考虑控制模型复杂性（正则化项，也可以
  说是结构风险最小化）
  参数 *C*，用于平衡两个优化目标之间的相对重要性。


        ![](media/image321.png)


  ![](media/image322.jpeg)
解释说明
  ![](media/image6.png)如上图所示，从 2 维 =*⇒*3 维空间，红蓝点用平面线性可分
  ![](media/image6.png)
```
\*⇒\*
```
从低维空间 =高维空间，不同类的数据可在高维空间中用线性超 平面分开
  ![](media/image307.png)问题：如何映射到高维空间/特征空间？如何确保在高维空间中线性可分？ 聚焦在“特征提取函数”！


例子
  ![](media/image5.png)**x **= [*x*1*, **x*2]*t*
  ![](media/image5.png)*ϕ*([*x*1*,** **x*2]*t*) = [1*,** **√*2*x*1*,** **√*2*x*2*,** **x*2*,** **x*2*,** **√*2*x*1*x*2]*t*
12
  ![](media/image323.png)2 维输入变成了 6 维特征，实现了升维，这是一个特征提取函数

特征提取函数的得与失
  ![](media/image323.png)得：线性不可分 可能变成线性可分；
  ![](media/image324.png)失：时间和空间代价增加，把数据集变换为新的高维空间的数据集。

  能避免所失吗？

SVM
  ![](media/image324.png)假设所有数据形成的空间结构中，存在这样的超平面，可以完美地  将数据分开, 那么
  ![](media/image7.png)
```
性 \*h\*(\*x\*) =
```

```
\*i\*\* \*\*α\*\*i\*\*y\*\*i\*\*ϕ\*(\*x\*\*i\*) · \*ϕ\*(\*x\*) + \*b\*, where (\*x\*\*i\*\*,\*\* \*\*y\*\*i\*) is a \*sv\*
```
依据 *W** *=∑∑*i** **α**i**y**i**x**i**,** **b** *= *y**i** **−** **W** *· *x**i**,** **∀*(*x**i**,** **y**i*) is a *sv*, SVM 得到线
![](media/image7.png)
  上式表明，获得分类器 *h *后，对任何新数据进行预测时，只需要将
  它与支持向量进行内积，然后求加权和即可。
  ![](media/image6.png)如果数据分布不好，不存在这样的超平面，怎么办？
  ![](media/image6.png)特征提取函数可以把在低维空间中线性不可分的数据集映射到高维  空间，可能实现线性可分。

如果能直接获得 *K*(*x**i**, **x*) = *ϕ*(*x**i*) · *ϕ*(*x*) 的值，不需要显式地先分别计算出 *ϕ*(*x**i*)*, **ϕ*(*x*)，然后求内积，就可以避免一些特征提取函数带来的时空代价！直接先定义 *K*(*x**i**, **x*), 不用执行把数据集从低维空间变换到高维特征空间的操作。那是否线性可分？（先放下别管！）

核函数/Kernel function
  ![](media/image6.png)称 *K*(*x**i**, **x**j*) 为核函数，它等于 *x**i**, **x**j** *两个变量升维（特征提取 &lt; 怎么提取的？不关心！&gt;）后的特征向量的内积；
  ![](media/image7.png)在线性 SVM 优化过程中，出现特征向量的地方，都是求两个特征向量的内积。
例子
  ![](media/image6.png)**x**** **= [*x*1*,** **x*2]*t**,** **ϕ*([*x*1*,** **x*2]*t*) = [1*,** **√*2*x*1*,** **√*2*x*2*,** **x*2*,** **x*2*,** **√*2*x*1*x*2]*t*
                        12
  *ϕ*(**x**) · *ϕ*(**a**) = 1 + 2*a*1*x*1 + 2*a*2*x*2 + *a*2*x*2 + *a*2*x*2 + 2*a*1*a*2*x*1*x*2
                      1  12 2
设计一个核函数：*K*(**x***, ***a**) = *ϕ*(**x**) · *ϕ*(**a**) = (1 + **x **· **a**)2
  ![](media/image324.png)常用的，可供我们选择的核函数有：
![](media/image32.png)*K*(*x**, **a*) = (1 + *x *· *a*)2 多项式核函数,上例的核函数
      ![](media/image31.png)*K*(*x**, **a*) = *x *· *a *内积核函数
          *−** **∥**x**−**a**∥*2
    ![](media/image31.png)
      *K*(*x**, **a*) = *e*2*σ*2高斯核函数


意义
  ![](media/image324.png)核函数是我们“假设存在一个特征提取函数，把数据集映射到了高维特征空间”，核函数就是高维特征空间的内积计算公式；
  ![](media/image7.png)核函数对应的特征提取函数，把数据集映射到了一个线性可分的高  维空间了吗？能检验吗？一般无法检验或确保高维特征空间中的数  据集线性可分，此时缺省就采用松弛变量的方法，把“捣乱”的数  据看成是噪声。
  ![](media/image6.png)理解核函数另一种观点：描述了两个数据之间的“相似性”，是一种
  *x**i**, **x**j** *之间的距离/相似性的计算方法；
  ![](media/image7.png)错误的理解：核函数把数据 *x *映射到了高维特征空间！


再生核希尔伯特空间
  ![](media/image6.png)有兴趣参考两份文献：
  ![](media/image7.png)《AN INTRODUCTION TO THE THEORY OF REPRODUCING KERNEL HILBERT SPACES》，VERN I. PAULSEN
  ![](media/image7.png)[打开网址：](https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space)
  [https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space](https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space)

kernel embedding of distributions
  ![](media/image7.png)![](media/image6.png)请感兴趣的同学自行查阅相关资料。[如：打开网址](https://en.wikipedia.org/wiki/Kernel_embedding_of_distributions)
  [https://en.wikipedia.org/wiki/Kernel_embedding_of_distributions](https://en.wikipedia.org/wiki/Kernel_embedding_of_distributions)


![](media/image325.png)![](media/image326.jpeg)

例子：训练样本数目越多，分类精度越高
  ![](media/image7.png)![](media/image7.png)![](media/image324.png)左图给出了平面上数据真正分布：不同颜色代表不同类（绿和白）  右图采用 1-近邻方法来判决：判决任意未知样本的色彩为离它最近的已知样本的色彩（*KNN** *就是由最近 *K** *个已知样本投票决定） 只有两个已知样本时，二者的中垂线就是分类界面；随着已知样本  的数目增加，分类边界越来越复杂
  ![](media/image5.png)当有 1000 个已知样本时，分类边界由很多短小的“线段”连接成一个复杂的分类边界，同时准确性越来越高，逼近真正分类边界。





![](media/image327.jpeg)解释说明
                              ![](media/image7.png)1-nn 的例子
                              ![](media/image7.png)样本越多，决策边界越复杂，很多 直线组合在一起， 用非线性边界划 分了整个平面



```
训练样本分布：采用距离公式为欧式距离
```

```
\*K \*= 1
```

  
```
\*K \*= 3
```

```
\*K \*= 5
```
不同颜色代表不同的类
  *K**  *越大，边界越光滑


训练过程
![](media/image7.png)将所有已知样本存储起来。
预测/分类过程: 在给定距离定义下，
  ![](media/image7.png)计算新数据/未知类别数据的 *K *个最近邻居
  ![](media/image7.png)以 *K *个邻居中占多数的类标号作为新数据的类标号
算法评述
  ![](media/image7.png)优点：
      ![](media/image31.png)![](media/image31.png)训练简单，基本是 0 代价可解释性好
  ![](media/image7.png)缺点
      ![](media/image31.png)![](media/image31.png)预测代价大，找最近的 *K *个邻居，算法时间复杂度不低样本数目太少时，易过拟合，泛化能力不足


非参数方法
  ![](media/image6.png)参数的个数随样本数目增加而增加
  ![](media/image6.png)参数可以理解为决策边界的细节；样本越多，参数越多，分类器复  杂性越高。
  ![](media/image7.png)想象一下，完整映射表几乎快填完整了，此时再来一个新数据，判  定错误的可能性，直觉上就会觉得变小了。
  ![](media/image324.png)*KNN *是非参数方法
参数方法
  ![](media/image6.png)相对应的参数方法，参数个数是固定的
  ![](media/image6.png)![](media/image7.png)如线性分类器，权向量 **W **的维数不会因样本增加而增加。通常，参数方法中，样本越多，参数设置得会更合理。


  ![](media/image7.png)机械学习算法：*KNN *预测新数据代价太大训练过程：存储所有的训练样本
  ![](media/image7.png)预测过程：随机产生类标号给新样本/或直接返回“不知道答案”
评述
  ![](media/image7.png)![](media/image7.png)训练和 *KNN *一样，觉得 *KNN *预测过程太复杂，改进了一下，几乎不费代价就能做到预测按照“最小化训练集损失”的思想，该算法训练误差为 0，也就是完美拟合了训练数据
  ![](media/image7.png)想想线性回归/分类问题，都在追求“最小化训练集损失”，这里为什么这么容易其它就实现了？（我们在其它方面失去了东西！）
  ![](media/image5.png)失去的东西/付出的代价，即决策边界的复杂性：相对于线性 *h*(*x*) 的简单，*KNN *描述复杂性增加了！
  ![](media/image7.png)![](media/image7.png)这也就是所谓的，因为模型太复杂，过拟合了训练数据，泛化能力可能不够。     解决办法：正则化，约束模型的复杂度。该算法中模型极度复杂。
  ![](media/image6.png)同时也说明了，仅仅追求“最小化训练集损失”是不够的，不应该是我们最终的目标，而应该是完整映射表 (所有数据上的) 损失最小，实践中用“最小化测试集损失”（泛化能力）来代替。


算法描述
  ![](media/image324.png)![](media/image7.png)训练过程：找到训练集中出现次数最多的 *y *值预测过程：对任何新样本，其类标号为该 *y *值
算法评述
  ![](media/image7.png)该算法可以理解为 *KNN *的 *K *变成和训练数据集大小一样，该算法也简化了 *KNN *的预测过程
  ![](media/image7.png)这个算法它没有复杂的分类边界，没有过拟合训练数据，泛化能力  非常好
  ![](media/image6.png)但是预测能力很差，原因是太简单了，找到的规律近乎于“常识”，能最大化压缩数据，整个数据集就用一个 *y *值就存储了！
  ![](media/image5.png)所谓泛化能力，是指“训练集上的损失”和“测试集上的损失”是  一致的
  ![](media/image7.png)该算法中模型极度简单。


过拟合与泛化能力
  ![](media/image7.png)过拟合：定义在训练数据集上，训练误差非常小的情况。可能造成的原因：模型太复杂，太“迁就特殊的训练数据”，而训练数据本身可能因为“噪声”就存在不精确的问题。
  ![](media/image5.png)泛化能力：无法在所有数据上计算误差，折衷利用测试集上的误差，  该误差和训练误差接近即认为是泛化能力好。

模型/假设的复杂性和正则化
  ![](media/image324.png)完整映射表具有最大描述复杂性，*KNN *的复杂性随样本增加而增加；
  ![](media/image5.png)正则化可以认为是人为“强行”在模型中添加“预定义”的知识，  以此来控制描述复杂性。比如 *KNN** *算法扩展 2



能否用 SVM 来改进 *KNN*
  ![](media/image7.png)SVM 得到的支持向量是不是可以用在 *KNN *中，当成是构建 *KNN*
  分类器的数据？
  ![](media/image7.png)复杂的 *KNN *决策边界用 *sv *来简化？
  ![](media/image7.png)SVM  的中的分类界面表达式中有核函数，如内积/点积运算，核函数可以理解为两个数据的相似性，也就是预测的过程就是综合新数  据和 *sv** *之间的相似性，最后给出一个判决。
  ![](media/image6.png)因此，SVM 只是用核函数定义了一种新的距离计算公式，压缩了*KNN *的大量样本，保留了一些关键样本（*sv*）用于构建分类器/距离计算公式，而 *KNN *设计的关键之一就是定义合适的距离计算公式。


张三去吃饭，没座了，等吗？考虑以下影响因素：
    ![](media/image331.png)Alternate: is there an alternative

    restaurant nearby?
    ![](media/image18.png)Bar: is there a comfortable bar area to wait in?
    ![](media/image18.png)Fri/Sat: is today Friday or Saturday?
    ![](media/image23.png)![](media/image18.png)![](media/image331.png)Hungry: are we hungry? Price: price range ($, $$, $$$) Raining: is it raining outside?

所有情形共计有：26 *× *32 *× *42 = 9216
  Patrons: number of people in the restaurant (None, Some, Full)
  ![](media/image19.png)![](media/image19.png)Reservation: have we made a reservation?
  ![](media/image332.png)Type: kind of restaurant (French, Italian, Thai, Burger)
  ![](media/image19.png)WaitEstimate: estimated waiting time (0-10, 10-30, 30-60, &gt;60)


  ![](media/image333.jpeg)

张三曾经去吃饭遇到的各种情形及其应对结果
  ![](media/image6.png)12 次经历，即 12 个样本数据
  ![](media/image6.png)今天周三，天下着雨，餐馆里坐满了人，张三会等着吃法国餐吗？


![](media/image334.jpeg)


![](media/image335.jpeg)


决策树静态结构
  ![](media/image5.png)树形结构，每个节点是一个简单的线性决策器 *h**i*(*x*) = *A**i*，依据属性 *A**i *的取值不同划分为不同的类
  ![](media/image336.png)决策树中任意一个非叶节点有两个特点：拥有一个训练数据集的一个子集 *D**i*，对应数据的一个列/属性（称为分割属性）
  ![](media/image7.png)决策树中任何一层中所有节点的训练数据子集互不相交，且并集为完整的训练数     据集
  ![](media/image7.png)叶节点不包括任何数据，只有一个标记父节点中数据所属的类别号。

决策树动态部分
  ![](media/image7.png)训练过程：即构建决策树的过程，确定每个非叶结点的分割属性；并分割节点拥     有的数据子集给孩子节点；
  ![](media/image7.png)分类/预测过程：沿从树根开始到叶节点的一条路径，依次使用路过节点的线性分类器。
  ![](media/image7.png)一种特殊“树形”组合多个线性决策器的方法。


决策树的构造
  ![](media/image337.png)在初始时刻，构建树根节点，树根拥有所有训练数据 *D**train*
  ![](media/image7.png)对任何一个节点 *N**i*，选择数据的某一个属性/特征 *A*，以 *A *的不同取值，把节点 *N**i** *拥有的训练数据集 *D**i** *分成若干个不相交的子集， 每个子集变成节点 *N**i** *的一个子节点（每个子节点拥有训练数据的一个子集）；
  ![](media/image6.png)当某个节点内的所有训练数据都属于同一类（*y *值相同）时，该节点的划分过程结束，它生成唯一一个子节点（叶节点），叶节点只有一个属性：它的父节点拥有的数据集所属的类标号。

选择数据属性 *A *做分割属性的时候，要一一测试所有的候选属性，依据测试结果选择一个最好的， 何谓最好？


分割属性的选择
  ![](media/image6.png)模仿人的决策过程
  ![](media/image6.png)买车/买房/买手机时，你考虑哪些因素？每个因素就对应商品的一个特征；
  ![](media/image7.png)人做决策的时候就一般会把自己最看重的“品质”第一个考虑（根节点？），然后在满足第一个“品质”要求的商品中，选择第二看重的“品质”，依次类推；
  ![](media/image7.png)给你一个数据集，是人们购买商品的记录，包括产品功能、质量、  价格在内的信息，虽然每个人对商品的“品质”看法具有个性，但是你能不能从中找到共性，让计算机自动找到大部分顾客最看重的“品质”？
  ![](media/image337.png)对生产厂商、顾客都非常重要。
  问题：如何从数据集中找到最被看重的属性！



  ![](media/image338.jpeg)

例子
  ![](media/image6.png)Patrons 比 Type 更好
  why？



数据集合的不纯性
  ![](media/image7.png)假设采用了某个属性划分了数据集，我们通过划分结果的好坏来定  义属性分割数据集能力
  ![](media/image7.png)分割属性选择的标准：
  ![](media/image337.png)纯：意指分割完后的子集异类的数据越少越好，将来可以很快地把  “不纯”的数据划分掉，降低子集未来划分出的节点数目
  ![](media/image5.png)不纯：比“纯度”的定义和计算更直接和简单一些。集合内的数据全  部属于一类，则不纯度为 0，均匀来自 2 类或多类，则不纯度最大




  信息熵/熵不 纯 度
####   分割属性选择标准： 不纯性
  Gini 指数







          信息增益/熵不 纯 度
        误差不纯度


信息熵
  ![](media/image6.png)![](media/image7.png)
```
∑
```
给定随机变量的概率分布向量 (*p*1*, **p*2*, . . . , **p**m*)，信息熵即概率向量的对数期望值：*H *= *− **i** p**i** *log *p**i*，量化该随机变量的不确定性。假设：集合中有无穷多 *m *种不同的球，每种球的占比服从上述概
  率分布；若每个球的抽取概率相等；随机抽取一个球出来，当上述  概率分布相等时，抽出哪一种球是最“混乱”无规律的，不确定性  最大的；当集合最“纯”时，几乎全是一种球，那么随机抽取出一  个球，很大可能都是确定的。
熵不纯度
  ![](media/image7.png)
```
∑
```
给定决策树节点 *N*，定义其熵不纯度为*i*(*N*) = *H*(*N*) = *−**i** **p**i** *log *p**i*
  ![](media/image6.png)其中 *p**i** *是节点 *N *拥有数据集 *D *中，属于第 *i *类的数据在 *D *中的占比


  ![](media/image7.png)应用方法：给定节点 *N *确定采用哪个属性来分割计 算 *i*(*N*) = *H*(*N*)
  ![](media/image6.png)对所有的属性 *A**i** *依次执行下述计算：
      ![](media/image31.png)依据 *A**i** *的不同取值，获得多个子节点及其拥有的子数据集 *D**i*
      ![](media/image31.png)对所有的子节点 *N**i** *计算 *i*(*N**i*) = *H*(*N**i*);
      ![](media/image31.png)
```
即不确定性降低的量
```

```
\*|\*\*N\*\*|\*
```
计算信息增益：*IG*(*N**|**A**i*) = *H*(*N*) *−** *∑*i**  * *|**N**i**|** **H*(*N**i*) ≜ *H*(*N*) *−**H*(*N**|**A**i*)，


# ID3 算法


        ![](media/image345.png)

信息熵和信息增益计算的例子
  ![](media/image7.png)数据集中，年龄取三个不同的值，把数据集划分为三个子集，每个  子集分别包含不同的正例个数 *p**i** *和负例个数 *n**i*，如表，可以算出第四列的信息熵
  ![](media/image7.png)![](media/image337.png)分割后的信息熵为：5/14\*0.971+4/14\*0+5/14\*0.971=0.694 故信息增益为：
  -9/14\*log(9/14)-5/14\*log(5/14)-0.694=0.940-0.694=0.246




  ![](media/image338.jpeg)


Patrons 比 Type 更好
  ![](media/image7.png)请给出用熵不纯度判断的计算过程。



信息增益率: 避免信息增益倾向选择值多的属性
  信息增益率： *IG*(*N**|**A**i*)  =  *H*(*N*)*−**H*(*N**|**A**i*)
  ![](media/image337.png)
          *H*(*N**|**A**i*)*H*(*N**|**A**i*)
  ![](media/image6.png)用信息增益除以分割后的信息熵

#   信息增益率 + 对连续属性的处理
  =*⇒*C4.5 算法


误差不纯度
  ![](media/image7.png)*i*(*N*) ≜ *H*(*N*) = 1 *−** *max*i** p**i*
  ![](media/image7.png)其中 *p**i** *是集合中，第 *i *类数据的占比

```
∑
```
Gini 指数

  ![](media/image7.png)*i*(*N*) ≜ *H*(*N*) =*i*
  据的占比
*j** **p**i**p**j** *= 1 *−** *∑*i** **p*2*i** *, 其中 *p**i**  *是集合中，第 *i** *类数


  ![](media/image7.png)Gini 指数的“增益” 类似于信息增益
  ![](media/image6.png)![](media/image6.png)本质上还是找到一个属性，它分割数据集后，剩下的 Gini 指数最小在相同的初始水平上，下降量和最后下降到的水平，二者是一致的


Gini 指数的应用方法
  ![](media/image7.png)Gini 系数的计算过程为不停地二分节点 *N *为两个子节点，故得到的是一棵“二叉树”
  ![](media/image7.png)因为二分节点  *N*，所以对于任意一个多值属性需要一个“值域二分” 过程，即把值域分成两个子集，以此来划分数据集；
  ![](media/image7.png)![](media/image6.png)值域二分过程非常耗时，时间复杂度是值域大小的指数函数  在各种值域二分后的结果上都要计算最优的基尼指数

# CART 树算法


  ![](media/image346.png)

应用的例子
  ![](media/image337.png)
```
14
```

```
14
```
*gini*(*D*) = 1 *−** *( 5 )2 *−** *( 9 )2 = 0*.*459
  ![](media/image337.png)income 是多值的 *{**l**, **m**, **h**}*，有三种值域划分方法
  ![](media/image337.png)*gini**l**,**m*(*D*) = 10 *gini*(*D*1) + 4 *gini*(*D*2) = 0*.*443
        1414
  ![](media/image6.png)类似有 *gini**l**,**h*(*D*) = 0*.*458*, **gini**m**,**h*(*D*) = 0*.*450
  ![](media/image6.png)所以最优值域二分为:*{**l**, **m**, **h**} *= *{**l**, **m**} ∪ {**h**}*，故 *gini**income*(*D*) = 0*.*443
  ![](media/image7.png)类似可以计算 *gini**age*(*D*) = 0*.*357*, . . .*


      ![](media/image347.jpeg)

考量的因素
  ![](media/image7.png)信息增益：偏向选择值多的属性
  ![](media/image6.png)![](media/image7.png)信息增益率：解决了 ID3/信息增益偏向值多属性的弊端，但是会造成不平衡分割，偏向于分割为大小相差大的各个子集Gini 系数：偏向于值多的属性，类多（*y *值多）的时候存在困难；偏向于子集大小大致相等，纯度大致相等的分割
  不纯度度量的选择往往不是决策树设计时最重要的因素，大量的实践表明，不同的不纯度，结果基本相当。




其它候选项
  ![](media/image6.png)![](media/image6.png)*CHAID*：基于卡方对属性进行独立性检验*G*-统计：类似于卡方
  ![](media/image6.png)最小描述长度：用一种方法描述一棵树，树的增长用到了最小的长  度，就最好，核心要描述的就是“树”以及“树的异常（错分的数据）”
  ![](media/image337.png)属性的线性组合获得新的属性


提高决策树的性能：避免过拟合
  ![](media/image7.png)![](media/image6.png)分支太多，有些靠近叶的分支可能因为噪声，异常点等造成过拟合  泛化能力太差

解决办法
  ![](media/image7.png)先剪枝：提前停止树的构建，不再分割某个节点，停下来直接构建  叶节点，叶节点标号为父节点的占优类或者类分布/比例。如设置信息增益的阈值，某个节点无论如何分割，都无法获得超过阈值的  信息增益，那么分割就停止。阈值如何设置？难点。
  ![](media/image5.png)后剪枝：生成决策树之后，再去掉某些分支。比如：训练时保留一部分训练数据（剪枝集）不用，用来把一个完全训练好的决策树剪枝。



连续型数据/属性的处理
  ![](media/image5.png)离散化处理技术：离散区间


缺失值的处理
  ![](media/image337.png)中心趋势度量
  ![](media/image5.png)每个取值赋予一个取值概率



面对大数据集：无法一次在内存中放下所有的训练数据
  ![](media/image337.png)在决策树的每个节点考察每个候选分割属性的时候都要载入一次训  练数据集；涉及内外存数据交换，性能低；
  ![](media/image6.png)方法一：采用 RainForest 算法来改进，载入一次数据，完成对所有候选分割属性的不纯度计算；（详细算法请自行查阅资料）
  ![](media/image6.png)方法二：用随机采样获得可以全部放入内存的训练数据子集，在获  得的子集上构造决策树；可重复采样，构造多棵决策树；然后用集  成学习的方法综合多棵决策树的结果获得最终判决。




  ![](media/image7.png)决策树：综合多个线性判决的方法简单，可解释性好
  ![](media/image7.png)是完备的，因为所有函数在计算机内都可以转化为 *n *维真值表, 任何一个 *n *维真值表都可以如对应一个完全二叉树；也就是任何函数的任何 *x *都可以用一颗二叉树来判决其输出；
  ![](media/image5.png)描述复杂性一般用节点的数目来度量。

![](media/image1.png)



## ********人工智能讲义
  **神经网络**


  May 7, 2019

### ****Outline
  
```
\*\*1\*\*
```

```
\*\*2\*\*
```

```
\*\*3\*\*
```
[特征提取函数]()[神经网络的例子]()[神经网络]()
  
```
\*\*4\*\*
```
[深度神经网络]()
  
```
\*\*5\*\*
```
[卷积神经网络 CNN]()
  
```
\*\*6\*\*
```
[循环神经网络 RNN]()
  
```
\*\*7\*\*
```
[神经网络近年来的进展]()



作用
  ![](media/image7.png)消去线性 *h*(*x*) 的常数项：*h*(*x*) = **W **· **x **+ *b *= **W **· *ϕ*(**x**)
  ![](media/image7.png)从输入变量空间（如图片，一段语音）映射到一个更有预测意义的  “特征空间”
  ![](media/image7.png)实现某些非线性的处理

#### 寻找通用的特征提取函数的构造方法！



讨论线性判决的例子
  ![](media/image7.png)线性 *h*(*x*) = **W **· *ϕ*(*x*)，分数 *score *由 **W **和特征提取函数 *ϕ*( · )
  来共同决定。
  ![](media/image7.png)我们有一套方法/机制来评价 *h*(*x*)，而 *h*(*x*) 的部分影响因素 *ϕ*( · )
  如何评价？
  ![](media/image7.png)*ϕ*( · ) 被线性分类器 *h*(*x*)“使用”，不同线性分类器使用方式不同的
  (**W **会产生相互影响)，发生的作用大小不一样，不好评价.

因此，摒弃或屏蔽 **W **带来的影响!


考虑相同 *ϕ*( · ) 的所有 **W **可以屏蔽 **W **带来的影响
  ![](media/image5.png)
```
\*H\*\*{\*\*∈\*\*}\*
```
假设类：  Φ =  *h***W**** **: **W***R**d** *，所有满足下列条件的假设/模型 *h*
  的集合：
      ![](media/image31.png)*ϕ*( · ) 相同
      ![](media/image31.png)**W **不同，即参数不同
  ![](media/image7.png)用假设类中使得 *h*(*x*) 性能最好的 **W **来代表 *ϕ*( · ) 的性能
我们比较不同“假设类”的性能，来评价特征提取函数 *ϕ*( · ) 的性能
  ![](media/image6.png)由 *ϕ*( · ) 确定的“假设类”是所有可能假设的一个子集
  ![](media/image7.png)学习算法从“假设类”中搜索最优的参数 **W**，确定最优假设
  ![](media/image7.png)如果特征提取函数不好，即特征空间的表示能力不行，再怎么学习也得不到一个好的假设 *h*
  ![](media/image337.png)我们不关心 *ϕ*( · ) 是否会导致很多“糟糕的”*h *存在于“假设类”中，只关心它产生的那个最优假设性能如何
  ![](media/image5.png)(正则化：控制假设类中 **W **的取值范围 (复杂性)，减小 *H*Φ，如 min*∥***W***∥*)



假设类的例子



解释说明

*x*R*,** **y*R

```
\*∈\*\*∈\*
```
Linear function: Φ(*x*) = *x*

```
\*H\*\*{\*\* \*\*→\*\*∈\*\*}\*
```
1 =  *x**w*1*x** *: *w*1R
Quadratic functions:Φ(*x*) = [*x**, **x*2]*t*
*H*2 = *{**x **→** **w*1*x *+ *w*2*x*2 : *w*1 *∈** *R*, **w*2 *∈** *R*}*

  ![](media/image7.png)我们增加了特征 *x*2，就能够描述二次函数/用二次函数 *h *来进行逼近真实 *f*，增加了表达能力；
  ![](media/image6.png)增加特征，往往意味着增加“假设类”的大小/size，即在更大的范围内搜索最优假设 *h*，但是付出的代价是，通常会增加寻找最优参数 **W **的难度



  ![](media/image6.png)*x** *表示病人，*y** *= +1 表示身体健康，*y** *= *−*1 表示身体不好; 特征是什么？
  ![](media/image6.png)基本思路：提取和 *y *相关的所有特征！
  ![](media/image7.png)![](media/image6.png)病人 *x *的特征：体温/血压/是否咳嗽/体重/…… 存在的问题：（用于线性预测 **W**** **· *ϕ*(*x*)）
      ![](media/image31.png)特征 *ϕ*(*x*) 和输出 *y *之间的关系可能是非单调的，例如由体温判断健康状况；
      ![](media/image31.png)特征 *ϕ*(*x*) 和输出 *y** *之间的关系不一定是线性的，例如由产品购买人数预测用户是否购买；
      ![](media/image31.png)特征 *ϕ*(*x*) 内部不同维度之间有相互作用/影响/相关，例如由身高和体重来预测健康状况；


*ϕ*(*x*) 和输出 *y *之间是非单调的关系
  ![](media/image337.png)由体温判断健康状况：（体温低于或高于正常体温 37，意味着可能会有问题）
  ![](media/image5.png)特征 *ϕ*(*x*) = [1*, **T*(*x*)]*t*，描述偏差 (常数项）和体温
  ![](media/image6.png)
```
\*−\*
```
特征 *ϕ*(*x*) = [1*, *(*T*(*x*) 37)2]*t*，将“正常人体温 37”硬编码进入特征提取函数，需要领域知识；
  ![](media/image7.png)
```
\*−\*
```
特征 *ϕ*(*x*) = [1*, **T*(*x*)*, **T*(*x*)2]*t*，通用方法，将构建正确特征提取函数的“基本构造因子”列入特征向量，领域知识 (*T*(*x*) 37)2 可以通过足够的样本用基本构造因子表示出来。

# 问题：包括哪些“基本构造因子”？




*ϕ*(*x*) 和输出 *y *之间不一定是线性关系
  ![](media/image6.png)由产品的购买人数预测用户是否会购买产品
  ![](media/image6.png)特征 *ϕ*(*x*) = *N*(*x*)，即购买人数。但是 100 人购买 100 件产品和
  100 人购买 1000 件产品的差异被“忽视”了
  ![](media/image7.png)特征 *ϕ*(*x*) = *log*(*N*(*x*))，当值域较大时，缩小值域
  ![](media/image7.png)特征 *ϕ*(*x*) = [1[0 *&lt; **N*(*x*) *&lt; *11]*, *1[10 *&lt; **N*(*x*) *&lt; *101]*, . . . , *]*t*，有些类
  似上一个方法，离散化技术



*ϕ*(*x*) 内部不同维度之间相互影响
  ![](media/image7.png)由身高和体重判断病人 *x *的健康状况
  ![](media/image7.png)特征 *ϕ*(*x*) = [*height*(*x*)*, **weight*(*x*)]*t*，身高和体重之间有合适的“健康”关系
  ![](media/image7.png)
```
\*−\*\*−\*
```
特征 *ϕ*(*x*) = (52 + 1*.*9(*height*(*x*)60)*weight*(*x*))2, from J.D.Robinson，需要领域/专家知识才能给出这个式子
  ![](media/image337.png)特征 *ϕ*(*x*) =
  [1*, **height*(*x*)*, **weight*(*x*)*, **height*(*x*)2*, **weight*(*x*)2*, **height*(*x*)*weight*(*x*)]*t*， 通用方法，给出“基本构造因子”构成的特征抽取函数
  ![](media/image7.png)存在的一个问题，基本构造因子最高次数如何确定?



特征提取函数设计的通用方法
  ![](media/image349.png)定义输入 *x *的各个单项式构成的向量为特征 *ϕ*(*x*)
  ![](media/image350.png)存在问题：单项式的最高次数难以确定，太高会过拟合，增加计算  代价；太低可能不能很好地处理复杂的非线性决策边界

线性 *h*(*x*)+ 特征提取函数: 处理非线性 *f*
  ![](media/image350.png)**W **和特征 *ϕ*(*x*) 都是值向量，它们做内积运算得到分数 *score*，是线性运算，整个过程非常简单高效；
  非线性的部分，可以用非线性的特征提取函数来获得.


问题描述
  ![](media/image7.png)假设输入是两车的位置 *x *= [*x*1*, **x*2]，一维位置
  ![](media/image7.png)当车距大于等于 1 时，是安全的 (*y *= +1)，当车距小于 1 时，认为是危险的，二者会相撞 *y *= *−*1 , 真实 *f *的表达式如[nn-1]()所示
  ![](media/image5.png)这是一个非线性的分类问题，可以用特征提取的方法来处理非线性，  使之转化为用线性 *h** *来近似真实的 *f*，关键在合适地选择特征提取函数
  ![](media/image7.png)这里用神经网络来实现一个 *h*，去近似 *f*

            *y** *= *f*(*x*) = *sign*(*|**x*1 *−** **x*2*|** **−** *1)(nn-1)


分情况讨论
  ![](media/image7.png)如果车 1 在车 2 的右边很远处，即 *h*1 = 1[*x*1 *− **x*2 *≥ *1]
  ![](media/image351.png)如果车 2 在车 1 的右边很远处，即 *h*2 = 1[*x*2 *− **x*1 *≥ *1]
  ![](media/image351.png)
```
\*≥\*
```
上述两种情况不可能同时出现，只要出现一种，就会 *h*1 + *h*21，就可以判定两车处于安全车距 *y** *= +1。上述两种情况包括了所有安全车距的情形，故我们可以定义 *h** *为


数据例子



    Table: 具体数据例子
*h *= *sign*(*h*1 + *h*2)
  求解方法总结与提高
    ![](media/image352.png)![](media/image353.png)
```
|              |    |    |              |
|--------------|----|----|--------------|
|[\*x\*1\*, \*\*x\*2]|\*h\*1|\*h\*2|\*y \*= \*h\*(\*x\*)|
|[3\*, \*1]      |1   |0   |1             |
|[1\*, \*3]      |0   |1   |1             |
|[1\*, \*0\*.\*5]  |0   |0   |0             |


```
定义 Φ(*x*) = [1*, **x*1*, **x*2] 分别求两个子问题： *h*1 = 1[*v*1 · Φ(*x*) *≥ *0]
    *h*2 = 1[*v*2 · Φ(*x*) *≥** *0]
    ![](media/image352.png)然后综合两个子问题的解，
    *h *= *sign*(*w*1*h*1 + *w*2*h*2)，得到原问题的解。
    ![](media/image353.png)反思：非线性问题，用多个线性问题来近 似（本例子中要解三个线性子问题）。分而治之

求解子问题 *h*1
  ![](media/image7.png)*h*1 = 1[*v*1 · Φ(*x*) *≥ *0] ，分段线性函数（两条射线的并集）
  ![](media/image7.png)![](media/image7.png)
```
\*−≥−\*\*−\*
```
任意二值的两段线性函数，总可以用一个解析式表示出来：*h*1 = *sign*(*v*1 · Φ(*x*)) 因为已知 *h*1  = 1[*x*1      *x*2      1]，故能看出来该子问题 *v*1  = [  1*, *1*,   *1]，通常我们对 *h*1 一无所知，只有数据集，该如何求解 *v*1？
  ![](media/image6.png)如左下图所示的符号函数，无法利用梯度信息来求解 *v*1，因此我们引入右下图所示的可导的 logistic 函数来替换符号函数
  ![](media/image7.png)数据集 + 线性模型 *−→ *优化问题 *−→ *梯度下降
![](media/image354.jpeg)![](media/image355.jpeg)
Figure: 符号函数：*sign*Figure: logistic 函数


激活函数
  ![](media/image5.png)对分数/score 做一种非线性映射/变换，增加非线性处理能力，是对生物机制的模拟。

![](media/image356.jpeg)常见的激活函数 1









  1sigmoid 就是 logistic


![](media/image357.png)![](media/image358.png) ![](media/image359.png)

ReLu/Rectified Linear Units/Rectifier 的优点
  ![](media/image6.png)稀疏激活性：激活少量的神经元，2003 年 Lennie 等人估测大脑同时被激活的神经元只有 1 4%; 快速提取（稀疏）特征，噪声的剔除； 线性特征，非线性处理变成选择性激活
  ![](media/image7.png)单侧抑制（有界）和相对较宽阔的兴奋边界，降低梯度“消失”的  影响 (梯度的计算要乘两个小于 1 的缩减因子)


图形化线性函数
  ![](media/image7.png)我们用一种图形来直观描述一个线性函数，如图所示
![](media/image360.jpeg)

  Figure: 线性函数 *score** *= [*ϕ*(*x*1)*, **ϕ*(*x*2)*, **ϕ*(*x*3)] · *W*


图形化“激活的”线性函数
  ![](media/image361.png)若将激活函数加入，得到下图

![](media/image362.jpeg)

  Figure: “激活的”线性函数 *h *= *σ*(*score*) = *σ*([*ϕ*(*x*1)*, **ϕ*(*x*2)*, **ϕ*(*x*3)] · *W*)


图形化线性函数
  ![](media/image5.png)将例子中三个线性子问题的求解过程描述依据求解的次序描述出来
  （*h*1*,** **h*2 可以并行求解），如图所示，这就是“神经网络”
![](media/image363.jpeg)

  Figure: 例子：神经网络


基本概念：NN
  ![](media/image361.png)![](media/image7.png)网络结构: 输入层、隐层、输出层，权值，隐层单元/节点激活函数
  ![](media/image7.png)![](media/image6.png)训练信号/样本数据隐层输出与数据特征
![](media/image363.jpeg)


例子中存在的基本问题
  ![](media/image6.png)我们不知道 *h*1 的意义，即车 1 在车 2 很远的地方
  ![](media/image7.png)求解子问题 *h*1 需要有训练数据，实践中，没有用于训练 *h*1 的数据
  ![](media/image361.png)具体来说，如下表，*h*1*, **h*2 列是手工分解问题后的中间结果，一般情况下， 我们没有手工分解问题及其中间结果，即中间两列不存在。如何获得
  *v*1*, **v*2? *w *的训练是有“监督信号”的。
  ![](media/image7.png)思路：能不能利用 *w *的监督信号，把它无法解决的“误差”反向传递给
  *v*1*, **v*2，让它们去解决？

```
|              |    |    |              |
|--------------|----|----|--------------|
|[\*x\*1\*, \*\*x\*2]|\*h\*1|\*h\*2|\*y \*= \*h\*(\*x\*)|
|[3\*, \*1]      |1   |0   |1             |
|[1\*, \*3]      |0   |1   |1             |
|[1\*, \*0\*.\*5]  |0   |0   |0             |


```
![](media/image363.jpeg)
Table: 具体数据例子Figure: 例子：神经网络




  ![](media/image7.png)NN 中权值学习问题描述给定数据集 *D*
  ![](media/image7.png)![](media/image7.png)给定网络结构：隐层数目及各层节点数，连边方式等； 求：“各边的权值”


导数/偏导数的意义
  ![](media/image361.png)![](media/image7.png)
```
\*∂\*\*in\*
```
输入 *in *的微小改变是如何影响输出 *out *的？一种“敏感性分析” 当 *in*1 发生改变 *ϵ *时，输入 *out *发生的改变为 *∂**out** **ϵ*
          1
  ![](media/image7.png)用图形来描述导数计算，如下图 (*out *= *function*(*in*1*, **in*2*, **in*3))。边上的绿色字体标记导数，孩子节点是输入变量。
![](media/image364.jpeg)
  Figure: 导数计算的图形化描述


    ![](media/image365.jpeg)

  Figure: 常见函数的偏导数图形表示


                    ![](media/image366.png)进一步解释
                      ![](media/image18.png)复合函数求导的“链式法则”
                      ![](media/image23.png)神经网络权值训练需要用梯度下降法，计算一个复杂的复合函数的梯度/偏导数
                      ![](media/image367.png)如右图，*in *的微小改动 *ϵ*
                      最后在 *out *出的变动为
                       *∂**out**ϵ *= *∂**out **∂**mid**ϵ*

![](media/image18.png)*∂**in*
  *∂**mid*
*∂**in*



  Figure: 复合函数的偏导数图示
    计算复合函数的导数时，计算其孩子节点所在单路径子树的分支乘积。











  ![](media/image368.jpeg)Figure: Hinge loss 函数的偏导数
  进一步解释说明
    ![](media/image23.png)hinge loss: *loss*(*x**, **y**, **W*) =
    *max**{*1 *−** **W *· *ϕ*(*x*)*y**, *0*}*
    ![](media/image18.png)右图由“常见偏导数的图形表示”，以及“复合函数的偏导数描述”二者一起绘制出来
    ![](media/image17.png)
```
\*∂\*\*W\*
```
最终偏导数/梯度信息，由边上的绿色“权值”相乘获得。*∂**loss*(*x**,**y**,**W*) =
    *−*1[*margin **&lt; *1]Φ(*x*)*y*


    ![](media/image369.jpeg)

          Figure: 平方损失函数的梯度/偏导数计算


  ![](media/image369.jpeg)
  Figure: 平方损失函数的梯度计算

    ![](media/image18.png)![](media/image18.png)核心亮点：快速梯度计算权值更新：知道梯度信息， 也就知道了“最佳”修改权
BP 算法核心思想
    ![](media/image18.png)给图中红色叶子节点/变量赋随机初值；
    ![](media/image23.png)将数据 (*x**, **y*) 代入叶子输入变量，从叶到根，计算每个中间节点的输出（前向值 *f**i*），直到根节点/输出节点，得到 *f*0； 此为 前向过程；
    ![](media/image367.png)
```
\*−\*
```
我们希望根 *f**∗*0  = 0，故，从根开始，把“误差”向下（向输入层）反馈。回答问题：根节点有误差 *g*0 = *f*0      *f**∗*0，是如何被任意一个中间节点 *i *的误差所影响？求每个中间节点对根节点影响，即后向值:
    *g**i *= *∂**out **∂**f**j** *= *∂**f**j** **g**j*. 此 为 后

    值的方法，权值沿负梯度方向行走一个步长/学习率。
*∂**f**i*
    向传播
*∂**f**i*
*∂**f**i*




  ![](media/image7.png)步长/学习率如何设置达到最优？
  ![](media/image7.png)网络有几个隐层，每个隐层各有几个节点？节点间如何连边？（网络结构设置）
  ![](media/image370.png)如何对时间序列问题进行预测？
  ![](media/image371.png)如何使用样本？先把一个样本数据进行多次循环（前向/后向过程），训练完毕，再训练下一个样本（在线学习），还是一批样本依次轮换循环？
  ![](media/image6.png)......


深度学习
  ![](media/image7.png)在图像/语音识别领域获得了突破性进展2，成为目前机器学习领域最热门的研究课题。
  ![](media/image372.png)深度学习的出发点: 类标号也是一种输入数据的“抽象”特征，分类器 *h*
  被视为一种“特征提取函数”。
几点解释说明
  ![](media/image7.png)以前，我们总是用神经网络直接来实现图像或语音的识别/分类；现在， 认为神经网络可用来自动提取图像/语音的特征；
  ![](media/image373.png)模式识别中，一般来说，如果特征提取的非常好，分类器就会很容易获得，    如用简单的线性判别即可；
  ![](media/image7.png)如何设计好的“特征提取函数”？具体问题具体分析，领域知识等。
  ![](media/image6.png)深度学习，近乎于任何图像/语音数据都可以用神经网络来进行自动特征提取，而且效果非常好！神奇！

  2参考《Natrue》2015 年综述性论文“deep learning”


神经网络被诟病的缺点之一
  ![](media/image373.png)在做预测/分类之前，神经网络的训练代价大，收敛速度慢（获得收敛的权值）；当隐层的层数和节点的数据增加时，该问题尤为突出；以前，通常应用中都只用一个隐层。

深度神经网络
  ![](media/image7.png)很多个隐层，但是不用 BP 算法去训练权值。

如何做？ 新的权值训练方法用于深度神经网络！



          ![](media/image374.jpeg)

  Figure: 例子：深度神经网络





  ![](media/image375.jpeg)

  Figure: 例子：深度神经网络学习方法的改进
  特征提取的核心思想：自编码器
    ![](media/image18.png)每个隐层独立训练，训练一个三层
    BP 网络；
    ![](media/image19.png)对任意一个三层 BP 网络：输入层是前一个隐层的输出（或原始输入数
    据），输出层与输入层完全一样；训练该三层 BP 网络；
    ![](media/image376.png)丢弃输出层及其关联边；
    ![](media/image23.png)重复上述过程，进行多次，得到多个连续的隐层；这个循环过程构建了一系列的自编码器。
    ![](media/image18.png)最后，利用“监督信号”训练最后一个输出层连边的权值。


特征提取不需要“监督信号”
  ![](media/image377.png)现实中，训练数据/类标签通常难以获得；有大量的数据没有标签
  （即有 *x*，没有 *y*），该方法的特征提取过程可以充分利用大量没添加标签的数据。（分类就是为了给数据自动添加标签）

训练代价相对于整体的梯度下降要小很多
  ![](media/image7.png)虽然每个三层 BP 网络的训练还是比较费时间，相对于多层的 BP， 时间代价已经降低了。

隐藏的约束条件
  ![](media/image7.png)![](media/image7.png)假设数据来自某个具有“特点”数据生成器或者说给定的数据集具有“可分类”的特点


从左下角，沿蓝色箭头方向查看。
![](media/image378.jpeg)

  Figure: 深度神经网络构建示意图


深度神经网络
  ![](media/image6.png)任何一个隐层，实现了对原始输入数据的一种特征提取，找到了数据的“规律”，实现了一种“数据压缩”。

问题
  ![](media/image7.png)超参数的设计：层数，每层的节点数；
  ![](media/image7.png)如何避免隐层节点及其参数是“平凡的”；
  ![](media/image6.png)一般认为：随着层次的增加，后续的特征越来越抽象；越抽象就能  更好地去实现分类吗？
  ![](media/image6.png)![](media/image7.png)不同类型/超高维原始输入数据的应用（大数据的特点） 理论分析困难：随机性
  ![](media/image379.png)深度神经网络更接近生物大脑？


![](media/image380.jpeg)

  Figure: 例子：分层提取的特征



两个关键点
  ![](media/image6.png)![](media/image7.png)观点的改变：神经网络用于特征提取，隐层是一个特征提取函数；  权值学习方法的改变：自编码器，实现隐层代表的特征提取函数。

两大类深度学习网络3
  ![](media/image6.png)卷积神经网络 /Convolutional Neural Network,CNN: 对连接方式做了约简处理
  ![](media/image7.png)循环神经网络/Recurrent Neural Networks,RNN: 应用于序列数据


  3进一步学习请网上搜索相关文献和材料，slides 中仅仅阐述了基本原理。

输入
  ![](media/image7.png)假设输入是二维图像，一个数值矩阵描述，矩阵每个元素代表对应  位置像素点的灰度值；如图所示
  ![](media/image6.png)构建全连接神经网络，隐层节点数为 1 百万，输入层和隐层之间连
  边有 1012 条，也就是需要确定的参数个数
  ![](media/image7.png)训练难度高，需要样本量大
![](media/image381.jpeg)


利用：隐层节点的局部性
  ![](media/image6.png)将隐层的每个节点视为一个神经元，能感知外界输入信息（和输入层相连），处理输入层的信息；
  ![](media/image7.png)一个（合理的）假设：每个隐层节点能感受到的信息都是输入信息的某个局部（图像的某个小块）；如图所示；每个隐层节点连接 10 *×** *10 的局部区域，共 108  个参数要确定
  ![](media/image5.png)隐层节点感知的信息处理后被后续的隐层节点处理，综合成更大范围、直至全局的信息。
![](media/image382.jpeg)

利用：隐层节点的同一性
  ![](media/image6.png)将隐层的每个节点都是一样的，假设其对输入的加权方式和处理方式都是同样的，即功能完全一样的神经元；（合理性：统计显示不同位置，神经元处理方式相似）
  ![](media/image379.png)108 个参数变成了 100 个参数需要确定；这种技术被称为“权值共享”。其中这 100 个参数构成的神经元处理方式称为一个滤波器/filter 或卷积核
![](media/image383.jpeg)

卷积核：例子 1




![](media/image392.jpeg)卷积核：例子 2

不同的卷积核，不同的特征
  ![](media/image7.png)不同的卷积核，对应一类不同的图像特征 (或者叫特征提取方法)；每个卷积核作用在输入图像上，就得到一个特征映射 (feature map)；特征映射可视为图像的一种变换
  ![](media/image6.png)取多个不同的卷积核，提取多种特征，多角度描述图像；每个特征形成一个“平面图像”
  ![](media/image6.png)参数的个数和卷积核的结构大小，卷积核的个数相关，与输入层节点数、隐层节点数无直接      关系!
  ![](media/image393.jpeg)![](media/image7.png)卷积层的层数越高，提取到的特征就越全局化。

池化/Down-pooling/下采样:
  ![](media/image5.png)聚合特征、降维，达到减少运算量的目的；
  ![](media/image379.png)对一块数据进行抽样或聚合，例如选择该区域的最大值（或平均值）  取代该区域；
  ![](media/image394.jpeg)![](media/image7.png)下图的例子将 10\*10 的区域聚合成 1\*1 的小方块。思考一下，所有的卷积结果都这样处理一遍。

           





输出层：
  ![](media/image7.png)全连接层
  ![](media/image7.png)前面的层输出作为输入
  ![](media/image7.png)以此构建一个经典的用于分类的神经网络





                    ![](media/image402.png)RNN 图示与符号
                      ![](media/image91.png)A: 神经网络模块，*x**i** *输入，*h**i *输出
                      ![](media/image114.png)循环使得前一时刻的信息能当成当前时刻的输入


理解：将 RNN 的循环展开
![](media/image403.png)
长期依赖问题
  ![](media/image7.png)![](media/image7.png)RNN 的特点就是能把历史信息应用到当前多长的历史信息会对当前产生影响？
  ![](media/image7.png)RNN  很难处理时间上很长的历史信息


    ![](media/image404.jpeg)

RNN 背后
  ![](media/image379.png)序列数据，先后出现的数据之间存在关联
  ![](media/image7.png)对序列数据的每个数据，RNN 执行相同操作，但是输入和前面的状态或输出相关
  ![](media/image7.png)隐藏层 s 的状态计算 *s**t *= *f*(*Ux**t *+ *Ws**t**−*1)，其中 *f *可以是 tanh 或 ReLU,*s**t *含有历史信息
  ![](media/image7.png)RNN 用隐含层状态来捕获数据的特征


    




  ![](media/image6.png)LSTM: Long Short Term Memeory，长短时记忆网络特殊类型的 RNN，可用于学习长期依赖信息；
  ![](media/image7.png)刻意的设计，LSTM 的默认行为是记住长期信息；
  ![](media/image379.png)改进之处：RNN 中的 A(重复的循环体）只有一个单一的层结构， 例如 tanh


    ![](media/image407.png)
![](media/image408.png)



    ![](media/image409.png)


图例说明
  ![](media/image6.png)带箭头的实线：表示在两个节点间传输一个向量
  ![](media/image5.png)![](media/image5.png)粉色圆：表示 pointwise 的操作，例如求两个向量的和黄色矩形框表示学习的神经网络层










![](media/image410.png)类比解释：
  ![](media/image6.png)最重要的信息流：如图，从左到右水平方向 *C**t**−*1 *→ **C**t*
  ![](media/image6.png)信息在黑实线上传输，途中经过其它信号的叠加或干涉


              ![](media/image411.png)

“门”的设计：
  ![](media/image7.png)信息流中增加或删除信息的控制开关
  ![](media/image7.png)![](media/image7.png)包含一个 sigmoid 神经元/网络，和一个 pointwise 的乘法操作sigmoid 输出 [0*, *1] 之间的实数，描述信息流每个分量能通过的多少，例如：0 表示不允许任何量通过，1 表示允许任意量通过。


  ![](media/image412.png)

LSTM 的遗忘门设计：
  ![](media/image7.png)第一步：信息流中删除什么信息？
  ![](media/image7.png)
```
\*−\*
```
从上一时刻的输出 *h**t** *1 和当前的输入 *x**t** *通过一个 sigmoid 神经元， 输出一个 [0*, *1] 之间的实数，0 表示完全舍弃，1 表示完全保留；也就是这个输出和 *C**t**−*1 的每个分量做乘法运算。


  ![](media/image413.png)

LSTM 的输入门设计：
  ![](media/image7.png)第二步：信息流中增加什么信息？
  ![](media/image7.png)第一个 sigmoid 层，被称为输入门层，用来选择/确定更新值；一个
  tanh 层来创建各个更新值的候选值 *C*˜*t*



  ![](media/image414.png)

LSTM 的遗忘门和输入门的实现：
  ![](media/image6.png)前两步确定了信息如何删减和增加
  
```
\*−\*\* \*\*∗\*\*∗\*
```
如图，开始实现：*c**t** ** *1*f**t** ** *实现历史信息的遗忘，然后加上 *i**t****C*˜*t*
  得到新的状态值/信息流；


  ![](media/image415.png)

LSTM 的输出门的设计与实现：
  ![](media/image379.png)第三步，信息流中的什么信息需要被输出？
  一个 sigmoid 层来确定那一部分信息被输出；信息流的 tanh 值被计算，形成输出的候选


  ![](media/image416.png)

流形 LSTM：
  ![](media/image6.png)增加 peephole 连接，如图
  ![](media/image7.png)sigmoid 层接受信息流状态的影响
  ![](media/image7.png)并不是每个 sigmoid 门都添加 peephole 连接


  ![](media/image417.png)

耦合型 LSTM：
  ![](media/image7.png)![](media/image7.png)如图，删除信息和增添信息由一个 sigmoid 门确定输入的新信息仅仅是用来替代删除的旧信息


  ![](media/image418.png)

GRU-LSTM：
  GRU：Gated Recurrent Unit，遗忘门 + 输入门 *→ *更新门
  如图，还混合了信息流状态，隐藏状态等；比标准 LSTM 简单？


      ![](media/image419.jpeg)![](media/image420.jpeg)
注意力机制
  ![](media/image6.png)目的：为了增加神经网络的可解释性，一种分解神经网络部件，进  而深入理解神经网络的思路
  ![](media/image7.png)思路：每个隐层节点是一种原始数据数据的特征，这个特征有多重  要？人会注意到这个特征吗？注意力放多少在这个特征上？
  ![](media/image7.png)技术：一切能够计算这个注意力的方法，有监督的方法/无监督的方法





输入的改变
  ![](media/image7.png)输入：可以扩展到任意的隐藏层，其为下一层的输入
  ![](media/image379.png)输入分割分组（多头/multi-head），复制多组或组合出更多维/multi-dimensional，胶囊/capsule）


胶囊网络
            ![](media/image421.jpeg)
![](media/image422.jpeg)




随机特征提取
  ![](media/image7.png)例如卷积神经网络，卷积核的训练不做，直接随机赋权值，做多个  不同的卷积核
  ![](media/image7.png)![](media/image7.png)从输入到各个隐藏层，权值都是随机； 仅仅只训练最后一层的分类器映射
  ![](media/image7.png)水库模型：reservoir

![](media/image1.png)




## ********人工智能讲义
  **贝叶斯网络****–****从概率论看机器学习**


  May 7, 2019

### ****Outline
  
```
\*\*1\*\*
```
[概率论基础回顾]()
  
```
\*\*2\*\*
```

```
\*\*3\*\*
```
[贝叶斯网络：PMF 的约简表示]()[获得贝叶斯网络]()
  
```
\*\*4\*\*
```
[贝叶斯推理：不确定性推理]()

随机变量的定义
  ![](media/image5.png)一个随机试验可能结果（称为基本事件）的全体组成一个基本空间
  Ω。随机变量 *X *是定义在基本空间 Ω 上的取值为实数的函数。
进一步理解
  ![](media/image5.png)和传统变量定义一样，随机变量 *X *首先定义在一个集合上，该集合称为随机变量的” 值域”，可以解释为 *X *表示将来会发生的某个事件，而值域就是所有可能事件的集合。
  ![](media/image7.png)与传统变量定义不一样，随机变量 *X *在其每个可能取值上都附加了一个“特征”: 取到该值的可能性，可以理解为：该值对应的事件重复发生了很多次，该值出频率或比例。
完整描述一个随机变量
  ![](media/image6.png)需要用两个集合来描述:
  ![](media/image7.png)取值范围/值域：*X **∈ **A *= *{**a*1*, **a*2*, . . .**}*
  ![](media/image7.png)特征：*p*(*X*) = *{**p*(*a*1)*, **p*(*a*2)*, . . .**}*


连续型随机变量
  ![](media/image5.png)连续型随机变量，若值域，即集合 *A*，由不可数的集合，如一段连续的区间组成。

离散型随机变量
  ![](media/image5.png)离散型随机变量，若值域，即集合 *A*，由有限或可列的元素组成。通常离散随机变量的值域可以映射到自然数集合或自然数的某个有限子集。

随机变量的“特征”：概率
  ![](media/image379.png)离散型：概率质量函数/Probability Mass Function/PMF, 每个值对应的概率;
  ![](media/image5.png)连续型：每个取值对应的概率都是 0，但是我们还是给出一个非 0 的概率，表示在该值附近的一个小区间内取值的概率。概率密度函数/Probability Density Function/PDF, 每个值对应的概率（虽然无法一一列出）；
  ![](media/image7.png)在不引发二义时，因计算机本质上是处理离散信息，我们的讨论将概率密度函数     和概率质量函数都统一称为“概率质量函数”。

函数与表格
  ![](media/image93.png)给定函数
  
```
\*∈\*\* \*\*{\*\*}\*
```
*y *= *f*(*x*)*, **x**v*1*, **v*2*, . . . , **v**n** *，可用如下表格来完全描述该函数

|       |              |
|-------|--------------|
|*x*    |*y *= *f*(*x*)|
|*v*1   |*f*(*v*1)     |
|*v*2   |*f*(*v*2)     |
|*. . .*|*. . .*       |
|*v**n* |*f*(*v**n*)   |

  Table: 用表格表示任意函数
函数与表格
  ![](media/image152.png)给定随机变量 *X*, 及其概率质量函数 *p*(*X*), 可用如下表格来完全描述随机变量：

|       |                      |
|-------|----------------------|
|*X*    |*p*(*X*)              |
|*a*1   |*p*1 = *p*(*a*1)      |
|*a*2   |*p*2 = *p*(*a*2)      |
|*. . .*|*. . .*               |
|*a**n* |*p**n** *= *p*(*a**n*)|

  Table: 用表格表示概率质量函数


随机变量 *X *的概率质量函数可以用表格右侧列来简化表示（假定表格左边的列序是固定的），即“概率向量”：(*p*1*,** **p*2*,** **.** **.** **.** **,** **p**n*)


问题
  ![](media/image7.png)用两个集合/向量来描述一个随机变量太复杂（描述长度），可以简化/压缩随机变量的描述吗？


```
∑
```
例子
  ![](media/image7.png)期望：*i** **p*(*X** *= *a**i*)*a**i** *两个向量（值域和每个值对应的概率特征） 被综合成一个值。
  ![](media/image379.png)
```
∑
```
类似期望，还有有方差，高阶矩等。
  ![](media/image379.png)
```
\*−\*\* \*∑
```
均值：不考虑概率向量，仅仅关注值域*i** **a**i*/*n*；
  ![](media/image5.png)信息熵：*i** **p*(*X** *= *a**i*) log2 *p*(*X** *= *a**i*), 概率特征向量被综合成一个值，不考虑值域。


随机向量的定义
  ![](media/image423.png)随机向量: 多个相关或不相关的随机变量构成的向量。
理解
  ![](media/image423.png)联合概率质量/密度函数：随机向量的任何一个取值（每个随机分量取一个值构成一个值向量）都对应一个概率，离散时称联合概率  质量函数，连续时称联合概率密度函数。
工程实践问题
  ![](media/image6.png)长度为 *n** *的随机向量，每个分量有 2 个取值，这样的联合概率质量函数（值域）有多大？或者说描述该联合概率质量函数的概率向量  有多少维？
  ![](media/image7.png)2*n*，当 *n *很大时，该联合概率质量函数在计算机中的“穷举”式表示存在问题，存储代价和遍历处理时间开销变得不可行。

随机向量的联合概率质量函数
  ![](media/image423.png)
```
\*|\*\* \*\*|\*
```
*X *= (*X*1*, **X*2*, . . . , **X**n*)，第 *i** *个随机分量的值域大小记为 *X**i** *, 其第 *j** *个取值为 *v**ij** *，则有如下表格表示联合概率质量函数：

|              |              |       |                  |                                   |
|--------------|--------------|-------|------------------|-----------------------------------|
|*X*1          |*X*2          |*. . .*|*X**n*            |*p*(*X*1*, **X*2*, . . . , **X**n*)|
|*v*11         |*v*21         |*. . .*|*v**n*1           |0.00003                            |
|*v*11         |*v*21         |*. . .*|*v**n*2           |0.000001                           |
|*. . .*       |*. . .*       |*. . .*|*. . .*           |…                                 |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|0.000002                           |

  Table: 联合概率质量函数的表格表示

分析与思考
  ![](media/image7.png)当 *X**i** *表示事物的“因”或“果”的时候，我们可以用来进行与事物相关的一些“推理”活动；
  ![](media/image424.png)进一步，这种推理的价值和困难？表格有多少行？


复杂的推理问题
  ![](media/image7.png)如上一页的联合概率质量函数表格，假设已知 *X*2 = *v*21，而其他的*X**j**, **j **&gt; *2 都未知，能否推断出 *X*1 =?
  ![](media/image6.png)这就引入了所谓的条件概率。
条件概率
  ![](media/image425.png)
```
\*p\*(\*A\*)
```
定义：两个事件 *A**, **B*，在事件 *A *发生的条件下，事件 *B *发生的概率，记为 *p*(*B**|**A*) =  *p*(*AB*) .(当事件 *A** *发生的概率不为 0 时，上述定义有效）
带条件概率的推理问题
  ![](media/image6.png)*X**∗** *= arg *max**a**P*(*X*1 = *a**|**X*2 = *v*21)
  ![](media/image5.png)如何用代码实现这个公式？从表中查找出所有 *X*2 = *v*21 行，将这些行按*X*1 的不同取值分组，求每组内的概率和，求概率和的最大值对应的组对应的 *X*1 的值。
  ![](media/image7.png)对本 slides 中的任何一个概率/概率题，尝试编写代码实现。


|              |              |       |                  |                                   |
|--------------|--------------|-------|------------------|-----------------------------------|
|*X*1          |*X*2          |*. . .*|*X**n*            |*p*(*X*1*, **X*2*, . . . , **X**n*)|
|*v*11         |*v*21         |*. . .*|*v**n*1           |0.00003                            |
|*v*11         |*v*21         |*. . .*|*v**n*2           |0.000001                           |
|*. . .*       |*. . .*       |*. . .*|*. . .*           |…                                 |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|0.000002                           |

  Table: 联合概率质量函数的表格表示

函数 *f *遇上概率论: *f *多了一列概率值
  ![](media/image7.png)函数 *f *如何获得？即学习问题，具体来说，函数 *f *就是完整联合概率质量函数/表格，其行数是随机分量数目的指数函数，存储该表格的空间复杂度问题，获得该表格的方法问题等。
  ![](media/image6.png)函数 *f *如何使用？即搜索解决问题的方法，具体来说，就是基于函数 *f*，即完整联合概率质量函数/表格，实现概率推理计算/算法，以及算法的时间复杂度等方面的考虑。


|              |              |       |                  |                                   |
|--------------|--------------|-------|------------------|-----------------------------------|
|*X*1          |*X*2          |*. . .*|*X**n*            |*p*(*X*1*, **X*2*, . . . , **X**n*)|
|*v*11         |*v*21         |*. . .*|*v**n*1           |0.00003                            |
|*v*11         |*v*21         |*. . .*|*v**n*2           |0.000001                           |
|*. . .*       |*. . .*       |*. . .*|*. . .*           |…                                 |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|0.000002                           |

  Table: 联合概率质量函数的表格表示

存储需求/空间复杂度
  ![](media/image6.png)表格共有 *|**X*1*|** *· *|**X*2*|** *· *.** **.** **.** *· *|**X**n**|** *行，是列数 *n** *的指数函数
  ![](media/image6.png)现实应用中，通常没有上述完整的表格，该怎么办？上述表格不全（包括行不全、    列不全）怎么办？事物的复杂性，相关因果成百上千，上述表格无法保存和精确制作出来。
  ![](media/image7.png)所谓“概率论下的机器学习”，其目标就是找到方法将上述表格表示和制作出来。


|    |    |       |      |                                   |
|----|----|-------|------|-----------------------------------|
|*X*1|*X*2|*. . .*|*X**n*|*p*(*X*1*, **X*2*, . . . , **X**n*)|


|              |              |       |                  |        |
|--------------|--------------|-------|------------------|--------|
|*v*11         |*v*21         |*. . .*|*v**n*1           |0.00003 |
|*v*11         |*v*21         |*. . .*|*v**n*2           |0.000001|
|*. . .*       |*. . .*       |*. . .*|*. . .*           |…      |
|*v*1*\|**X*1*\|*|*v*2*\|**X*2*\|*|*. . .*|*v**n**\|**X**n**\|*|0.000002|

  Table: 联合概率质量函数的表格表示

时间复杂度
  ![](media/image7.png)
```
\*∈\*\* \*\*{\*\*−\*\* \*\*}\*
```
假设 *X*1+1*,** *1 是类标号，任意给定一个 (*X*2*,** **X*3*,** **.** **.** **.** **,** **X**n*) 的值 (*v*2*,** **v*3*,** **.** **.** **.** **,** **v**n*)，求 *X*1 的值，这就是分类问题，你能从上述联合概率质量函数中给出分类结果吗？
  ![](media/image7.png)![](media/image6.png)分类非常简单，查询上述表格，比较 *p*(+1*, **v*2*, **v*3*, . . . , **v**n*) 和 *p*(*−*1*, **v*2*, **v*3*, . . . , **v**n*) 二者的大小即可。假设 *X*2 = 3，能得到 *X*1 =?，这就是求条件概率问题。
  ![](media/image7.png)
```
\*p\*\*i\*
```
典型的计算过程：遍历一遍表格，统计 *X*2 = 3 的那些行的概率值之和 *p*，同时完成对这些行的分组 (按 *X*1 的取值不同分组)，计算每组的概率值之和 *q**i*，然后计算条件概率 *q**i *，然后比较条件概率值的大小，取最大条件概率值对应的组的
  *X*1 的取值为最终结果。整个计算时间代价在遍历函数 *f*/完整的联合概率质量函数表格，时间代价太大！




出现了新情形
  ![](media/image7.png)知道了联合概率质量函数 (PMF) 的所有信息，就可以进行任意的概率值计算，对应某一类不确定性推理活动；
  ![](media/image6.png)实践难题 1：如何表示和存储 PMF？数学上，通常假设 PMF 有数学的解析表达式，我们该如何给出这种解析表达式？
  ![](media/image7.png)实践难题 2：如何计算某个概率值？如果采用表格存储 PMF，时间代价？空间代价？




![](media/image426.png)网络结构边缘分布

  B=1: 发生入室盗窃, 否则 B=0


  E=1: 发生地震， 否则 E=0

  A=1: 警铃响了， 否则 A=0



联合概率质量函数

条件概率质量函数

约简：联合概率质量函数 = 网络结构 + 若干边缘分布 + 若干条件概率质量函数


存在问题
  ![](media/image7.png)为什么说二者是等价的？即：“联合概率质量函数 = 网络结构 + 若干边缘分布 + 若干条件概率质量函数”能证明吗？
  ![](media/image7.png)如果等价，二者如何相互转换？
  ![](media/image7.png)实现了约简吗？即降低了存储代价吗？（该例子没有！），下图中的例子呢？

        ![](media/image427.jpeg)解释说明
                      ![](media/image18.png)J=1: john 打电话通知我警铃响了，否则 J=0； M=1：mary 打电话通知我警铃响了，否则 M=0
                      ![](media/image18.png)前一个例子比较：联合概率质量函数 8 行，而约简的 Bayes 网络表示：12 行 + 一个网络/图
                      ![](media/image376.png)左边例子：联合概率质量函数 16 行，而约简的
                      bayes 网络表示：16 行 + 一个网络/图
                      ![](media/image376.png)右边例子：联合概率质量函数 32 行，而约简的
                      bayes 网络表示：20 行 + 一个网络/图


步骤与方法
  ![](media/image428.png)网络结构 =*⇒ *联合概率的计算公式，一个乘积表达式；
  ![](media/image7.png)边缘概率质量函数和条件概率质量函数，给上述乘积表达式中每个  乘积因子提供一个特定的值。
进一步解释说明
  ![](media/image7.png)对任意联合概率（也就是联合概率质量函数的任何一行），我们都可以用上述方法计算出其概率值；因此，我们从 Bayes 网络可以恢复出整个联合熵质量函数；
  ![](media/image7.png)核心：乘积表达式的合理性来自随机分量的独立性假设。
  *p*(*AB*) = *p*(*A*)*p*(*B*)，当 *A**, **B *独立时成立。
  ![](media/image428.png)网络结构描述了随机分量之间的独立性。
  ![](media/image428.png)巧妙地用一些小的“表格/函数”相乘（SQL 中的连接操作，笛卡儿积），获得大的完整的联合概率质量函数/表格。



                    ![](media/image429.jpeg)解释说明
                      ![](media/image376.png)开始之前，先思考存储代价降低了多少。
                      ![](media/image376.png)看左图，写乘积公式的规律/方法是什么？
                      ![](media/image376.png)原理是什么？
                          ![](media/image32.png)（条件）概率计算的链式法则
                        ![](media/image31.png)（条件）独立性

*p*(*x*1*, . . . , **x*7) = *p*(*x*1)*p*(*x*2)*p*(*x*3)*p*(*x*4*|**x*1*, **x*2*, **x*3)*p*(*x*5*|**x*1*, **x*3)*p*(*x*6*|**x*4)*p*(*x*7*|**x*4*, **x*5)


链式法则：用条件概率和边缘概率计算联合概率的通用方法
  *p*(*x*1*, . . . , **x**n*) = *p*(*x**n**|**x*1*, **. . . , **x**n**−*1) · *p*(*x*1*, . . . , **x**n**−*1)
= *p*(*x**n**|**x*1*,** **.** **.** **.** **,** **x**n**−*1) · *p*(*x**n**−*1*|**x*1*,** **.** **.** **.** **,** **x**n**−*2) · *p*(*x*1*,** **.** **.** **.** **,** **x**n**−*2)
*. . .*
= *p*(*x**n**|**x*1*,** **.** **.** **.** **,** **x**n**−*1) · *p*(*x**n**−*1*|**x*1*,** **.** **.** **.** **,** **x**n**−*2) · *.** **.** **.** *· *p*(*x*1)
链式法则：应用的例子
*p*(*x*1*, . . . , **x*7) = *p*(*x*7*|**x*1*, **. . . , **x*6) · *p*(*x*1*, . . . , **x*6)
= *p*(*x*7*|**x*1*, **. . . , **x*6) · *p*(*x*6*|**x*1*, **. . . , **x*5) · *p*(*x*1*, . . . , **x*5)
*. . .*
= *p*(*x*7*|**x*1*, **. . . , **x*6) · *p*(*x*6*|**x*1*, **. . . , **x*5) · *. . . *· *p*(*x*1)
链式法则应用后，如何得到下述的公式？
  ![](media/image428.png)*p*(*x*1*, . . . , **x*7) =
  *p*(*x*1)*p*(*x*2)*p*(*x*3)*p*(*x*4*|**x*1*, **x*2*, **x*3)*p*(*x*5*|**x*1*, **x*3)*p*(*x*6*|**x*4)*p*(*x*7*|**x*4*, **x*5)
  ![](media/image6.png)结合网络结构图，应用独立性，去掉条件中不相关的随机分量。


![](media/image430.jpeg)

条件独立
  ![](media/image7.png)先写出各个图形表示的联合概率质量函数的乘积表达式，然后用后面的条    件独立公式来证明/约简链式法则的结果。
  ![](media/image428.png)
```
\*|\*
```
情形 1：*p*(*a**, **b**, **c*) = *p*(*a*)*p*(*b*)*p*(*c a**, **b*), 因为 *a**, **b *在 *c *未知的条件下独立：
  *p*(*a**, **b*) = *p*(*a*)*p*(*b*)，绝对独立。
  ![](media/image6.png)情形 2：*p*(*a**,** **b**,** **c*) = *p*(*c*)*p*(*a**|**c*)*p*(*b**|**c*), 因为 *a**,** **b** *在 *c** *已知/给定的条件下独立：*p*(*a**,** **b**|**c*) = *p*(*a**|**c*)*p*(*b**|**c*)
  ![](media/image7.png)情形 3：*p*(*a**,** **b**,** **c*) = *p*(*a*)*p*(*c**|**a*)*p*(*b**|**c*), 因为 *a**,** **b** *在 *c** *已知/给定的条件下独立：*p*(*a**,** **b**|**c*) = *p*(*a**|**c*)*p*(*b**|**c*)
  ![](media/image7.png)一句话：网络结构图中，不直接连边的节点之间条件独立
解释了为什么从链式法则，可得到最终的乘积公式。




![](media/image431.jpeg)把所有的边缘概率值，条件概率值都列出来
网络结构和这些概率值就构成了联合概率质量函数的约简表示


            ![](media/image432.jpeg)

解释说明
  ![](media/image428.png)如图所示的特殊网络结构，其中 *X*1 一般称为“cause”或类标签， 其他的 *X**i**, **i **&gt; *1 称为观测值，现象，效果等；
  ![](media/image428.png)联合概率计算公式为:
  *p*(*X*1*, **X*2*, **. . . , **X**n*) = *p*(*X*1) · *p*(*X*2*|**X*1) · *. . . *· *p*(*X**n**|**X*1)
  ![](media/image6.png)
```
\*|\*
```
朴素 Bayes 模型的应用：分类或推理，就是已知 *X*2*, **X*3*, . . . , **X**n*， 求 *X*1；在概率论框架下，我们转换为求 *p*(*X*1 *X*2*, . . . , **X**n*)，计算概率值！


        ![](media/image433.png)

解释说明
  ![](media/image428.png)如图，*H *= (*H*1*, **H*2*, **H*3*, **H*4*, **H*5)，*E *= (*E*1*, **E*2*, **E*3*, **E*4*, **E*5)，*H *是隐
  藏的随机分量，看不见/无法观测的“causes”，*E** *是可观测的随机分量，在某个时刻，也许只能观测到一部分，比如前 *k *个 *E**i*
  联合概率计算公式：
  
```
\*i\*=2
```

```
\*i\*=1
```
*p*(*H** *= *h**,** **E** *= *e*) = *p*(*h*1)Π*n**  ** **p*(*h**i**|**h**i**−*1)Π*n**  ** **p*(*e**i**|**h**i*)



问题描述
  ![](media/image6.png)已知条件：给定数据集 *D*
  ![](media/image6.png)目标：Bayes 网络：包括网络结构和各种边缘/条件概率质量函数/表

基本思想
  ![](media/image434.png)分别解决两个子问题：
      ![](media/image32.png)网络结构的确定。
      ![](media/image31.png)概率质量函数的确定。


问题描述
  ![](media/image6.png)
```
\*D\*
```
给定数据集（有时有专家/知识库存在），求网络结构（变量之间的依赖关系）。
方法分类
  ![](media/image7.png)![](media/image7.png)依靠专家建模，手工给出网络结构从数据集中自动学习网络结构
      ![](media/image31.png)利用卡方/互信息等做相关性测试。如用数据集验证变量间是否独立/条件独立，从完全图开始，逐步删除独立/条件独立变量之间的边；要验证的次数随变量个数指数增加；
      ![](media/image32.png)基于搜索-评分的方法。一般从无边图开始（变量两两独立的假设模型），逐步添加变量之间的边（每次得到一个新假设模型），然后对每个新模型评分（预设的评分函数，用来验证模型的优劣），依据分数选择一个最好的模型，这个步骤多次迭代。
  ![](media/image7.png)结合二者的混合方法



问题描述
  ![](media/image5.png)
```
\*D\*
```
给定数据集和网络结构（图 *G*)，求各边缘/条件概率质量函数/表。

方法思想
  ![](media/image6.png)利用蒙特卡洛逼近。将数据集视为“粒子”集，然后计算网络结构  需要的各种边缘/条件概率质量函数/表。



问题描述
  ![](media/image5.png)数据集：*D** *= *{*1*, *5*, *4*, *4*, *3*, *5*, *5*, *4*, *4*, *4*}*，表示对一个餐馆的打分；
  ![](media/image435.png)随机变量 *R** **∈ {*1*, *2*, *3*, *4*, *5*} *表示餐馆的分数，求 (*p*1*, **p*2*, **p*3*, **p*4*, **p*5)

求解过程 蒙特卡罗逼近：
  ![](media/image6.png)分别统计每个分数出现的次数 *c**i** *以及数据总数 *c*
  ![](media/image7.png)得 到 (*p*1*, **p*2*, **p*3*, **p*4*, **p*5) = (*c*1/*c**, **c*2/*c**, **c*3/*c**, **c*4/*c**, **c*5/*c*) = (0*.*1*, *0*, *0*.*1*, *0*.*5*, *0*.*3)，即用频度近似概率值


                        ![](media/image436.png)给定的网络结构

问题描述
  ![](media/image7.png)数据集：*D *= *{*(*c**, *4)*, *(*c**, *4)*, *(*c**, *5)*, *(*s**, *1)*, *(*s**, *5)*}*
  ![](media/image6.png)
```
\*∈\*\* \*\*{\*\*}\*
```

```
\*{}\*\*∈\*\* \*\*{\*\*}\*
```
随机向量 *X *=   *T**, **R  *, 随机分量 *R   *1*, *2*, *3*, *4*, *5   表示对一个餐馆的评分, 随机分量 *T    c**, **s   *表示餐馆类型，假设类型是决定餐馆评分的唯一标准（简化）
求解过程
  ![](media/image6.png)统计频度当边缘概率 *p*(*T*) = (0*.*6*, *0*.*4)
  ![](media/image6.png)令 *T *= *c *或 *s *时，分别统计各个打分的频度，得到条件概率
  *p*(*R**|**T*) = ((0*,** *0*,** *0*,** *0*.*67*,** *0*.*33)*,** *(0*.*5*,** *0*,** *0*,** *0*,** *0*.*5))



                        ![](media/image437.png)给定的网络结构


问题描述
  ![](media/image435.png)数据集：*D *= *{*(*c**, *0*, *3)*, *(*c**, *1*, *5)*, *(*s**, *0*, *1)*, *(*s**, *0*, *5)*, *(*s**, *1*, *4)*}*
  ![](media/image6.png)随机向量：*X *= *{**T**, **A**, **R**}*，*A *表示是否获得认证，其他变量含义如前所述
求解过程
  ![](media/image435.png)统计频度当边缘概率 *p*(*T*) = (0*.*4*, *0*.*6)*, **p*(*A*) = (0*.*6*, *0*.*4)
  ![](media/image435.png)对 (*T**, **A*) 的任意给定的组合取值，统计 *R *的出现频度当成条件概率
  *p*(*R**|**T**,** **A*) = ((0*,** *0*,** *1*,** *0*,** *0)*c*0*,** *(0*,** *0*,** *0*,** *0*,** *1)*c*1*,** *(*.** **.** **.*)*s*0*,** *(*.** **.** **.*)*s*1)
  ![](media/image6.png)条件概率质量函数中出现了大量的 0，这是非常不合理/不准确地对概率值的估计，有没有改良的办法？


![](media/image438.png)问题描述
  ![](media/image152.png)条件概率表中存在很多不合理的估计值
  0，原因是样本数量太少。如何处理？
解决办法：拉普拉斯平滑
  ![](media/image93.png)去掉这些 0 的方法称为平滑技术
  ![](media/image50.png)若在统计每个值出现次数时，计数器的初始值设置为非零，这就是所谓的“拉普拉斯平滑”
  ![](media/image198.png)![](media/image198.png)通常设置计数器初始值为 1 如右图的例子，数据集为 *D *= *{*(*d**, *4)*, *(*d**, *5)*, *(*c**, *5)*}*


                        ![](media/image432.jpeg)给定的 Bayes 网络结构

问题描述
  ![](media/image7.png)给定数据集 *D *和 Bayes 网络结构如图，求边缘/条件概率质量函数/表。

求解过程
  ![](media/image7.png)首先在数据集中统计 *X*1 各种取值出现的频度，并以之替代概率，得到
  *p*(*X*1)；
  ![](media/image6.png)![](media/image7.png)依据 *X*1 的不同取值，将数据集 *D *分为若干组，同组 *X*1 的值相同； 统计每组内 *X**i**, **i **&gt; *1 的各种取值出现的频度，得到条件概率质量函数*p*(*X**i**|**X*1)



          ![](media/image439.jpeg)给定的 Bayes 网络结构给定数据集为
          *D *= *{*(?*, *4*, *5)*, *(?*, *4*, *4)*, *(?*, *5*, *3)*, *(?*, *1*, *2)*, *(?*, *5*, *4)*}*

问题描述
  ![](media/image7.png)给定数据集 *D *和 Bayes 网络结构如图，求边缘/条件概率质量函数/表。
问题分析
  ![](media/image7.png)数据集中有隐变量存在，即没有任何的观测到的分量数据，图中
  *H *= *{**G**}**, **E *= *{**R*1*, **R*2*}*
  ![](media/image6.png)典型的代表问题：隐马尔可夫模型，聚类问题
  ![](media/image6.png)思想：将条件概率质量函数视为参数/变量，在这些参数/变量的取值中找一组最好的参数，使得出现观测到输出变量（已知数据集）的概率最大。


算法思想
  ![](media/image435.png)隐变量 *H *和条件概率质量函数都是未知变量，在算法依次/轮流更新；随机设置条件概率质量函数的初值, 不妨设为 *cpt*0；
  ![](media/image440.png)E-step：
      ![](media/image31.png)
```
\*−\*
```

```
\*|\*\*−\*\*\*\*−\*
```
对所有 *H *= *h*，计算 *p*(*E *= *e h**, **cpt**i**  *1)，给定第 *i  *1 次迭代获得的各个” 小表”*cpt**i** *1，我们可以计算该条件概率值；
      ![](media/image31.png)
```
\*∗\*
```

```
\*|\*\*∗\*
```
比较不同 *h** *的概率值 *p*(*E** *= *e** **h**, **cpt**i*)，取最大概率值对应的 *h** *来构建随机向量 (*H**,** **E*) 的取值 (*h**  **,** **e*)，这是概率中的“极大似然估计”，也就是说隐藏的嫌疑犯 *H** *就是最有可能造成观测到的证据 *E** *= *e** *出现的人；
  ![](media/image6.png)M-step：
      ![](media/image32.png)获得了样本数据集 (*H**, **E*)，用它来计算/更新 Bayes 网络的各种边缘/条件概率质量函数，即 *cpt**i*
  ![](media/image441.png)![](media/image7.png)E-step 和 M-step 迭代循环，*i *为循环控制变量； 算法停止条件：收敛到极值。



评述
  ![](media/image441.png)理解 EM 算法思想：假设我们想估计知道 A 和 B 两个参数，在开始状态下二者都是未知的，但如果知道了 A 的信息就可以得到 B 的信息，反过来知道了 B 也就得到了 A。可以考虑首先赋予 A 某种初值，以此得到 B 的估计值，然后从 B 的当前值出发，重新估计 A 的取值，这个过程一直持续到收敛为止。
  ![](media/image7.png)聚类算法中 k-means 算法就是 EM 的特例；Bayes 网络及推理可以用来解聚类问题。


问题描述
  ![](media/image7.png)给定完整的联合概率质量函数（表格），用程序代码（C，java，SQL或伪代码）描述某个特定概率值的计算。
典型的两类概率值计算问题
  ![](media/image7.png)边缘化：计算某些随机分量的边缘概率质量函数；
  ![](media/image441.png)条件概率：计算某些分量 A 的取值/取值范围已知时，其他某些分量 B 取某个/某些值的条件概率。
  ![](media/image441.png)请总结方法。
时间复杂度
  ![](media/image7.png)如何降低扫描整个表格的时间代价？表格有指数量级的行，在复杂  问题下，扫描一遍都不可行。
  ![](media/image7.png)算法总是和数据结构相关的。











  ![](media/image442.png)Figure: 两类典型的概率推理题
  解释说明
    ![](media/image19.png)左图字母含义如下：
    S—sunny，R—rain
    ![](media/image19.png)左图中三个表格分别是：联合概率质量函数，sunny 的边缘概率质量函数，rain
    （*R** *= 1）时 sunny 的条件概率质量函数；




  ![](media/image443.png)
结果
  ![](media/image6.png)*p*(*B *= 1) = *ϵ, **p*(*B *= 0) = 1 *−** **ϵ*
解释说明
  ![](media/image23.png)*p*(*B*) =?，即发生/不发生入室盗窃的概率各是多少？
  ![](media/image18.png)
```
\*|\*
```
*p*(*B A *= 1) =?，当警铃响了的时候， 发生/不发生入室盗窃的概率各是多少？
  ![](media/image17.png)
```
\*|\*
```
*p*(*B A *= 1*, **E *= 1)，当警铃响了，发生地震了，发生/不发生入室盗窃的概率各是多少？

  ![](media/image7.png)*p*(*B** *= 1*|**A** *= 1) =    1   *,** ** **p*(*B** *= 0*|**A** *= 1) =  1*−**ϵ*

  ![](media/image7.png)*p*2*−**ϵ*
  2*−**ϵ*

    (*B** *= 1*|**A** *= 1*,** **E** *= 1) = *ϵ,** ** **p*(*B** *= 0*|**A** *= 1*,** **E** *= 1) = 1 *−** **ϵ*
题外话
  ![](media/image6.png)你能解释 *ϵ *很小，如 0.00001 时，上面三个概率吗？



```





\*p\*(\*B\*) =?，即发生/不发生入室盗窃的概率各是多少？
\*p\*(\*B\*\*|\*\*A \*= 1) =?，当警铃响了的时候，发生/不发生入室盗窃的概率各是多少？
\*p\*(\*B\*\*|\*\*A \*= 1\*, \*\*E \*= 1)，当警铃响了，发生地震了，发生/不发生入室盗窃的概率各是多少？
```

计算/推理过程
  *p*(*B*)，直接查询边缘概率质量函数/表格
  *p*(*B**|**A** *= 1)，连接第一、二、三张表中 *A** *= 1 的那些行（连接条件：1*.**b** *= 3*.**b**,** *2*.**e** *= 3*.**e*），添加新列 *p*(*b*)*p*(*e*)*p*(*a**|**b**,** **e*)，并归一化得到表的新概率列，依据新表 *A**,** **B** *列取值不同，进行分组，组内新概率求和。 *p*(*B**|**A** *= 1*,** **E** *= 1)，类似上一个例子处理。
  上述过程可以优化：合理安排 SQL 中“投影、“连接”和“分组”等操作的次序，可以减少操作的数据量。


形式化描述
![](media/image447.png)输入：
      ![](media/image32.png)Bayes 网络（包括网络结构和相关的条件/边缘概率质量函数），也就是完整联合概率质量函数的约简描述形式 *p*(*X*)；
      ![](media/image31.png)![](media/image31.png)观察到的证据 *E *= *e**, **E **⊂ **X*，即 *E *是随机向量 *X *的一个分量子集； 查询 *Q** **⊂** **X** *是指定想要了解的对象（原因/现象）；
![](media/image7.png)输出：
      ![](media/image31.png)对所有的 *q*，求条件概率 *p*(*Q** *= *q**|**E** *= *e*)

一般性方法
  总结前面的例子所用的方法，得到一般性的推理计算过程。


符号说明
  ![](media/image6.png)随机向量 *X *= *E **∪ **Q **∪ **M*
  ![](media/image5.png)*E *观察到的现象，*Q *查询，*M *不关心的因素
主要思想: 变量消元法
  ![](media/image7.png)首先在各“小表”中选择 *E** *= *e** *的行留下（消去 *E*）；所有的“小表”通过“连接”操作，组合成一张“大表”，制作一个新的概率值列，即联合概率质量函数；
  ![](media/image6.png)再将不关心的因素 *M** *去掉（消去 *M*）：有多行满足 *Q** *= *q*，这些行的 *M *值不一样，若这些行的概率值之和为 *p *，则产生新的行
  (*q**, **p*)；实际上我们并没有组合出完整的联合概率质量函数，因此， 依次消去 *M *中的某个分量时，通常只需要访问一部分“小表”即可，减少了时间代价。
  ![](media/image7.png)最终得到新表 (*Q**, **P*) 即是所求。


空间复杂度
  ![](media/image7.png)当网络中某个节点的（入）度为 *k *时，会产生一个 *k *+ 1 列的条件概率“小表”，表的行数是 *k** *的指数函数，因此 Bayes 网络描述联合概率质量函数并非完美解决了存储代价问题。

时间复杂度
  ![](media/image448.png)遍历所有的“小表”是推理的基本操作之一，因此推理的时间复杂  度和各个表的大小相关；
  ![](media/image7.png)从网络结构的角度看，单连通网络（任何两个节点之间的路径只有  一条）通常能线性时间解决；非单连通网络需要指数时间复杂度。


  ![](media/image7.png)精确计算一个概率值常常不可能，能不能计算近似值？ 已知条件：Bayes 网络。
  ![](media/image7.png)目标：计算某个概率值。
  ![](media/image6.png)应用范围：当计算概率值的时间代价是指数的复杂度时，采用计算  概率近似值的方法。
蒙特卡罗逼近的基本概念
  ![](media/image7.png)粒子：随机向量的一个值向量。
  ![](media/image7.png)采样：利用 Bayes 网络，产生各个随机分量，最终获得一个完整的“粒子”。
  ![](media/image448.png)重复采样过程，获得大量粒子构成的集合；所谓“采样方法”就是  指产生一个粒子及多个粒子的过程。
  ![](media/image5.png)统计/计数粒子集合，用各种比例代表各种对应的概率值。

### ********如何写一个抽样程序？
假设我们有一个产生 (0,1) 之间均匀分布实数的函数，接下来......
  ![](media/image7.png)
```
\*−\*\*−\*
```
正态分布？box-muller 变换。*Y*1 = *√ *2 ln *X*1*cos*(2*π**X*2)*, **Y*2 = *√ *2 ln *X*2*cos*(2*π**X*1), *X*1*, **X*2 是均匀 (0,1) 间分布的样本，*Y*1*, **Y*2 服从标准正态分布。
      ![](media/image7.png)![](media/image31.png)MCMC/马尔可夫蒙特卡罗方法，通用的抽样方法，从任意概率质量函数 *p*(*x*) 中抽样。 利用马尔可夫链，随机过程的概念，每个样本是随机过程的一个状态，大量的样本/状态的分布服从随机过程的稳态分布 *p*(*x*)，即我们
      要抽样的分布。
      ![](media/image31.png)从当前状态（粒子），以一定的概率转移到下一个状态（粒子），并不一定每次都转移成功，有一个转移接受率。
      ![](media/image80.png)具体实现 MCMC 的一个算法是 Metropolis-Hastings 算法。一维随机变量。
  ![](media/image7.png)随机向量采样：Gibbs 抽样。当前粒子为 (*v*1*,** **v*2*,**,** **v**n*)，下一个粒子只改变当前粒子的一
  个分量的值，改变的方法为对应的条件概率用一次随机抽样。
  ![](media/image7.png)粒子滤波，通用抽样方法。
